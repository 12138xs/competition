{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 剔除重复数据->数据分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548942\n",
      "9993\n",
      "437781\n",
      "90113\n",
      "89366\n",
      "89902\n",
      "89966\n",
      "39227\n",
      "39207\n",
      "40080\n",
      "6275\n",
      "19709\n",
      "100\n",
      "8665\n",
      "6266\n",
      "45\n",
      "20028\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "剔除重复数据->数据分类\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "file_path = \"/home/ma-user/work/train.json\"\n",
    "data_list = []\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "        data_list.append(problem + \"#分隔符#\" + solution)\n",
    "\n",
    "data_list = set(data_list)  # 剔除重复数据\n",
    "print(len(data_list))  # 548942\n",
    "dataset = []\n",
    "for data in data_list:\n",
    "    problem, solution = data.split(\"#分隔符#\")\n",
    "    dataset.append({\"problem\": problem, \"solution\": solution})\n",
    "\n",
    "en_data = []  # en\n",
    "calculate_data = []  # cn_计算\n",
    "calculate_add_data = []\n",
    "calculate_sub_data = []\n",
    "calculate_mul_data = []\n",
    "calculate_div_data = []\n",
    "calculate_sqrt_data = []\n",
    "calculate_pow_data = []\n",
    "equation_data = []  # cn_解方程\n",
    "product_data = []  # cn_商品\n",
    "average_data = []  # cn_求平均值\n",
    "quality_data = []  # cn_计算物体质量\n",
    "area_data = []  # cn_计算面积\n",
    "sales_data = []  # cn_计算销售额\n",
    "simplify_data = []  # cn_进行简化\n",
    "function_data = [] # cn_求函数\n",
    "\n",
    "# 匹配加法、减法、乘法、除法、平方根和乘方\n",
    "add_pattern = re.compile(r'(\\d+\\.?\\d*)\\+(-?\\d+\\.?\\d*)')\n",
    "sub_pattern = re.compile(r'(\\d+\\.?\\d*)-(-?\\d+\\.?\\d*)')\n",
    "mul_pattern = re.compile(r'(\\d+\\.?\\d*)\\*(-?\\d+\\.?\\d*)')\n",
    "div_pattern = re.compile(r'(\\d+\\.?\\d*)/(-?\\d+\\.?\\d*)')\n",
    "sqrt_pattern = re.compile(r'(\\d+\\.?\\d*)的平方根')\n",
    "pow_pattern = re.compile(r'(\\d+\\.?\\d*)的(\\d+)次方')\n",
    "\n",
    "for item in dataset:\n",
    "    question = item['problem']\n",
    "    if not re.match(r'^[\\u4e00-\\u9fff]', question):\n",
    "        en_data.append(item)\n",
    "    elif question.startswith('计算'):\n",
    "        calculate_data.append(item)\n",
    "        new_item = item[\"problem\"].replace(' ', '')\n",
    "        if match := add_pattern.search(new_item):\n",
    "            calculate_add_data.append(item)\n",
    "        if match := sub_pattern.search(new_item):\n",
    "            calculate_sub_data.append(item)\n",
    "        if match := mul_pattern.search(new_item):\n",
    "            calculate_mul_data.append(item)\n",
    "        if match := div_pattern.search(new_item):\n",
    "            calculate_div_data.append(item)\n",
    "        if match := sqrt_pattern.search(new_item):\n",
    "            calculate_sqrt_data.append(item)\n",
    "        if match := pow_pattern.search(new_item):\n",
    "            calculate_pow_data.append(item)\n",
    "\n",
    "    elif question.startswith('解方程'):\n",
    "        equation_data.append(item)\n",
    "    elif question.startswith('商品'):\n",
    "        product_data.append(item)\n",
    "    elif question.startswith('求以下数据的平均值'):\n",
    "        average_data.append(item)\n",
    "    elif '请计算该物体的质量。' in question:\n",
    "        quality_data.append(item)\n",
    "    elif '请计算其面积。' in question:\n",
    "        area_data.append(item)\n",
    "    elif '请计算今年的销售额。' in question:\n",
    "        sales_data.append(item)\n",
    "    elif '进行简化。' in question:\n",
    "        simplify_data.append(item)\n",
    "    elif re.match(r'^当.*时，求函数.*', question):\n",
    "        function_data.append(item)\n",
    "\n",
    "print(len(en_data))  # 9993\n",
    "print(len(calculate_data))  # 437781\n",
    "print(len(calculate_add_data))  # 90113\n",
    "print(len(calculate_sub_data))  # 89366\n",
    "print(len(calculate_mul_data))  # 89902\n",
    "print(len(calculate_div_data))  # 89966\n",
    "print(len(calculate_sqrt_data))  # 39227\n",
    "print(len(calculate_pow_data))  # 39207\n",
    "print(len(equation_data))  # 40080\n",
    "print(len(product_data))  # 6275\n",
    "print(len(average_data))  # 19709\n",
    "print(len(quality_data))  # 100\n",
    "print(len(area_data))  # 8665\n",
    "print(len(sales_data))  # 6266\n",
    "print(len(simplify_data))  # 45\n",
    "print(len(function_data))  # 20028\n",
    "\n",
    "random.shuffle(en_data)\n",
    "random.shuffle(calculate_data)\n",
    "random.shuffle(calculate_add_data)\n",
    "random.shuffle(calculate_sub_data)\n",
    "random.shuffle(calculate_mul_data)\n",
    "random.shuffle(calculate_div_data)\n",
    "random.shuffle(calculate_sqrt_data)\n",
    "random.shuffle(calculate_pow_data)\n",
    "random.shuffle(equation_data)\n",
    "random.shuffle(product_data)\n",
    "random.shuffle(average_data)\n",
    "random.shuffle(quality_data)\n",
    "random.shuffle(area_data)\n",
    "random.shuffle(sales_data)\n",
    "random.shuffle(simplify_data)\n",
    "random.shuffle(function_data)\n",
    "\n",
    "os.makedirs('/home/ma-user/work/dataset/', exist_ok=True)\n",
    "\n",
    "with open('/home/ma-user/work/dataset/en.json', 'w', encoding='utf-8') as file:\n",
    "    for item in en_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/calculate.json', 'w', encoding='utf-8') as file:\n",
    "    for item in calculate_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/calculate_add.json', 'w', encoding='utf-8') as file:\n",
    "    for item in calculate_add_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/calculate_sub.json', 'w', encoding='utf-8') as file:\n",
    "    for item in calculate_sub_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/calculate_mul.json', 'w', encoding='utf-8') as file:\n",
    "    for item in calculate_mul_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/calculate_div.json', 'w', encoding='utf-8') as file:\n",
    "    for item in calculate_div_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/calculate_sqrt.json', 'w', encoding='utf-8') as file:\n",
    "    for item in calculate_sqrt_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/calculate_pow.json', 'w', encoding='utf-8') as file:\n",
    "    for item in calculate_pow_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/equation.json', 'w', encoding='utf-8') as file:\n",
    "    for item in equation_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/product.json', 'w', encoding='utf-8') as file:\n",
    "    for item in product_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/average.json', 'w', encoding='utf-8') as file:\n",
    "    for item in average_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/quality.json', 'w', encoding='utf-8') as file:\n",
    "    for item in quality_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/area.json', 'w', encoding='utf-8') as file:\n",
    "    for item in area_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/sales.json', 'w', encoding='utf-8') as file:\n",
    "    for item in sales_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/simplify.json', 'w', encoding='utf-8') as file:\n",
    "    for item in simplify_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open('/home/ma-user/work/dataset/function.json', 'w', encoding='utf-8') as file:\n",
    "    for item in function_data:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类构建 CoT 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "area_dataset\n",
    "\"\"\"\n",
    "\n",
    "def nums_extract(text):\n",
    "    # 使用正则表达式提取所有数字\n",
    "    numbers_text = re.findall(r'\\d+', text)\n",
    "    # 转换为整数列表\n",
    "    numbers = [int(num) for num in numbers_text]\n",
    "    return numbers_text, numbers\n",
    "\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/area.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/cot_area.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "\n",
    "        problem_numbers_text, problem_numbers = nums_extract(problem)\n",
    "\n",
    "        solution_number_text, solution_number = nums_extract(solution)\n",
    "        \n",
    "        multiply_text = \" * \".join(problem_numbers_text) + \" = \"\n",
    "        multiply_result = problem_numbers[0] * problem_numbers[1]\n",
    "\n",
    "        \n",
    "        if multiply_result != solution_number[0]:\n",
    "            print(problem)\n",
    "\n",
    "        cot_solution = \"面积 = 长 * 宽 = \" + multiply_text + solution_number_text[0] + \"\\n因此，\" + solution\n",
    "        # print(cot_solution)\n",
    "\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "average_dataset\n",
    "结果保留两位小数\n",
    "\"\"\"\n",
    "\n",
    "def nums_extract(text):\n",
    "    # 使用正则表达式提取所有数字\n",
    "    numbers_text = re.findall(r'\\d+', text)\n",
    "    # 转换为整数列表\n",
    "    numbers = [int(num) for num in numbers_text]\n",
    "    return numbers_text, numbers\n",
    "\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/average.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/cot_average.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "\n",
    "        problem_numbers_text, problem_numbers = nums_extract(problem)\n",
    "        problem_numbers_len = len(problem_numbers)\n",
    "\n",
    "        solution_number_text = solution.split(\"平均值为 \")[1]\n",
    "        solution_number = round(float(solution_number_text), 2)\n",
    "        \n",
    "        sum_text = \" + \".join(problem_numbers_text) + \" = \"\n",
    "        sum_result = str(sum(problem_numbers))\n",
    "\n",
    "        if round(sum(problem_numbers) / problem_numbers_len, 2) != round(solution_number, 2):\n",
    "            print(problem)\n",
    "\n",
    "        cot_solution = \"平均值 = 数据之和 / 数据个数\\n首先，计算所有数据的总和：\" + sum_text + sum_result + \"\\n\" + \"一共有 \" + str(problem_numbers_len) + \" 个数据\\n\" + \"数据之和 / 数据个数：\" + sum_result + \" / \" + str(problem_numbers_len) + \" = \" + str(solution_number) + \"\\n因此，平均值为 \" + str(solution_number)\n",
    "        # print(cot_solution)\n",
    "\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "equation_dataset\n",
    "结果保留两位小数\n",
    "\"\"\"\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/equation.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/cot_equation.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "\n",
    "        s1 = int(problem.split(\"解方程 \")[1].split(\"x\")[0])\n",
    "        s2 = int(problem.split(\"x + \")[1].split(\" = \")[0])\n",
    "        result = round(float(solution.split(\"方程的解为：\")[1]), 2)\n",
    "\n",
    "        if round(-s2 / s1, 2) != round(result, 2):\n",
    "            print(problem)\n",
    "\n",
    "        cot_solution = problem.split(\"解方程 \")[1] + \"\\n\" + str(s1) + \"x = \" + str(-s2) + \"\\nx = \" + str(-s2) + \" / \" + str(s1) + \" = \" + str(result) + \"\\n因此，方程的解为：\" + str(result)\n",
    "        # print(cot_solution)\n",
    "\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function_dataset\n",
    "\"\"\"\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/function.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/cot_function.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "\n",
    "        x = float(problem.split(\"当 x = \")[1].split(\" 时\")[0])\n",
    "        s1 = int(problem.split(\"求函数 y = \")[1].split(\"x^\")[0])\n",
    "        s2 = int(problem.split(\"x^\")[1].split(\" 的值\")[0])\n",
    "        result = float(solution.split(\"函数的值为：\")[1])\n",
    "\n",
    "\n",
    "        cot_solution = problem.split(\"，\")[0] + \"\\n\" + problem.split(\"求函数 \")[1].split(\" 的值\")[0] + \" = \" + str(s1) + \" * \" + str(x) + \"^\" + str(s2) + \" = \" + solution.split(\"函数的值为：\")[1] + \"\\n因此，\" + solution\n",
    "\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "product_dataset\n",
    "保留两位小数\n",
    "\"\"\"\n",
    "\n",
    "def nums_extract(text):\n",
    "    # 使用正则表达式提取所有数字\n",
    "    numbers_text = re.findall(r'\\d+', text)\n",
    "    # 转换为整数列表\n",
    "    numbers = [int(num) for num in numbers_text]\n",
    "    return numbers_text, numbers\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/product.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/cot_product.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "        result = round(float(solution), 2)\n",
    "\n",
    "        problem_numbers_text, problem_numbers = nums_extract(problem)\n",
    "        dec_result = problem_numbers[0] - problem_numbers[1]\n",
    "\n",
    "        if round(dec_result / problem_numbers[0] * 100, 2) != round(float(solution), 2):\n",
    "            print(problem)\n",
    "\n",
    "        cot_solution = \"折扣比例 = (1 - 价格 / 原价) * 100% = (1 - \" + problem_numbers_text[1] + \" / \" + problem_numbers_text[0] + \") * 100% = \" + str(result) + \"%\\n因此，折扣比例为 \" + str(result)\n",
    "\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "quality_dataset\n",
    "\"\"\"\n",
    "\n",
    "def nums_extract(text):\n",
    "    # 使用正则表达式提取所有数字\n",
    "    numbers_text = re.findall(r'\\d+', text)\n",
    "    # 转换为整数列表\n",
    "    numbers = [int(num) for num in numbers_text]\n",
    "    return numbers_text, numbers\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/quality.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/cot_quality.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "\n",
    "        problem_numbers_text, problem_numbers = nums_extract(problem)\n",
    "        solution_numbers_text, solution_numbers = nums_extract(solution)\n",
    "\n",
    "        if problem_numbers[0] * problem_numbers[1] != solution_numbers[0]:\n",
    "            print(problem)\n",
    "\n",
    "        cot_solution = \"质量 = 密度 * 体积 = \" + problem_numbers_text[0] + \" * \" + problem_numbers_text[1] + \" = \" + solution_numbers_text[0] + \"\\n因此，该物体的质量为 \" + solution\n",
    "\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sales_dataset\n",
    "保留两位小数\n",
    "\"\"\"\n",
    "\n",
    "def nums_extract(text):\n",
    "    # 使用正则表达式提取所有数字\n",
    "    numbers_text = re.findall(r'\\d+', text)\n",
    "    # 转换为整数列表\n",
    "    numbers = [int(num) for num in numbers_text]\n",
    "    return numbers_text, numbers\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/sales.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/cot_sales.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "        result = round(float(solution), 2)\n",
    "\n",
    "        problem_numbers_text, problem_numbers = nums_extract(problem)\n",
    "        mid_result = round(float(1 + problem_numbers[1] / 100), 2)\n",
    "\n",
    "        if round(problem_numbers[0] * mid_result, 2) != round(float(solution), 2):\n",
    "            print(problem)\n",
    "\n",
    "        cot_solution = \"今年销售额 = 去年销售额 * (1 + 增加比例) = \" + problem_numbers_text[0] + \" * (1 + \" + problem_numbers_text[1] + \"%) = \" + problem_numbers_text[0] + \" * \" + str(mid_result) + \" = \" + str(result) + \"\\n因此，今年的销售额为 \" + str(result) + \" 万元\"\n",
    "\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "simplify_dataset\n",
    "\"\"\"\n",
    "\n",
    "def nums_extract(text):\n",
    "    # 使用正则表达式提取所有数字\n",
    "    numbers_text = re.findall(r'\\d+', text)\n",
    "    # 转换为整数列表\n",
    "    numbers = [int(num) for num in numbers_text]\n",
    "    return numbers_text, numbers\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/simplify.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/cot_simplify.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "\n",
    "        problem_text = problem.split(\"将分数 \")[1].split(\" 进行简化。\")[0]\n",
    "        result = solution.split(\"最简化的形式为：\")[1]\n",
    "\n",
    "        cot_solution = problem_text + \" = \" + problem_text + \"，\" + solution\n",
    "\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "# 后续手动改几个化简结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate_add_dataset\n",
    "\"\"\"\n",
    "\n",
    "def nums_extract(text):\n",
    "    # 使用正则表达式提取所有数字\n",
    "    pattern = r'-?\\d+\\.?\\d*'\n",
    "    numbers_text = re.findall(pattern, text)\n",
    "    numbers = [float(num) for num in numbers_text]\n",
    "    return numbers\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/calculate_add.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/calculate_add.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "        result = solution.split('= ')[1]\n",
    "\n",
    "        s1, s2 = nums_extract(problem)\n",
    "        if s1 >= 0 and s2 >= 0:\n",
    "            cot_data = {\"problem\": problem, \"solution\": solution}\n",
    "        elif s1 >= 0 and s2 < 0:\n",
    "            cot_solution = str(s1) + \" + \" + str(s2) + \" = \" + str(s1) + \" - \" + str(-s2) + \" = \" + result\n",
    "            cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        elif s1 < 0 and s2 >= 0:\n",
    "            cot_solution = str(s1) + \" + \" + str(s2) + \" = \" + str(s2) + \" - \" + str(-s1) + \" = \" + result\n",
    "            cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        elif s1 < 0 and s2 < 0:\n",
    "            cot_solution = str(s1) + \" + \" + str(s2) + \" = -(\" + str(-s1) + \" + \" + str(-s2) + \") = \" + result\n",
    "            cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate_sub_dataset\n",
    "\"\"\"\n",
    "\n",
    "def nums_extract(text):\n",
    "    # 使用正则表达式提取所有数字\n",
    "    pattern = r'-?\\d+\\.?\\d*'\n",
    "    numbers_text = re.findall(pattern, text)\n",
    "    numbers = [float(num) for num in numbers_text]\n",
    "    return numbers\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/calculate_sub.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/calculate_sub.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "        result = solution.split('= ')[1]\n",
    "\n",
    "        s1, s2 = nums_extract(problem)\n",
    "        if s1 >= 0 and s2 >= 0:\n",
    "            cot_data = {\"problem\": problem, \"solution\": solution}\n",
    "        elif s1 >= 0 and s2 < 0:\n",
    "            cot_solution = str(s1) + \" - \" + str(s2) + \" = \" + str(s1) + \" + \" + str(-s2) + \" = \" + result\n",
    "            cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        elif s1 < 0 and s2 >= 0:\n",
    "            cot_solution = str(s1) + \" - \" + str(s2) + \" = -(\" + str(-s1) + \" + \" + str(s2) + \") = \" + result\n",
    "            cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        elif s1 < 0 and s2 < 0:\n",
    "            cot_solution = str(s1) + \" - \" + str(s2) + \" = \" + str(-s2) + \" - \" + str(-s1) + \" = \" + result\n",
    "            cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate_mul_dataset\n",
    "保留两位小数\n",
    "\"\"\"\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/calculate_mul.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/calculate_mul.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "        result = round(float(solution.split('= ')[1]), 2)\n",
    "\n",
    "        cot_solution = solution.split('= ')[0] + \"= \" + str(result)\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate_div_dataset\n",
    "保留两位小数\n",
    "\"\"\"\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/calculate_div.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/calculate_div.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "        result = round(float(solution.split('= ')[1]), 2)\n",
    "\n",
    "        cot_solution = solution.split('= ')[0] + \"= \" + str(result)\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate_sqrt_dataset\n",
    "保留两位小数\n",
    "\"\"\"\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/calculate_sqrt.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/calculate_sqrt.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "        result = round(float(solution.split('= ')[1]), 2)\n",
    "\n",
    "        cot_solution = solution.split('= ')[0] + \"= \" + str(result)\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate_pow_dataset\n",
    "保留两位小数\n",
    "\"\"\"\n",
    "\n",
    "path = \"/home/ma-user/work/dataset/calculate_pow.json\"\n",
    "output_path = \"/home/ma-user/work/dataset/calculate_pow.json\"\n",
    "data_list = []\n",
    "with open(path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        problem = data['problem']\n",
    "        solution = data['solution']\n",
    "        result = round(float(solution.split('= ')[1]), 2)\n",
    "\n",
    "        cot_solution = solution.split('= ')[0] + \"= \" + str(result)\n",
    "        cot_data = {\"problem\": problem, \"solution\": cot_solution}\n",
    "        data_list.append(cot_data)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for item in data_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 采样构建训练集&验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "train_path = \"/home/ma-user/work/train_dataset.json\"\n",
    "val_path = \"/home/ma-user/work/val_dataset.json\"\n",
    "area_path = \"/home/ma-user/work/dataset/cot_area.json\"\n",
    "average_path = \"/home/ma-user/work/dataset/cot_average.json\"\n",
    "calculate_add_path = \"/home/ma-user/work/dataset/cot_calculate_add.json\"\n",
    "calculate_sub_path = \"/home/ma-user/work/dataset/cot_calculate_sub.json\"\n",
    "calculate_mul_path = \"/home/ma-user/work/dataset/cot_calculate_mul.json\"\n",
    "calculate_div_path = \"/home/ma-user/work/dataset/cot_calculate_div.json\"\n",
    "calculate_sqrt_path = \"/home/ma-user/work/dataset/cot_calculate_sqrt.json\"\n",
    "calculate_pow_path = \"/home/ma-user/work/dataset/cot_calculate_pow.json\"\n",
    "en_path = \"/home/ma-user/work/dataset/en.json\"\n",
    "equation_path = \"/home/ma-user/work/dataset/cot_equation.json\"\n",
    "function_path = \"/home/ma-user/work/dataset/cot_function.json\"\n",
    "product_path = \"/home/ma-user/work/dataset/cot_product.json\"\n",
    "quality_path = \"/home/ma-user/work/dataset/cot_quality.json\"\n",
    "sales_path = \"/home/ma-user/work/dataset/cot_sales.json\"\n",
    "simplify_path = \"/home/ma-user/work/dataset/cot_simplify.json\"\n",
    "\n",
    "dataset_path_list_1 = [area_path, calculate_add_path, calculate_sub_path, calculate_mul_path, calculate_div_path, calculate_sqrt_path, calculate_pow_path, en_path, product_path, sales_path]\n",
    "\n",
    "dataset_path_list_2 = [average_path, equation_path, function_path]\n",
    "\n",
    "train_list = []\n",
    "val_list = []\n",
    "for file_path in dataset_path_list_1:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        i = 0\n",
    "        for line in file:\n",
    "            data = json.loads(line.strip())\n",
    "            i += 1\n",
    "            if i <= 6000:\n",
    "                train_list.append(data)\n",
    "            elif i > 6000 and i <= 6100:\n",
    "                val_list.append(data)\n",
    "\n",
    "for file_path in dataset_path_list_2:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        i = 0\n",
    "        for line in file:\n",
    "            data = json.loads(line.strip())\n",
    "            i += 1\n",
    "            if i <= 12000:\n",
    "                train_list.append(data)\n",
    "            elif i > 12000 and i <= 12100:\n",
    "                val_list.append(data)\n",
    "\n",
    "with open(quality_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        for i in range(10):\n",
    "            train_list.append(data)\n",
    "        val_list.append(data)\n",
    "\n",
    "with open(simplify_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line.strip())\n",
    "        for i in range(10):\n",
    "            train_list.append(data)\n",
    "        val_list.append(data)\n",
    "\n",
    "val_list = val_list[:1440]\n",
    "random.shuffle(train_list)\n",
    "# random.shuffle(val_list)\n",
    "\n",
    "with open(train_path, 'w', encoding='utf-8') as file:\n",
    "    for item in train_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')\n",
    "\n",
    "with open(val_path, 'w', encoding='utf-8') as file:\n",
    "    for item in val_list:\n",
    "        json.dump(item, file, ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kalman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
