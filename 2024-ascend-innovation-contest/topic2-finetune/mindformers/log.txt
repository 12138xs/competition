2024-06-05 15:59:42,124 - mindformers[mindformers/tools/utils.py:153] - INFO - set output path to '/home/ma-user/work/mindformers/output'
2024-06-05 15:59:42,145 - mindformers[mindformers/trainer/trainer.py:919] - INFO - Load configs in /home/ma-user/work/mindformers/configs/general/run_general_task.yaml to build trainer.
2024-06-05 15:59:42,145 - mindformers[mindformers/trainer/trainer.py:949] - INFO - ..........Init Config..........
2024-06-05 15:59:42,146 - mindformers[mindformers/core/parallel_config.py:45] - INFO - initial recompute_config from dict: {'recompute': False, 'select_recompute': False, 'parallel_optimizer_comm_recompute': False, 'mp_comm_recompute': True, 'recompute_slice_activation': True}
2024-06-05 15:59:42,146 - mindformers[mindformers/core/parallel_config.py:51] - INFO - initial parallel_config from dict: {'data_parallel': 1, 'model_parallel': 1, 'pipeline_stage': 1, 'use_seq_parallel': False, 'micro_batch_num': 1, 'vocab_emb_dp': True, 'gradient_aggregation_group': 4}
2024-06-05 15:59:42,146 - mindformers[mindformers/tools/utils.py:153] - INFO - set output path to '/home/ma-user/work/mindformers/output'
2024-06-05 15:59:42,147 - mindformers[mindformers/tools/utils.py:168] - INFO - set strategy path to './output/strategy/ckpt_strategy_rank_0.ckpt'
2024-06-05 15:59:42,147 - mindformers[mindformers/trainer/base_trainer.py:85] - INFO - Now Running Task is: text_generation, Model is: llama3_8b
2024-06-05 15:59:42,147 - mindformers[mindformers/trainer/base_trainer.py:111] - WARNING - Input model name is not in the supported list or unspecified.
2024-06-05 15:59:42,147 - mindformers[mindformers/trainer/base_trainer.py:112] - WARNING - See the list of supported task and model name: ['baichuan2_13b', 'baichuan2_7b', 'baichuan_7b', 'bloom_176b', 'bloom_560m', 'bloom_65b', 'bloom_7.1b', 'codegeex2_6b', 'codellama_34b', 'common', 'deepseek_33b', 'glm2_6b', 'glm2_6b_lora', 'glm2_6b_ptuning2', 'glm3_6b', 'glm_6b', 'glm_6b_chat', 'glm_6b_lora', 'glm_6b_lora_chat', 'gpt2', 'gpt2_13b', 'gpt2_52b', 'gpt2_lora', 'gpt2_xl', 'gpt2_xl_lora', 'internlm_7b', 'internlm_7b_lora', 'llama2_13b', 'llama2_70b', 'llama2_7b', 'llama_13b', 'llama_65b', 'llama_7b', 'llama_7b_lora', 'pangualpha_13b', 'pangualpha_2_6b', 'qwen_7b', 'qwen_7b_lora', 'skywork_13b', 'yi_34b', 'yi_6b', 'ziya_13b']
2024-06-05 15:59:42,148 - mindformers[mindformers/trainer/base_trainer.py:113] - WARNING - The default model config: /home/ma-user/work/mindformers/configs/gpt2/run_gpt2.yaml will now be used for the text_generation task 
2024-06-05 15:59:42,148 - mindformers[mindformers/trainer/trainer.py:1004] - INFO - ..........Init Model..........
2024-06-05 15:59:42,148 - mindformers[mindformers/trainer/trainer.py:335] - INFO - ==========Trainer Init Success!==========
2024-06-05 15:59:42,148 - mindformers[mindformers/trainer/trainer.py:1004] - INFO - ..........Init Model..........
2024-06-05 15:59:42,148 - mindformers[mindformers/trainer/base_trainer.py:213] - INFO - The current parallel mode is stand_alone, batch size per card will not be changed: batch_size_per_card = 1
2024-06-05 15:59:42,149 - mindformers[mindformers/trainer/base_trainer.py:217] - INFO - global_batch_size = batch_size_per_card * device_num * gradient_accumulation_steps = 1 = 1 * 1 * 1
2024-06-05 15:59:42,149 - mindformers[mindformers/trainer/base_trainer.py:226] - INFO - parallel_config will be change to default config: [ParallelConfig]
_recompute:[ParallelConfig]
_recompute:False
_select_recompute:False
_select_comm_recompute:False
_parallel_optimizer_comm_recompute:False
_mp_comm_recompute:True
_recompute_slice_activation:True

select_recompute:False
use_seq_parallel:False
_optimizer_shard:None
_gradient_aggregation_group:4
_embed_dp_mp_config:[ParallelConfig]
_dp_mp_config:[ParallelConfig]
_data_parallel:1
_model_parallel:1
use_seq_parallel:False
select_recompute:False

_vocab_emb_dp:True
use_seq_parallel:False
select_recompute:False

_pp_config:[ParallelConfig]
_pipeline_stage:1
_micro_batch_num:1

_moe_config:[ParallelConfig]
_dpmp:[ParallelConfig]
_data_parallel:1
_model_parallel:1
use_seq_parallel:False
select_recompute:False

_expert_parallel:1
use_seq_parallel:False
select_recompute:False

.
2024-06-05 15:59:42,149 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:193] - INFO - .........Build Dataset For Evaluate..........
2024-06-05 15:59:42,149 - mindformers[mindformers/trainer/base_trainer.py:360] - INFO - .........Build Dataset From Config..........
2024-06-05 15:59:42,150 - mindformers[mindformers/trainer/base_trainer.py:379] - INFO - For evaluate phase, batch size for eval dataset is 1, different from training, not multiplied by micro_batch_num, micro_batch_interleave_num and gradient_accumulation_steps
2024-06-05 15:59:42,150 - mindformers[mindformers/dataset/causal_language_model_dataset.py:166] - INFO - Now Create Causal Language Model Dataset.
2024-06-05 15:59:42,156 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:196] - INFO - Create evaluate dataset finish, dataset size:2067
2024-06-05 15:59:42,159 - mindformers[mindformers/trainer/base_trainer.py:387] - INFO - .........Build Network From Config..........
2024-06-05 15:59:42,160 - mindformers[mindformers/version_control.py:61] - INFO - The Cell Reuse compilation acceleration feature is not supported when the environment variable ENABLE_CELL_REUSE is 0 or MindSpore version is earlier than 2.1.0 or stand_alone mode or pipeline_stages <= 1
2024-06-05 15:59:42,160 - mindformers[mindformers/version_control.py:65] - INFO - 
The current ENABLE_CELL_REUSE=0, please set the environment variable as follows: 
export ENABLE_CELL_REUSE=1 to enable the Cell Reuse compilation acceleration feature.
2024-06-05 15:59:42,160 - mindformers[mindformers/version_control.py:71] - INFO - The Cell Reuse compilation acceleration feature does not support single-card mode.This feature is disabled by default. ENABLE_CELL_REUSE=1 does not take effect.
2024-06-05 15:59:42,160 - mindformers[mindformers/version_control.py:74] - INFO - The Cell Reuse compilation acceleration feature only works in pipeline parallel mode(pipeline_stage>1).Current pipeline stage=1, the feature is disabled by default.
2024-06-05 16:00:18,721 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-06-05 16:00:21,719 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-06-05 16:00:24,720 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-06-05 16:00:27,499 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-06-05 16:00:30,370 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-06-05 16:00:33,325 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-06-05 16:00:36,206 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-06-05 16:00:39,008 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-06-05 16:00:41,819 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-06-05 16:00:44,807 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-06-05 16:01:54,806 - mindformers[mindformers/models/modeling_utils.py:1438] - INFO - model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None.
2024-06-05 16:01:54,806 - mindformers[mindformers/models/modeling_utils.py:591] - INFO - Set jit config for jit level:O0 and infer boost:on.
2024-06-05 16:01:54,826 - mindformers[mindformers/trainer/base_trainer.py:543] - INFO - Network Parameters: 8030 M.
2024-06-05 16:01:54,827 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:210] - INFO - .........Build Compute Metrics For Evaluate..........
2024-06-05 16:01:54,827 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:217] - INFO - .........Build tokenizer For Evaluate..........
2024-06-05 16:01:55,890 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:221] - INFO - .........Starting Init Evaluate Model..........
2024-06-05 16:01:55,891 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:228] - INFO - .............Start load checkpoint for eval..................
2024-06-05 16:01:55,930 - mindformers[mindformers/trainer/utils.py:736] - INFO - ............Start load checkpoint from checkpoint............
2024-06-05 16:15:24,764 - mindformers[mindformers/trainer/utils.py:767] - INFO - Network parameters are not loaded: (['model.layers.0.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.0.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.value_cache'], [])
2024-06-05 16:15:24,767 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:236] - INFO - .........Starting Evaluate Model..........
{'auto_trans_ckpt': False,
 'auto_tune': False,
 'autotune_per_step': 10,
 'callbacks': [OrderedDict([('type', 'MFLossMonitor')]),
               OrderedDict([('type', 'CheckpointMointor'),
                            ('prefix', 'llama3_8b'),
                            ('save_checkpoint_steps', 10000),
                            ('integrated_save', False),
                            ('async_save', False)]),
               OrderedDict([('type', 'ObsMonitor')])],
 'context': {'device_id': 0,
             'device_target': 'Ascend',
             'enable_graph_kernel': False,
             'graph_kernel_flags': '--disable_expand_ops=Softmax,Dropout '
                                   '--enable_parallel_fusion=true '
                                   '--reduce_fuse_depth=8 '
                                   '--enable_auto_tensor_inplace=true',
             'max_call_depth': 10000,
             'runtime_num_threads': 1,
             'save_graphs': False,
             'save_graphs_path': './graph'},
 'device_num': 1,
 'do_eval': False,
 'eval_callbacks': [OrderedDict([('type', 'ObsMonitor')])],
 'eval_dataset': {'auto_tune': False,
                  'autotune_per_step': 10,
                  'batch_size': 1,
                  'data_loader': {'dataset_dir': '/home/ma-user/work/squad8192.mindrecord',
                                  'shuffle': False,
                                  'type': 'MindDataset'},
                  'do_eval': True,
                  'drop_remainder': False,
                  'filepath_prefix': './autotune',
                  'input_columns': ['input_ids', 'labels'],
                  'num_parallel_workers': 8,
                  'numa_enable': False,
                  'output_columns': ['input_ids', 'labels'],
                  'prefetch_size': 1,
                  'profile': False,
                  'python_multiprocessing': False,
                  'repeat': 1,
                  'seed': 0},
 'eval_dataset_task': {'dataset_config': {'auto_tune': False,
                                          'autotune_per_step': 10,
                                          'batch_size': 1,
                                          'data_loader': {'dataset_dir': '/home/ma-user/work/squad8192.mindrecord',
                                                          'shuffle': False,
                                                          'type': 'MindDataset'},
                                          'do_eval': True,
                                          'drop_remainder': False,
                                          'filepath_prefix': './autotune',
                                          'input_columns': ['input_ids',
                                                            'labels'],
                                          'num_parallel_workers': 8,
                                          'numa_enable': False,
                                          'output_columns': ['input_ids',
                                                             'labels'],
                                          'prefetch_size': 1,
                                          'profile': False,
                                          'python_multiprocessing': False,
                                          'repeat': 1,
                                          'seed': 0},
                       'type': 'CausalLanguageModelDataset'},
 'filepath_prefix': './autotune',
 'init_start_profile': False,
 'layer_decay': 0.65,
 'layer_scale': False,
 'load_checkpoint': '/home/ma-user/work/llama3-8B.ckpt',
 'local_rank': 0,
 'lr_scale_factor': 256,
 'lr_schedule': {'learning_rate': 5e-05,
                 'lr_end': 0.0,
                 'total_steps': -1,
                 'type': 'CosineWithWarmUpLR',
                 'warmup_ratio': 0.03},
 'metric': [{'type': 'EmF1Metric'}],
 'micro_batch_interleave_num': 1,
 'model': {'arch': {'type': 'LlamaForCausalLM'},
           'model_config': {'batch_size': 1,
                            'bos_token_id': 128000,
                            'checkpoint_name_or_path': None,
                            'compute_dtype': 'float16',
                            'do_sample': False,
                            'eos_token_id': 128001,
                            'extend_method': 'None',
                            'fine_grain_interleave': 1,
                            'hidden_size': 4096,
                            'ignore_token_id': -100,
                            'intermediate_size': 14336,
                            'layernorm_compute_type': 'float32',
                            'max_decode_length': 700,
                            'max_new_tokens': 20,
                            'n_kv_heads': 8,
                            'num_heads': 32,
                            'num_layers': 32,
                            'offset': 0,
                            'pad_token_id': 128002,
                            'param_init_type': 'float16',
                            'repetition_penalty': 1,
                            'rms_norm_eps': 1e-05,
                            'rotary_dtype': 'float32',
                            'scaling_factor': 1.0,
                            'seq_length': 8192,
                            'softmax_compute_type': 'float32',
                            'theta': 500000,
                            'top_k': 3,
                            'top_p': 1,
                            'type': 'LlamaConfig',
                            'use_flash_attention': False,
                            'use_past': True,
                            'vocab_size': 128256}},
 'moe_config': <mindformers.modules.transformer.moe.MoEConfig object at 0xfffe8a795e20>,
 'only_save_strategy': False,
 'optimizer': {'beta1': 0.9,
               'beta2': 0.95,
               'eps': 1e-08,
               'learning_rate': 5e-05,
               'type': 'FP32StateAdamWeightDecay'},
 'output_dir': './output',
 'parallel': {'enable_alltoall': False,
              'enable_parallel_optimizer': False,
              'full_batch': True,
              'gradients_mean': False,
              'parallel_mode': 1,
              'parallel_optimizer_config': {'gradient_accumulation_shard': False,
                                            'parallel_optimizer_threshold': 64},
              'search_mode': 'sharding_propagation',
              'strategy_ckpt_save_file': './output/strategy/ckpt_strategy_rank_0.ckpt'},
 'parallel_config': <mindformers.modules.transformer.transformer.TransformerOpParallelConfig object at 0xfffe8b0c1fa0>,
 'processor': {'return_tensors': 'ms',
               'tokenizer': {'model_max_length': 8192,
                             'pad_token': '<|reserved_special_token_0|>',
                             'type': 'Llama3Tokenizer',
                             'vocab_file': '/home/ma-user/work/tokenizer.model'},
               'type': 'LlamaProcessor'},
 'profile': False,
 'profile_communication': False,
 'profile_memory': True,
 'profile_start_step': 4,
 'profile_stop_step': 8,
 'rank_id': 0,
 'recompute_config': <mindformers.modules.transformer.transformer.TransformerRecomputeConfig object at 0xfffdf06adac0>,
 'remote_save_url': 'Please input obs url on AICC platform.',
 'resume_training': False,
 'run_mode': 'eval',
 'runner_config': {'batch_size': 1,
                   'epochs': 1,
                   'gradient_accumulation_steps': 1,
                   'sink_mode': True,
                   'sink_size': 2},
 'runner_wrapper': {'scale_sense': 1.0,
                    'type': 'MFTrainOneStepCell',
                    'use_clip_grad': True},
 'seed': 0,
 'src_strategy_path_or_dir': '',
 'train_dataset': {'auto_tune': False,
                   'autotune_per_step': 10,
                   'batch_size': 1,
                   'data_loader': {'dataset_dir': '',
                                   'shuffle': True,
                                   'type': 'MindDataset'},
                   'do_eval': False,
                   'drop_remainder': True,
                   'filepath_prefix': './autotune',
                   'input_columns': ['input_ids'],
                   'num_parallel_workers': 8,
                   'numa_enable': False,
                   'output_columns': ['input_ids'],
                   'prefetch_size': 1,
                   'profile': False,
                   'python_multiprocessing': False,
                   'repeat': 1,
                   'seed': 0},
 'train_dataset_task': {'dataset_config': {'auto_tune': False,
                                           'autotune_per_step': 10,
                                           'batch_size': 1,
                                           'data_loader': {'dataset_dir': '',
                                                           'shuffle': True,
                                                           'type': 'MindDataset'},
                                           'do_eval': False,
                                           'drop_remainder': True,
                                           'filepath_prefix': './autotune',
                                           'input_columns': ['input_ids'],
                                           'num_parallel_workers': 8,
                                           'numa_enable': False,
                                           'output_columns': ['input_ids'],
                                           'prefetch_size': 1,
                                           'profile': False,
                                           'python_multiprocessing': False,
                                           'repeat': 1,
                                           'seed': 0},
                        'type': 'CausalLanguageModelDataset'},
 'trainer': {'model_name': 'llama3_8b',
             'type': 'CausalLanguageModelingTrainer'},
 'use_parallel': False}
2024-06-05 16:15:24,823 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:15:24,823 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 214, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:15:24,824 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:15:24,824 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:15:24,825 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:15:53,778 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:15:54,004 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 29.17860746383667 s; generated tokens: 1 tokens; generate speed: 0.03427168350098195 tokens/s
2024-06-05 16:15:54,009 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:15:54,010 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1/2067], cost time 29.1962s, every example cost time is 29.1962, generate speed: 0.0343 tokens/s, avg speed: 0.0000 tokens/s, remaining time: 0:00:00
pred is:
 ['']
 label is:
 ['Denver Broncos']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:15:55,414 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:15:55,415 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 182, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:15:55,415 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:15:55,416 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:15:55,416 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:15:56,357 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:15:56,359 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430456161499023 s; generated tokens: 1 tokens; generate speed: 1.0603940921570907 tokens/s
2024-06-05 16:15:56,364 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:15:56,364 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[2/2067], cost time 0.9561s, every example cost time is 0.9561, generate speed: 1.0460 tokens/s, avg speed: 1.0459 tokens/s, remaining time: 0:16:27
pred is:
 ['']
 label is:
 ['Cam Newton']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:15:56,451 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:15:56,451 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 120, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:15:56,452 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:15:56,452 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:15:56,452 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:15:57,392 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:15:57,394 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414165019989014 s; generated tokens: 1 tokens; generate speed: 1.0622290961298309 tokens/s
2024-06-05 16:15:57,398 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:15:57,399 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[3/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.0477 tokens/s, remaining time: 0:21:53
pred is:
 ['']
 label is:
 ['Von Miller']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:15:57,480 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:15:57,480 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 141, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:15:57,480 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:15:57,481 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:15:57,481 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:15:58,420 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:15:58,422 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411616325378418 s; generated tokens: 1 tokens; generate speed: 1.0625167510319142 tokens/s
2024-06-05 16:15:58,427 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:15:58,427 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[4/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.0486 tokens/s, remaining time: 0:24:35
pred is:
 ['']
 label is:
 ['CBS']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:15:58,508 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:15:58,508 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 93, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:15:58,508 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:15:58,508 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:15:58,509 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:15:59,448 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:15:59,449 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404628276824951 s; generated tokens: 1 tokens; generate speed: 1.063306247269993 tokens/s
2024-06-05 16:15:59,454 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:15:59,454 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[5/2067], cost time 0.9512s, every example cost time is 0.9512, generate speed: 1.0513 tokens/s, avg speed: 1.0493 tokens/s, remaining time: 0:26:12
pred is:
 ['']
 label is:
 ['Roger Goodell']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:15:59,535 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:15:59,535 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 89, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:15:59,536 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:15:59,536 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:15:59,536 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:00,475 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:00,477 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9406309127807617 s; generated tokens: 1 tokens; generate speed: 1.0631162408257742 tokens/s
2024-06-05 16:16:00,482 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:00,482 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[6/2067], cost time 0.9515s, every example cost time is 0.9515, generate speed: 1.0510 tokens/s, avg speed: 1.0496 tokens/s, remaining time: 0:27:16
pred is:
 ['']
 label is:
 ["New Orleans' Mercedes-Benz Superdome"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:00,569 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:00,569 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 196, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:00,570 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:00,570 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:00,570 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:01,511 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:01,513 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430873394012451 s; generated tokens: 1 tokens; generate speed: 1.0603471791222308 tokens/s
2024-06-05 16:16:01,518 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:01,518 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[7/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0477 tokens/s, avg speed: 1.0493 tokens/s, remaining time: 0:28:02
pred is:
 ['']
 label is:
 ['October 16, 2012']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:01,600 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:01,601 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 138, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:01,601 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:01,601 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:01,601 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:02,541 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:02,543 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941185712814331 s; generated tokens: 1 tokens; generate speed: 1.0624895664956522 tokens/s
2024-06-05 16:16:02,547 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:02,548 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[8/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.0495 tokens/s, remaining time: 0:28:36
pred is:
 ['']
 label is:
 ['May 21, 2013']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:02,629 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:02,629 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 202, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:02,630 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:02,630 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:02,630 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:03,571 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:03,573 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423666000366211 s; generated tokens: 1 tokens; generate speed: 1.061158152210763 tokens/s
2024-06-05 16:16:03,577 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:03,578 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[9/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.0494 tokens/s, remaining time: 0:29:03
pred is:
 ['']
 label is:
 ['John Fox']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:03,664 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:03,665 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 235, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:03,665 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:03,665 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:03,665 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:04,607 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:04,609 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435842037200928 s; generated tokens: 1 tokens; generate speed: 1.0597888307768266 tokens/s
2024-06-05 16:16:04,614 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:04,614 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[10/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0473 tokens/s, avg speed: 1.0492 tokens/s, remaining time: 0:29:24
pred is:
 ['']
 label is:
 ['DeAngelo Williams']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 0.0, Em score: 0.0, current_count: 10
2024-06-05 16:16:04,697 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:04,697 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 335, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:04,698 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:04,698 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:04,698 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:05,641 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:05,643 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445366859436035 s; generated tokens: 1 tokens; generate speed: 1.0587201268958526 tokens/s
2024-06-05 16:16:05,647 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:05,648 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[11/2067], cost time 0.9554s, every example cost time is 0.9554, generate speed: 1.0467 tokens/s, avg speed: 1.0489 tokens/s, remaining time: 0:29:41
pred is:
 ['']
 label is:
 ['six']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:05,729 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:05,729 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 298, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:05,730 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:05,730 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:05,730 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:06,672 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:06,674 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438552856445312 s; generated tokens: 1 tokens; generate speed: 1.0594844519169369 tokens/s
2024-06-05 16:16:06,679 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:06,679 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[12/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.0488 tokens/s, remaining time: 0:29:56
pred is:
 ['']
 label is:
 ['308']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:06,760 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:06,761 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 470, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:06,761 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:06,761 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:06,761 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:07,706 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:07,707 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9459891319274902 s; generated tokens: 1 tokens; generate speed: 1.0570945968083802 tokens/s
2024-06-05 16:16:07,712 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:07,712 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[13/2067], cost time 0.9570s, every example cost time is 0.9570, generate speed: 1.0450 tokens/s, avg speed: 1.0484 tokens/s, remaining time: 0:30:08
pred is:
 ['']
 label is:
 ['Gary Kubiak']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:07,799 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:07,799 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 271, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:07,800 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:07,800 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:07,800 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:08,742 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:08,744 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436767101287842 s; generated tokens: 1 tokens; generate speed: 1.0596849421700036 tokens/s
2024-06-05 16:16:08,749 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:08,749 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[14/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0474 tokens/s, avg speed: 1.0484 tokens/s, remaining time: 0:30:18
pred is:
 ['']
 label is:
 ['67.9']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:08,830 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:08,830 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 208, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:08,831 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:08,831 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:08,831 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:09,772 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:09,774 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426405429840088 s; generated tokens: 1 tokens; generate speed: 1.0608497665869696 tokens/s
2024-06-05 16:16:09,779 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:09,779 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[15/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.0484 tokens/s, remaining time: 0:30:26
pred is:
 ['']
 label is:
 ['4,530']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:09,860 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:09,860 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 131, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:09,861 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:09,861 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:09,861 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:10,801 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:10,802 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410502910614014 s; generated tokens: 1 tokens; generate speed: 1.0626424639560015 tokens/s
2024-06-05 16:16:10,807 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:10,807 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[16/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.0485 tokens/s, remaining time: 0:30:33
pred is:
 ['']
 label is:
 ['Seattle Seahawks']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:10,895 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:10,895 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 149, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:10,896 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:10,896 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:10,896 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:11,836 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:11,838 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941502571105957 s; generated tokens: 1 tokens; generate speed: 1.0621319905959765 tokens/s
2024-06-05 16:16:11,842 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:11,842 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[17/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.0486 tokens/s, remaining time: 0:30:40
pred is:
 ['']
 label is:
 ['Pittsburgh Steelers']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:11,925 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:11,925 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 114, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:11,925 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:11,926 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:11,926 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:12,865 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:12,867 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411098957061768 s; generated tokens: 1 tokens; generate speed: 1.0625751621171022 tokens/s
2024-06-05 16:16:12,872 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:12,872 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[18/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.0487 tokens/s, remaining time: 0:30:45
pred is:
 ['']
 label is:
 ['Thomas Davis']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:12,954 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:12,954 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 131, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:12,955 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:12,955 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:12,955 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:13,895 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:13,896 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410262107849121 s; generated tokens: 1 tokens; generate speed: 1.062669656316903 tokens/s
2024-06-05 16:16:13,901 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:13,901 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[19/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0506 tokens/s, avg speed: 1.0488 tokens/s, remaining time: 0:30:49
pred is:
 ['']
 label is:
 ['39']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:13,983 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:13,983 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:13,983 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:13,983 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:13,984 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:14,924 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:14,926 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421799182891846 s; generated tokens: 1 tokens; generate speed: 1.0613684080804922 tokens/s
2024-06-05 16:16:14,931 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:14,931 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[20/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.0488 tokens/s, remaining time: 0:30:54
pred is:
 ['']
 label is:
 ['1998']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 0.0, Em score: 0.0, current_count: 20
2024-06-05 16:16:15,020 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:15,021 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 105, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:15,022 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:15,022 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:15,022 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:15,961 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:15,963 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409730434417725 s; generated tokens: 1 tokens; generate speed: 1.0627296998246902 tokens/s
2024-06-05 16:16:15,968 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:15,968 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[21/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.0488 tokens/s, remaining time: 0:30:57
pred is:
 ['']
 label is:
 ['Super Bowl XX']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:16,050 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:16,050 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 244, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:16,051 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:16,051 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:16,051 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:16,992 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:16,994 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430875778198242 s; generated tokens: 1 tokens; generate speed: 1.0603469110596735 tokens/s
2024-06-05 16:16:16,999 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:16,999 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[22/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.0488 tokens/s, remaining time: 0:31:01
pred is:
 ['']
 label is:
 ['Justin Tucker']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:17,081 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:17,081 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 273, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:17,082 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:17,082 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:17,082 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:18,024 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:18,026 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438784122467041 s; generated tokens: 1 tokens; generate speed: 1.0594584927731425 tokens/s
2024-06-05 16:16:18,031 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:18,031 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[23/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0473 tokens/s, avg speed: 1.0487 tokens/s, remaining time: 0:31:04
pred is:
 ['']
 label is:
 ['Broncos']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:18,112 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:18,112 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 80, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:18,112 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:18,112 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:18,113 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:19,051 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:19,053 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9401295185089111 s; generated tokens: 1 tokens; generate speed: 1.0636832269515866 tokens/s
2024-06-05 16:16:19,057 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:19,058 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[24/2067], cost time 0.9510s, every example cost time is 0.9510, generate speed: 1.0515 tokens/s, avg speed: 1.0488 tokens/s, remaining time: 0:31:06
pred is:
 ['']
 label is:
 ['San Jose State']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:19,139 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:19,139 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 220, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:19,140 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:19,140 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:19,140 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:20,081 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:20,084 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434583187103271 s; generated tokens: 1 tokens; generate speed: 1.0599302376886806 tokens/s
2024-06-05 16:16:20,088 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:20,089 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[25/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.0488 tokens/s, remaining time: 0:31:09
pred is:
 ['']
 label is:
 ['June 4, 2014']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:20,170 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:20,170 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 165, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:20,170 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:20,171 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:20,171 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:21,111 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:21,113 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417715072631836 s; generated tokens: 1 tokens; generate speed: 1.0618286838025395 tokens/s
2024-06-05 16:16:21,117 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:21,118 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[26/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.0488 tokens/s, remaining time: 0:31:11
pred is:
 ['']
 label is:
 ['gold']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:21,199 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:21,199 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:21,199 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:21,200 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:21,200 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:22,140 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:22,142 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419829845428467 s; generated tokens: 1 tokens; generate speed: 1.0615903008962626 tokens/s
2024-06-05 16:16:22,147 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:22,147 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[27/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.0489 tokens/s, remaining time: 0:31:12
pred is:
 ['']
 label is:
 ['Moscone Center']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:22,234 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:22,234 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 145, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:22,234 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:22,235 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:22,235 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:23,175 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:23,177 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416759014129639 s; generated tokens: 1 tokens; generate speed: 1.0619364884452518 tokens/s
2024-06-05 16:16:23,181 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:23,181 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[28/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.0489 tokens/s, remaining time: 0:31:14
pred is:
 ['']
 label is:
 ['Santa Clara University']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:23,263 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:23,263 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 130, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:23,263 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:23,263 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:23,264 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:24,203 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:24,205 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411699771881104 s; generated tokens: 1 tokens; generate speed: 1.0625073304905597 tokens/s
2024-06-05 16:16:24,210 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:24,210 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[29/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.0489 tokens/s, remaining time: 0:31:15
pred is:
 ['']
 label is:
 ['Monday']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:24,291 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:24,291 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 137, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:24,291 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:24,292 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:24,292 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:25,232 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:25,234 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419102668762207 s; generated tokens: 1 tokens; generate speed: 1.0616722581402895 tokens/s
2024-06-05 16:16:25,238 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:25,239 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[30/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.0490 tokens/s, remaining time: 0:31:17
pred is:
 ['']
 label is:
 ['Business Connect']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 0.0, Em score: 0.0, current_count: 30
2024-06-05 16:16:25,323 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:25,324 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 123, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:25,324 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:25,324 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:25,324 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:26,264 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:38,157 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:38,195 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:38,233 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:38,235 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 12.910577774047852 s; generated tokens: 4 tokens; generate speed: 0.30982346956157025 tokens/s
2024-06-05 16:16:38,240 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:38,240 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[31/2067], cost time 12.9216s, every example cost time is 12.9216, generate speed: 0.3096 tokens/s, avg speed: 0.8134 tokens/s, remaining time: 0:44:24
pred is:
 ['25%']
 label is:
 ['25']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:38,326 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:38,326 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 130, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:38,327 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:38,327 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:38,327 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:39,266 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:39,268 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404881000518799 s; generated tokens: 1 tokens; generate speed: 1.063277674587097 tokens/s
2024-06-05 16:16:39,273 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:39,273 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[32/2067], cost time 0.9517s, every example cost time is 0.9517, generate speed: 1.0507 tokens/s, avg speed: 0.8189 tokens/s, remaining time: 0:44:00
pred is:
 ['']
 label is:
 ['Vince Lombardi']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:39,359 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:39,360 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 193, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:39,360 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:39,360 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:39,360 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:40,301 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:40,302 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94173264503479 s; generated tokens: 1 tokens; generate speed: 1.0618725020019428 tokens/s
2024-06-05 16:16:40,307 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:40,307 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[33/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 0.8241 tokens/s, remaining time: 0:43:37
pred is:
 ['']
 label is:
 ['CBS']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:40,393 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:40,394 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 214, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:40,394 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:40,394 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:40,395 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:41,335 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:41,336 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417309761047363 s; generated tokens: 1 tokens; generate speed: 1.0618743838460967 tokens/s
2024-06-05 16:16:41,341 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:41,341 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[34/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 0.8290 tokens/s, remaining time: 0:43:16
pred is:
 ['']
 label is:
 ['ESPN Deportes']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:41,428 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:41,428 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 132, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:41,429 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:41,429 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:41,429 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:42,368 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:42,370 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407382011413574 s; generated tokens: 1 tokens; generate speed: 1.062994995618061 tokens/s
2024-06-05 16:16:42,375 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:42,375 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[35/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 0.8337 tokens/s, remaining time: 0:42:56
pred is:
 ['']
 label is:
 ['NFL Mobile']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:42,461 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:42,462 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 122, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:42,462 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:42,462 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:42,463 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:43,402 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:43,404 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410064220428467 s; generated tokens: 1 tokens; generate speed: 1.0626920035562384 tokens/s
2024-06-05 16:16:43,408 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:43,409 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[36/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0500 tokens/s, avg speed: 0.8383 tokens/s, remaining time: 0:42:37
pred is:
 ['']
 label is:
 ['The Late Show with Stephen Colbert']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:43,498 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:43,498 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 256, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:43,499 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:43,499 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:43,499 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:44,443 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:44,445 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9452965259552002 s; generated tokens: 1 tokens; generate speed: 1.057869115714271 tokens/s
2024-06-05 16:16:44,449 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:44,450 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[37/2067], cost time 0.9574s, every example cost time is 0.9574, generate speed: 1.0445 tokens/s, avg speed: 0.8426 tokens/s, remaining time: 0:42:19
pred is:
 ['']
 label is:
 ['$5,000,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:44,536 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:44,536 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 101, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:44,537 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:44,537 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:44,537 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:45,476 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:45,478 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.940467119216919 s; generated tokens: 1 tokens; generate speed: 1.0633013951967307 tokens/s
2024-06-05 16:16:45,482 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:45,483 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[38/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0505 tokens/s, avg speed: 0.8467 tokens/s, remaining time: 0:42:02
pred is:
 ['']
 label is:
 ['"Small Business Big Game"']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:45,569 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:45,569 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 166, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:45,570 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:45,570 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:45,570 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:46,510 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:46,517 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9461631774902344 s; generated tokens: 1 tokens; generate speed: 1.056900145546323 tokens/s
2024-06-05 16:16:46,521 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:46,522 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[39/2067], cost time 0.9576s, every example cost time is 0.9576, generate speed: 1.0443 tokens/s, avg speed: 0.8507 tokens/s, remaining time: 0:41:46
pred is:
 ['']
 label is:
 ['Jason Bourne']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:46,603 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:46,603 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 104, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:46,604 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:46,604 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:46,604 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:47,543 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:47,545 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409627914428711 s; generated tokens: 1 tokens; generate speed: 1.0627412785011416 tokens/s
2024-06-05 16:16:47,550 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:47,550 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[40/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0505 tokens/s, avg speed: 0.8545 tokens/s, remaining time: 0:41:30
pred is:
 ['']
 label is:
 ['Westwood One']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 0.0, Em score: 0.0, current_count: 40
2024-06-05 16:16:47,636 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:47,636 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 259, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:47,637 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:47,637 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:47,637 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:48,578 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:48,580 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428224563598633 s; generated tokens: 1 tokens; generate speed: 1.0606450803695249 tokens/s
2024-06-05 16:16:48,585 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:48,585 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[41/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 0.8582 tokens/s, remaining time: 0:41:15
pred is:
 ['']
 label is:
 ['KRFX']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:48,666 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:48,666 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 96, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:48,666 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:48,667 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:48,667 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:49,605 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:49,607 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.940004825592041 s; generated tokens: 1 tokens; generate speed: 1.0638243259763824 tokens/s
2024-06-05 16:16:49,612 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:49,612 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[42/2067], cost time 0.9509s, every example cost time is 0.9509, generate speed: 1.0516 tokens/s, avg speed: 0.8618 tokens/s, remaining time: 0:41:01
pred is:
 ['']
 label is:
 ['BBC Radio 5']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:49,694 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:49,694 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 167, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:49,695 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:49,695 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:49,695 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:50,635 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:50,637 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413859844207764 s; generated tokens: 1 tokens; generate speed: 1.062263531164943 tokens/s
2024-06-05 16:16:50,641 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:50,641 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[43/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 0.8653 tokens/s, remaining time: 0:40:47
pred is:
 ['']
 label is:
 ['Bart Starr']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:50,722 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:50,722 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 81, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:50,723 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:50,723 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:50,723 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:51,662 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:51,663 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9399454593658447 s; generated tokens: 1 tokens; generate speed: 1.063891516295714 tokens/s
2024-06-05 16:16:51,668 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:51,668 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[44/2067], cost time 0.9508s, every example cost time is 0.9508, generate speed: 1.0517 tokens/s, avg speed: 0.8686 tokens/s, remaining time: 0:40:34
pred is:
 ['']
 label is:
 ['Six']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:51,750 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:51,750 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 174, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:51,751 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:51,751 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:51,751 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:52,691 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:52,693 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413940906524658 s; generated tokens: 1 tokens; generate speed: 1.0622543841409875 tokens/s
2024-06-05 16:16:52,697 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:52,697 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[45/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 0.8718 tokens/s, remaining time: 0:40:22
pred is:
 ['']
 label is:
 ['December 3']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:52,779 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:52,780 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:52,780 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:52,780 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:52,780 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:53,720 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:53,722 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417204856872559 s; generated tokens: 1 tokens; generate speed: 1.0618862127335083 tokens/s
2024-06-05 16:16:53,727 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:53,727 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[46/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 0.8749 tokens/s, remaining time: 0:40:10
pred is:
 ['']
 label is:
 ['Denver']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:53,814 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:53,814 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 200, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:53,814 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:53,815 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:53,815 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:54,755 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:54,757 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422533512115479 s; generated tokens: 1 tokens; generate speed: 1.0612856921274958 tokens/s
2024-06-05 16:16:54,762 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:54,762 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[47/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 0.8779 tokens/s, remaining time: 0:39:58
pred is:
 ['']
 label is:
 ['Mike Carey']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:54,849 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:54,849 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 253, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:54,850 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:54,850 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:54,850 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:55,791 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:55,793 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427187442779541 s; generated tokens: 1 tokens; generate speed: 1.0607617659771034 tokens/s
2024-06-05 16:16:55,797 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:55,798 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[48/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 0.8808 tokens/s, remaining time: 0:39:47
pred is:
 ['']
 label is:
 ['Jonathan Stewart']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:55,884 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:55,885 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 188, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:55,885 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:55,885 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:55,886 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:56,826 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:56,828 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418375492095947 s; generated tokens: 1 tokens; generate speed: 1.061754228039874 tokens/s
2024-06-05 16:16:56,832 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:56,832 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[49/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0493 tokens/s, avg speed: 0.8835 tokens/s, remaining time: 0:39:37
pred is:
 ['']
 label is:
 ['Darian Stewart']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:56,921 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:56,921 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 259, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:56,922 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:56,922 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:56,922 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:57,866 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:57,873 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9505994319915771 s; generated tokens: 1 tokens; generate speed: 1.0519678072023722 tokens/s
2024-06-05 16:16:57,878 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:57,878 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[50/2067], cost time 0.9628s, every example cost time is 0.9628, generate speed: 1.0386 tokens/s, avg speed: 0.8861 tokens/s, remaining time: 0:39:27
pred is:
 ['']
 label is:
 ['Ted Ginn Jr.']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 0.0, Em score: 0.0, current_count: 50
2024-06-05 16:16:57,965 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:57,966 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 167, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:57,966 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:57,966 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:57,966 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:58,906 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:58,907 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407994747161865 s; generated tokens: 1 tokens; generate speed: 1.0629257635392204 tokens/s
2024-06-05 16:16:58,912 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:58,912 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[51/2067], cost time 0.9517s, every example cost time is 0.9517, generate speed: 1.0508 tokens/s, avg speed: 0.8887 tokens/s, remaining time: 0:39:17
pred is:
 ['']
 label is:
 ['Ealy']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:16:58,993 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:16:58,993 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 266, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:16:58,993 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:58,994 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:16:58,994 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:16:59,935 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:16:59,937 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429585933685303 s; generated tokens: 1 tokens; generate speed: 1.0604919527035654 tokens/s
2024-06-05 16:16:59,942 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:16:59,942 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[52/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 0.8912 tokens/s, remaining time: 0:39:07
pred is:
 ['']
 label is:
 ['24']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:00,023 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:00,023 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 316, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:00,024 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:00,024 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:00,024 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:00,966 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:00,968 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943988561630249 s; generated tokens: 1 tokens; generate speed: 1.059334869771113 tokens/s
2024-06-05 16:17:00,973 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:00,973 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[53/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0473 tokens/s, avg speed: 0.8936 tokens/s, remaining time: 0:38:58
pred is:
 ['']
 label is:
 ['five']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:01,054 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:01,055 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 358, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:01,055 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:01,055 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:01,055 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:01,998 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:02,000 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9443626403808594 s; generated tokens: 1 tokens; generate speed: 1.0589152484862194 tokens/s
2024-06-05 16:17:02,005 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:02,005 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[54/2067], cost time 0.9552s, every example cost time is 0.9552, generate speed: 1.0469 tokens/s, avg speed: 0.8960 tokens/s, remaining time: 0:38:49
pred is:
 ['']
 label is:
 ['194']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:02,086 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:02,087 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:02,087 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:02,087 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:02,087 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:03,028 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:03,030 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942267656326294 s; generated tokens: 1 tokens; generate speed: 1.0612695801305465 tokens/s
2024-06-05 16:17:03,034 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:03,035 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[55/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 0.8983 tokens/s, remaining time: 0:38:41
pred is:
 ['']
 label is:
 ['Nobel Prize']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:03,120 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:03,121 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 435, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:03,121 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:03,121 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:03,122 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:04,066 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:04,068 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9461982250213623 s; generated tokens: 1 tokens; generate speed: 1.0568609975752417 tokens/s
2024-06-05 16:17:04,073 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:04,073 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[56/2067], cost time 0.9577s, every example cost time is 0.9577, generate speed: 1.0442 tokens/s, avg speed: 0.9005 tokens/s, remaining time: 0:38:33
pred is:
 ['']
 label is:
 ['100']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:04,159 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:04,160 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 205, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:04,160 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:04,160 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:04,160 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:05,101 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:05,131 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:05,161 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:05,190 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:05,219 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:05,248 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:05,277 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:05,306 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:05,307 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.1463067531585693 s; generated tokens: 8 tokens; generate speed: 6.978934720533182 tokens/s
2024-06-05 16:17:05,312 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:05,312 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[57/2067], cost time 1.1578s, every example cost time is 1.1578, generate speed: 6.9096 tokens/s, avg speed: 1.0066 tokens/s, remaining time: 0:38:32
pred is:
 ['15 kilometres (9 miles)']
 label is:
 ['15 kilometres']
The F1/Em of this example is:  {'F1': 50.0, 'Em': 0.0}
2024-06-05 16:17:05,393 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:05,393 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 215, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:05,393 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:05,393 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:05,394 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:06,334 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:06,336 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420928955078125 s; generated tokens: 1 tokens; generate speed: 1.0614664485512058 tokens/s
2024-06-05 16:17:06,341 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:06,341 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[58/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0494 tokens/s, avg speed: 1.0072 tokens/s, remaining time: 0:38:24
pred is:
 ['']
 label is:
 ['city']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:06,422 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:06,422 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:06,423 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:06,423 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:06,423 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:07,364 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:07,366 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422225952148438 s; generated tokens: 1 tokens; generate speed: 1.0613203345776079 tokens/s
2024-06-05 16:17:07,370 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:07,371 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[59/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.0078 tokens/s, remaining time: 0:38:16
pred is:
 ['']
 label is:
 ['Warsaw University of Technology']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:07,451 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:07,452 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 192, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:07,452 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:07,452 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:07,452 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:08,393 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:08,395 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428329467773438 s; generated tokens: 1 tokens; generate speed: 1.0606332791170021 tokens/s
2024-06-05 16:17:08,400 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:08,400 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[60/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0483 tokens/s, avg speed: 1.0083 tokens/s, remaining time: 0:38:08
pred is:
 ['']
 label is:
 ['1816']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 0.8333333333333334, Em score: 0.0, current_count: 60
2024-06-05 16:17:08,489 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:08,489 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:08,489 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:08,490 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:08,490 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:09,430 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:09,432 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417297840118408 s; generated tokens: 1 tokens; generate speed: 1.0618757280245759 tokens/s
2024-06-05 16:17:09,436 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:09,437 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[61/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.0089 tokens/s, remaining time: 0:38:01
pred is:
 ['']
 label is:
 ['infrastructure']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:09,521 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:09,522 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:09,522 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:09,522 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:09,522 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:10,463 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:10,465 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423971176147461 s; generated tokens: 1 tokens; generate speed: 1.0611237888025906 tokens/s
2024-06-05 16:17:10,470 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:10,470 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[62/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.0094 tokens/s, remaining time: 0:37:54
pred is:
 ['']
 label is:
 ['Warsaw']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:10,551 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:10,552 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 176, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:10,552 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:10,552 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:10,552 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:11,493 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:11,495 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419863224029541 s; generated tokens: 1 tokens; generate speed: 1.0615865392281454 tokens/s
2024-06-05 16:17:11,499 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:11,499 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[63/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.0100 tokens/s, remaining time: 0:37:47
pred is:
 ['']
 label is:
 ['musical']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:11,581 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:11,581 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:11,582 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:11,582 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:11,582 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:12,522 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:12,524 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418315887451172 s; generated tokens: 1 tokens; generate speed: 1.0617609474453766 tokens/s
2024-06-05 16:17:12,529 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:12,529 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[64/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.0105 tokens/s, remaining time: 0:37:40
pred is:
 ['']
 label is:
 ['Ogród Saski']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:12,610 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:12,611 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 216, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:12,611 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:12,611 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:12,611 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:13,553 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:13,555 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431319236755371 s; generated tokens: 1 tokens; generate speed: 1.0602970537810223 tokens/s
2024-06-05 16:17:13,560 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:13,560 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[65/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0481 tokens/s, avg speed: 1.0110 tokens/s, remaining time: 0:37:34
pred is:
 ['']
 label is:
 ['Wianki']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:13,641 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:13,641 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 171, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:13,642 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:13,642 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:13,642 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:14,582 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:14,584 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418230056762695 s; generated tokens: 1 tokens; generate speed: 1.0617706235387157 tokens/s
2024-06-05 16:17:14,589 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:14,589 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[66/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.0115 tokens/s, remaining time: 0:37:28
pred is:
 ['']
 label is:
 ['art posters']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:14,670 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:14,670 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 155, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:14,671 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:14,671 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:14,671 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:15,611 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:15,613 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941704273223877 s; generated tokens: 1 tokens; generate speed: 1.0619044942597007 tokens/s
2024-06-05 16:17:15,618 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:15,618 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[67/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.0120 tokens/s, remaining time: 0:37:21
pred is:
 ['']
 label is:
 ['Warsaw Uprising Museum']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:15,699 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:15,699 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 154, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:15,700 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:15,700 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:15,700 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:16,640 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:16,642 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420208930969238 s; generated tokens: 1 tokens; generate speed: 1.0615475806618981 tokens/s
2024-06-05 16:17:16,647 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:16,647 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[68/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.0124 tokens/s, remaining time: 0:37:15
pred is:
 ['']
 label is:
 ['Royal Ujazdów Castle']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:16,734 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:16,734 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:16,734 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:16,735 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:16,735 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:17,676 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:17,678 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429826736450195 s; generated tokens: 1 tokens; generate speed: 1.0604648716763636 tokens/s
2024-06-05 16:17:17,683 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:17,683 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[69/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0478 tokens/s, avg speed: 1.0129 tokens/s, remaining time: 0:37:09
pred is:
 ['']
 label is:
 ['Polonia Warsaw']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:17,764 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:17,764 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 185, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:17,765 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:17,765 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:17,765 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:18,706 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:18,707 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421563148498535 s; generated tokens: 1 tokens; generate speed: 1.061394998089425 tokens/s
2024-06-05 16:17:18,712 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:18,712 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[70/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.0133 tokens/s, remaining time: 0:37:04
pred is:
 ['']
 label is:
 ['syrenka']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 0.7142857142857143, Em score: 0.0, current_count: 70
2024-06-05 16:17:18,802 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:18,803 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 188, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:18,803 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:18,803 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:18,803 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:19,744 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:19,745 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418327808380127 s; generated tokens: 1 tokens; generate speed: 1.0617596035574723 tokens/s
2024-06-05 16:17:19,750 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:19,750 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[71/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.0137 tokens/s, remaining time: 0:36:58
pred is:
 ['']
 label is:
 ['legend']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:19,836 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:19,837 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 211, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:19,837 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:19,837 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:19,838 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:20,779 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:20,780 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426162242889404 s; generated tokens: 1 tokens; generate speed: 1.0608771356066429 tokens/s
2024-06-05 16:17:20,785 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:20,785 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[72/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0483 tokens/s, avg speed: 1.0142 tokens/s, remaining time: 0:36:53
pred is:
 ['']
 label is:
 ['Warsaw']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:20,866 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:20,866 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 269, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:20,867 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:20,867 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:20,867 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:21,809 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:21,811 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435791969299316 s; generated tokens: 1 tokens; generate speed: 1.0597944541948798 tokens/s
2024-06-05 16:17:21,816 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:21,816 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[73/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0474 tokens/s, avg speed: 1.0146 tokens/s, remaining time: 0:36:47
pred is:
 ['']
 label is:
 ['Economist Intelligence Unit']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:21,896 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:21,897 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 395, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:21,897 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:21,897 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:21,897 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:22,841 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:22,843 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.945439338684082 s; generated tokens: 1 tokens; generate speed: 1.05770931997801 tokens/s
2024-06-05 16:17:22,848 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:22,848 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[74/2067], cost time 0.9563s, every example cost time is 0.9563, generate speed: 1.0457 tokens/s, avg speed: 1.0149 tokens/s, remaining time: 0:36:42
pred is:
 ['']
 label is:
 ['1313']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:22,929 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:22,930 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 233, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:22,930 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:22,930 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:22,931 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:23,872 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:23,874 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430060386657715 s; generated tokens: 1 tokens; generate speed: 1.0604385963581606 tokens/s
2024-06-05 16:17:23,878 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:23,879 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[75/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.0153 tokens/s, remaining time: 0:36:37
pred is:
 ['']
 label is:
 ['Roman Catholic']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:23,963 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:23,964 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 286, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:23,964 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:23,964 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:23,965 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:24,907 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:24,909 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445297718048096 s; generated tokens: 1 tokens; generate speed: 1.0587278769299118 tokens/s
2024-06-05 16:17:24,914 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:24,914 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[76/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0463 tokens/s, avg speed: 1.0157 tokens/s, remaining time: 0:36:32
pred is:
 ['']
 label is:
 ['Warszawa']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:25,022 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:25,022 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 240, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:25,022 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:25,023 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:25,023 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:25,964 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:25,966 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430272579193115 s; generated tokens: 1 tokens; generate speed: 1.0604147352075408 tokens/s
2024-06-05 16:17:25,971 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:25,971 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[77/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.0160 tokens/s, remaining time: 0:36:27
pred is:
 ['']
 label is:
 ['Jazdów']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:26,052 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:26,053 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 232, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:26,053 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:26,053 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:26,054 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:26,995 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:26,997 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432499408721924 s; generated tokens: 1 tokens; generate speed: 1.0601643919270567 tokens/s
2024-06-05 16:17:27,002 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:27,002 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[78/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0475 tokens/s, avg speed: 1.0164 tokens/s, remaining time: 0:36:22
pred is:
 ['']
 label is:
 ['General Sejm']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:27,083 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:27,083 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 163, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:27,083 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:27,083 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:27,084 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:28,024 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:28,025 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415006637573242 s; generated tokens: 1 tokens; generate speed: 1.0621341423268016 tokens/s
2024-06-05 16:17:28,030 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:28,030 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[79/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.0167 tokens/s, remaining time: 0:36:18
pred is:
 ['']
 label is:
 ['until 1796']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:28,111 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:28,111 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:28,111 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:28,112 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:28,112 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:29,052 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:29,054 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423098564147949 s; generated tokens: 1 tokens; generate speed: 1.061222052589685 tokens/s
2024-06-05 16:17:29,059 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:29,059 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[80/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.0171 tokens/s, remaining time: 0:36:13
pred is:
 ['']
 label is:
 ['from 4 August 1915 until November 1918']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 0.625, Em score: 0.0, current_count: 80
2024-06-05 16:17:29,156 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:29,156 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 229, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:29,156 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:29,157 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:29,157 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:30,098 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:30,100 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426901340484619 s; generated tokens: 1 tokens; generate speed: 1.0607939596285112 tokens/s
2024-06-05 16:17:30,104 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:30,105 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[81/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0482 tokens/s, avg speed: 1.0174 tokens/s, remaining time: 0:36:08
pred is:
 ['']
 label is:
 ['September 1939']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:30,186 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:30,186 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 223, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:30,187 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:30,187 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:30,187 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:31,128 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:31,130 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426889419555664 s; generated tokens: 1 tokens; generate speed: 1.0607953010730606 tokens/s
2024-06-05 16:17:31,135 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:31,135 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[82/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.0178 tokens/s, remaining time: 0:36:04
pred is:
 ['']
 label is:
 ['the Red Army']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:31,216 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:31,216 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 179, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:31,216 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:31,217 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:31,217 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:32,157 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:32,159 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418525695800781 s; generated tokens: 1 tokens; generate speed: 1.0617372955152065 tokens/s
2024-06-05 16:17:32,163 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:32,164 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[83/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.0181 tokens/s, remaining time: 0:36:00
pred is:
 ['']
 label is:
 ['"Bricks for Warsaw"']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:32,245 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:32,245 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 161, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:32,245 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:32,246 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:32,246 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:33,186 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:33,188 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419217109680176 s; generated tokens: 1 tokens; generate speed: 1.061659359112017 tokens/s
2024-06-05 16:17:33,193 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:33,193 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[84/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.0184 tokens/s, remaining time: 0:35:55
pred is:
 ['']
 label is:
 ['John Paul II']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:33,279 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:33,280 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 308, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:33,280 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:33,280 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:33,281 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:34,224 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:34,226 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9447934627532959 s; generated tokens: 1 tokens; generate speed: 1.0584323869958017 tokens/s
2024-06-05 16:17:34,230 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:34,230 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[85/2067], cost time 0.9562s, every example cost time is 0.9562, generate speed: 1.0459 tokens/s, avg speed: 1.0187 tokens/s, remaining time: 0:35:51
pred is:
 ['']
 label is:
 ['about 300']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:34,312 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:34,312 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 254, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:34,312 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:34,313 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:34,313 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:35,254 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:35,256 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435920715332031 s; generated tokens: 1 tokens; generate speed: 1.0597799940975998 tokens/s
2024-06-05 16:17:35,261 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:35,261 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[86/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0475 tokens/s, avg speed: 1.0190 tokens/s, remaining time: 0:35:47
pred is:
 ['']
 label is:
 ['two']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:35,342 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:35,342 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 236, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:35,343 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:35,343 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:35,343 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:36,284 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:36,286 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427616596221924 s; generated tokens: 1 tokens; generate speed: 1.0607134791637005 tokens/s
2024-06-05 16:17:36,291 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:36,291 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[87/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.0193 tokens/s, remaining time: 0:35:43
pred is:
 ['']
 label is:
 ['moraine']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:36,378 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:36,378 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 175, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:36,378 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:36,378 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:36,379 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:37,319 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:37,321 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420716762542725 s; generated tokens: 1 tokens; generate speed: 1.061490357056539 tokens/s
2024-06-05 16:17:37,326 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:37,326 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[88/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0489 tokens/s, avg speed: 1.0196 tokens/s, remaining time: 0:35:39
pred is:
 ['']
 label is:
 ['turbulent history of the city']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:37,407 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:37,407 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 269, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:37,408 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:37,408 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:37,408 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:38,350 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:38,352 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434142112731934 s; generated tokens: 1 tokens; generate speed: 1.059979792598673 tokens/s
2024-06-05 16:17:38,356 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:38,357 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[89/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0478 tokens/s, avg speed: 1.0199 tokens/s, remaining time: 0:35:35
pred is:
 ['']
 label is:
 ['Gothic']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:38,438 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:38,438 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 321, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:38,439 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:38,439 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:38,439 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:39,382 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:39,384 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9443686008453369 s; generated tokens: 1 tokens; generate speed: 1.0589085650506227 tokens/s
2024-06-05 16:17:39,388 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:39,389 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[90/2067], cost time 0.9557s, every example cost time is 0.9557, generate speed: 1.0464 tokens/s, avg speed: 1.0201 tokens/s, remaining time: 0:35:31
pred is:
 ['']
 label is:
 ['17th century']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 0.5555555555555556, Em score: 0.0, current_count: 90
2024-06-05 16:17:39,481 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:39,482 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 200, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:39,482 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:39,482 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:39,482 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:40,423 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:40,425 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942847728729248 s; generated tokens: 1 tokens; generate speed: 1.060616650525086 tokens/s
2024-06-05 16:17:40,430 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:40,431 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[91/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.0204 tokens/s, remaining time: 0:35:28
pred is:
 ['']
 label is:
 ['bourgeois']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:40,516 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:40,516 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 201, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:40,517 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:40,517 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:40,517 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:41,458 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:41,460 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426360130310059 s; generated tokens: 1 tokens; generate speed: 1.0608548646306677 tokens/s
2024-06-05 16:17:41,465 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:41,465 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[92/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0484 tokens/s, avg speed: 1.0207 tokens/s, remaining time: 0:35:24
pred is:
 ['']
 label is:
 ['many places']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:41,546 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:41,546 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 266, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:41,547 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:41,547 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:41,547 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:42,489 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:42,491 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433155059814453 s; generated tokens: 1 tokens; generate speed: 1.0600907052403203 tokens/s
2024-06-05 16:17:42,495 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:42,496 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[93/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0478 tokens/s, avg speed: 1.0209 tokens/s, remaining time: 0:35:20
pred is:
 ['']
 label is:
 ['green']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:42,577 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:42,577 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 241, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:42,578 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:42,578 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:42,578 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:43,519 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:43,526 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.948188066482544 s; generated tokens: 1 tokens; generate speed: 1.0546430980824941 tokens/s
2024-06-05 16:17:43,531 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:43,531 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[94/2067], cost time 0.9594s, every example cost time is 0.9594, generate speed: 1.0423 tokens/s, avg speed: 1.0211 tokens/s, remaining time: 0:35:17
pred is:
 ['']
 label is:
 ['location of Warsaw']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:43,613 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:43,613 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 247, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:43,614 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:43,614 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:43,614 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:44,556 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:44,558 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435408115386963 s; generated tokens: 1 tokens; generate speed: 1.0598375690493258 tokens/s
2024-06-05 16:17:44,563 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:44,563 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[95/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0475 tokens/s, avg speed: 1.0214 tokens/s, remaining time: 0:35:13
pred is:
 ['']
 label is:
 ['1,300,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:44,644 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:44,644 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 215, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:44,645 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:44,645 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:44,645 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:45,586 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:45,589 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943305253982544 s; generated tokens: 1 tokens; generate speed: 1.060102226482993 tokens/s
2024-06-05 16:17:45,593 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:45,594 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[96/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0476 tokens/s, avg speed: 1.0216 tokens/s, remaining time: 0:35:10
pred is:
 ['']
 label is:
 ['multi-cultural']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:45,674 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:45,675 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 327, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:45,675 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:45,675 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:45,675 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:46,618 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:46,620 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94451904296875 s; generated tokens: 1 tokens; generate speed: 1.0587399030694669 tokens/s
2024-06-05 16:17:46,625 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:46,625 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[97/2067], cost time 0.9554s, every example cost time is 0.9554, generate speed: 1.0467 tokens/s, avg speed: 1.0219 tokens/s, remaining time: 0:35:06
pred is:
 ['']
 label is:
 ['a commune']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:46,706 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:46,706 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 159, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:46,707 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:46,707 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:46,707 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:47,647 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:47,649 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416985511779785 s; generated tokens: 1 tokens; generate speed: 1.061910946713353 tokens/s
2024-06-05 16:17:47,654 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:47,654 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[98/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.0221 tokens/s, remaining time: 0:35:03
pred is:
 ['']
 label is:
 ['Warsaw City Council']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:47,735 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:47,735 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 218, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:47,736 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:47,736 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:47,736 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:48,677 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:48,678 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421937465667725 s; generated tokens: 1 tokens; generate speed: 1.061352830714347 tokens/s
2024-06-05 16:17:48,683 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:48,683 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[99/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.0224 tokens/s, remaining time: 0:34:59
pred is:
 ['']
 label is:
 ['President']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:48,764 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:48,765 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 352, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:48,765 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:48,765 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:48,765 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:49,709 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:49,711 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94498610496521 s; generated tokens: 1 tokens; generate speed: 1.0582166179436208 tokens/s
2024-06-05 16:17:49,715 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:49,716 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[100/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0462 tokens/s, avg speed: 1.0226 tokens/s, remaining time: 0:34:56
pred is:
 ['']
 label is:
 ['Śródmieście']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 0.5, Em score: 0.0, current_count: 100
2024-06-05 16:17:49,808 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:49,808 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 187, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:49,808 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:49,809 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:49,809 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:50,749 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:50,751 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424037933349609 s; generated tokens: 1 tokens; generate speed: 1.0611162721037217 tokens/s
2024-06-05 16:17:50,756 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:50,756 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[101/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.0228 tokens/s, remaining time: 0:34:53
pred is:
 ['']
 label is:
 ['1817']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:50,837 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:50,837 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 235, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:50,838 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:50,838 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:50,838 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:51,780 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:51,782 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437167644500732 s; generated tokens: 1 tokens; generate speed: 1.0596399657928344 tokens/s
2024-06-05 16:17:51,787 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:51,787 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[102/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.0230 tokens/s, remaining time: 0:34:50
pred is:
 ['']
 label is:
 ['1951']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:51,869 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:51,869 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 201, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:51,869 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:51,870 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:51,870 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:52,810 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:52,812 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421701431274414 s; generated tokens: 1 tokens; generate speed: 1.0613794199427695 tokens/s
2024-06-05 16:17:52,817 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:52,817 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[103/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.0232 tokens/s, remaining time: 0:34:47
pred is:
 ['']
 label is:
 ['Warszawa']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:52,898 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:52,899 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 212, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:52,899 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:52,899 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:52,899 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:53,840 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:53,842 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942363977432251 s; generated tokens: 1 tokens; generate speed: 1.061161105420005 tokens/s
2024-06-05 16:17:53,846 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:53,847 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[104/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.0235 tokens/s, remaining time: 0:34:43
pred is:
 ['']
 label is:
 ['France']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:53,954 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:53,955 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 337, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:53,955 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:53,955 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:53,955 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:54,899 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:54,901 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9452412128448486 s; generated tokens: 1 tokens; generate speed: 1.057931019522886 tokens/s
2024-06-05 16:17:54,905 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:54,906 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[105/2067], cost time 0.9565s, every example cost time is 0.9565, generate speed: 1.0455 tokens/s, avg speed: 1.0237 tokens/s, remaining time: 0:34:40
pred is:
 ['']
 label is:
 ['William the Conqueror']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:54,987 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:54,987 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 144, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:54,987 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:54,988 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:54,988 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:55,927 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:55,930 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415843486785889 s; generated tokens: 1 tokens; generate speed: 1.062039743336209 tokens/s
2024-06-05 16:17:55,934 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:55,934 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[106/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.0239 tokens/s, remaining time: 0:34:37
pred is:
 ['']
 label is:
 ['Viking']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:56,016 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:56,016 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 252, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:56,016 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:56,017 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:56,017 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:56,958 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:56,960 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429037570953369 s; generated tokens: 1 tokens; generate speed: 1.0605536275309273 tokens/s
2024-06-05 16:17:56,965 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:56,965 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[107/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.0241 tokens/s, remaining time: 0:34:34
pred is:
 ['']
 label is:
 ['911']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:57,046 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:57,046 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 203, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:57,047 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:57,047 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:57,047 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:57,988 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:57,990 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426980018615723 s; generated tokens: 1 tokens; generate speed: 1.0607851061795739 tokens/s
2024-06-05 16:17:57,995 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:57,995 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[108/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.0243 tokens/s, remaining time: 0:34:31
pred is:
 ['']
 label is:
 ['Rollo']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:58,076 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:58,077 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 151, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:58,077 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:58,077 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:58,077 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:17:59,017 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:59,019 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412903785705566 s; generated tokens: 1 tokens; generate speed: 1.0623714241280144 tokens/s
2024-06-05 16:17:59,023 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:17:59,024 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[109/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.0245 tokens/s, remaining time: 0:34:28
pred is:
 ['']
 label is:
 ['Catholicism']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:17:59,105 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:17:59,105 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 181, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:17:59,106 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:17:59,106 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:17:59,106 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:00,046 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:00,048 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419739246368408 s; generated tokens: 1 tokens; generate speed: 1.0616005112726767 tokens/s
2024-06-05 16:18:00,053 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:00,053 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[110/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.0247 tokens/s, remaining time: 0:34:26
pred is:
 ['']
 label is:
 ['fighting horsemen']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 0.45454545454545453, Em score: 0.0, current_count: 110
2024-06-05 16:18:00,146 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:00,147 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 246, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:00,147 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:00,147 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:00,147 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:01,088 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:01,091 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430038928985596 s; generated tokens: 1 tokens; generate speed: 1.0604410093432897 tokens/s
2024-06-05 16:18:01,095 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:01,096 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[111/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.0249 tokens/s, remaining time: 0:34:23
pred is:
 ['']
 label is:
 ['999']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:01,177 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:01,177 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 254, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:01,177 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:01,177 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:01,178 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:02,119 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:02,121 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432194232940674 s; generated tokens: 1 tokens; generate speed: 1.060198693224143 tokens/s
2024-06-05 16:18:02,126 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:02,126 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[112/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.0251 tokens/s, remaining time: 0:34:20
pred is:
 ['']
 label is:
 ['Drogo']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:02,206 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:02,206 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 222, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:02,207 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:02,207 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:02,207 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:03,148 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:03,150 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427227973937988 s; generated tokens: 1 tokens; generate speed: 1.0607572053678416 tokens/s
2024-06-05 16:18:03,155 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:03,155 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[113/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.0253 tokens/s, remaining time: 0:34:17
pred is:
 ['']
 label is:
 ['Saracens']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:03,236 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:03,237 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 237, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:03,237 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:03,237 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:03,237 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:04,178 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:04,180 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427530765533447 s; generated tokens: 1 tokens; generate speed: 1.0607231361746885 tokens/s
2024-06-05 16:18:04,185 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:04,185 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[114/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0485 tokens/s, avg speed: 1.0255 tokens/s, remaining time: 0:34:14
pred is:
 ['']
 label is:
 ['Kitab Rudjdjar']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:04,266 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:04,266 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 217, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:04,266 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:04,267 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:04,267 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:05,208 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:05,210 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426167011260986 s; generated tokens: 1 tokens; generate speed: 1.0608765989456248 tokens/s
2024-06-05 16:18:05,214 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:05,214 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[115/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.0256 tokens/s, remaining time: 0:34:12
pred is:
 ['']
 label is:
 ['Seljuk Turks']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:05,320 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:05,320 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 181, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:05,321 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:05,321 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:05,321 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:06,261 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:06,264 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424035549163818 s; generated tokens: 1 tokens; generate speed: 1.061116540555419 tokens/s
2024-06-05 16:18:06,268 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:06,269 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[116/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.0258 tokens/s, remaining time: 0:34:09
pred is:
 ['']
 label is:
 ['1050s']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:06,349 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:06,350 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 244, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:06,350 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:06,350 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:06,350 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:07,292 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:07,294 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429676532745361 s; generated tokens: 1 tokens; generate speed: 1.0604817636399448 tokens/s
2024-06-05 16:18:07,298 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:07,299 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[117/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.0260 tokens/s, remaining time: 0:34:06
pred is:
 ['']
 label is:
 ['Afranji']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:07,379 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:07,379 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 155, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:07,380 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:07,380 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:07,380 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:08,320 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:08,322 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416666030883789 s; generated tokens: 1 tokens; generate speed: 1.0619469743540924 tokens/s
2024-06-05 16:18:08,327 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:08,327 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[118/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.0262 tokens/s, remaining time: 0:34:04
pred is:
 ['']
 label is:
 ['Norman mercenary']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:08,408 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:08,408 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 436, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:08,409 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:08,409 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:08,409 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:09,353 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:09,391 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:09,421 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:09,450 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:09,480 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:09,522 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:09,552 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:09,582 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:09,611 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:09,641 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:09,642 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.232921838760376 s; generated tokens: 10 tokens; generate speed: 8.110814234626876 tokens/s
2024-06-05 16:18:09,647 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:09,647 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[119/2067], cost time 1.2439s, every example cost time is 1.2439, generate speed: 8.0395 tokens/s, avg speed: 1.0960 tokens/s, remaining time: 0:34:06
pred is:
 ['Robert Guiscard']
 label is:
 ['Robert Guiscard']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:18:09,728 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:09,728 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 232, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:09,728 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:09,729 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:09,729 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:10,670 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:10,672 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942781925201416 s; generated tokens: 1 tokens; generate speed: 1.060690678585464 tokens/s
2024-06-05 16:18:10,676 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:10,677 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[120/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.0956 tokens/s, remaining time: 0:34:03
pred is:
 ['']
 label is:
 ['Deabolis']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 1.25, Em score: 0.8333333333333334, current_count: 120
2024-06-05 16:18:10,771 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:10,771 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 120, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:10,772 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:10,772 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:10,772 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:11,711 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:11,713 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412112236022949 s; generated tokens: 1 tokens; generate speed: 1.0624607685538459 tokens/s
2024-06-05 16:18:11,718 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:11,718 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[121/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.0953 tokens/s, remaining time: 0:34:01
pred is:
 ['']
 label is:
 ['1185']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:11,799 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:11,800 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 185, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:11,800 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:11,800 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:11,801 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:12,740 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:12,742 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413890838623047 s; generated tokens: 1 tokens; generate speed: 1.0622600337548298 tokens/s
2024-06-05 16:18:12,747 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:12,747 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[122/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.0949 tokens/s, remaining time: 0:33:58
pred is:
 ['']
 label is:
 ['King Ethelred II']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:12,829 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:12,829 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 207, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:12,829 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:12,829 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:12,830 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:13,770 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:13,772 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419517517089844 s; generated tokens: 1 tokens; generate speed: 1.0616255006540394 tokens/s
2024-06-05 16:18:13,776 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:13,777 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[123/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.0946 tokens/s, remaining time: 0:33:55
pred is:
 ['']
 label is:
 ['Harthacnut']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:13,864 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:13,864 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:13,865 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:13,865 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:13,865 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:14,805 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:14,806 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412550926208496 s; generated tokens: 1 tokens; generate speed: 1.0624112505097634 tokens/s
2024-06-05 16:18:14,811 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:14,811 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[124/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.0943 tokens/s, remaining time: 0:33:53
pred is:
 ['']
 label is:
 ['Battle of Hastings']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:14,893 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:14,893 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 174, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:14,893 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:14,893 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:14,894 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:15,834 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:15,835 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417295455932617 s; generated tokens: 1 tokens; generate speed: 1.0618759968606801 tokens/s
2024-06-05 16:18:15,840 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:15,840 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[125/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.0939 tokens/s, remaining time: 0:33:50
pred is:
 ['']
 label is:
 ['Modern English']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:15,922 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:15,922 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 342, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:15,923 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:15,923 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:15,923 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:16,865 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:16,868 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9444317817687988 s; generated tokens: 1 tokens; generate speed: 1.0588377258197825 tokens/s
2024-06-05 16:18:16,872 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:16,873 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[126/2067], cost time 0.9553s, every example cost time is 0.9553, generate speed: 1.0467 tokens/s, avg speed: 1.0936 tokens/s, remaining time: 0:33:48
pred is:
 ['']
 label is:
 ['1169']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:16,954 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:16,954 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 157, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:16,954 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:16,955 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:16,955 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:17,894 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:17,896 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410536289215088 s; generated tokens: 1 tokens; generate speed: 1.0626386948276758 tokens/s
2024-06-05 16:18:17,901 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:17,901 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[127/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.0933 tokens/s, remaining time: 0:33:45
pred is:
 ['']
 label is:
 ['Edgar']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:17,988 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:17,988 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 272, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:17,988 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:17,989 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:17,989 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:18,930 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:18,932 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431116580963135 s; generated tokens: 1 tokens; generate speed: 1.0603198374395209 tokens/s
2024-06-05 16:18:18,937 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:18,937 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[128/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.0930 tokens/s, remaining time: 0:33:43
pred is:
 ['']
 label is:
 ['Sybilla of Normandy']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:19,019 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:19,019 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 113, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:19,019 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:19,019 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:19,020 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:19,959 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:19,961 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407696723937988 s; generated tokens: 1 tokens; generate speed: 1.06295943560286 tokens/s
2024-06-05 16:18:19,965 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:19,965 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[129/2067], cost time 0.9517s, every example cost time is 0.9517, generate speed: 1.0508 tokens/s, avg speed: 1.0927 tokens/s, remaining time: 0:33:41
pred is:
 ['']
 label is:
 ['Hereford']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:20,046 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:20,047 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 143, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:20,047 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:20,047 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:20,047 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:20,987 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:20,989 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414477348327637 s; generated tokens: 1 tokens; generate speed: 1.0621938563351447 tokens/s
2024-06-05 16:18:20,994 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:20,994 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[130/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0500 tokens/s, avg speed: 1.0924 tokens/s, remaining time: 0:33:38
pred is:
 ['']
 label is:
 ['Wales']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 1.1538461538461537, Em score: 0.7692307692307693, current_count: 130
2024-06-05 16:18:21,101 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:21,101 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:21,101 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:21,101 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:21,102 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:22,041 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:22,044 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417033195495605 s; generated tokens: 1 tokens; generate speed: 1.0619055696631974 tokens/s
2024-06-05 16:18:22,048 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:22,048 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[131/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.0921 tokens/s, remaining time: 0:33:36
pred is:
 ['']
 label is:
 ['1018']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:22,129 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:22,129 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 169, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:22,130 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:22,130 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:22,130 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:23,070 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:23,072 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416773319244385 s; generated tokens: 1 tokens; generate speed: 1.0619348752468871 tokens/s
2024-06-05 16:18:23,077 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:23,077 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[132/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.0918 tokens/s, remaining time: 0:33:34
pred is:
 ['']
 label is:
 ['1097']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:23,158 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:23,158 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 106, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:23,159 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:23,159 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:23,159 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:24,098 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:24,099 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9401798248291016 s; generated tokens: 1 tokens; generate speed: 1.0636263123193184 tokens/s
2024-06-05 16:18:24,104 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:24,104 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[133/2067], cost time 0.9511s, every example cost time is 0.9511, generate speed: 1.0515 tokens/s, avg speed: 1.0915 tokens/s, remaining time: 0:33:31
pred is:
 ['']
 label is:
 ['380 years']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:24,191 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:24,191 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 192, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:24,191 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:24,192 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:24,192 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:25,132 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:25,134 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94191575050354 s; generated tokens: 1 tokens; generate speed: 1.0616660773167967 tokens/s
2024-06-05 16:18:25,139 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:25,139 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[134/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.0912 tokens/s, remaining time: 0:33:29
pred is:
 ['']
 label is:
 ['a storm']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:25,219 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:25,220 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 257, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:25,220 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:25,220 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:25,220 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:26,162 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:26,163 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428951740264893 s; generated tokens: 1 tokens; generate speed: 1.06056328163146 tokens/s
2024-06-05 16:18:26,168 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:26,168 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[135/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.0909 tokens/s, remaining time: 0:33:27
pred is:
 ['']
 label is:
 ['Conrad of Montferrat']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:26,249 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:26,249 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 164, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:26,250 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:26,250 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:26,250 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:27,190 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:27,192 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420013427734375 s; generated tokens: 1 tokens; generate speed: 1.0615696120515106 tokens/s
2024-06-05 16:18:27,197 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:27,197 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[136/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.0906 tokens/s, remaining time: 0:33:24
pred is:
 ['']
 label is:
 ['Richard the Lion-Heart']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:27,284 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:27,285 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 168, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:27,285 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:27,285 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:27,286 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:28,225 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:28,227 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941279411315918 s; generated tokens: 1 tokens; generate speed: 1.06238380227821 tokens/s
2024-06-05 16:18:28,232 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:28,232 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[137/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.0904 tokens/s, remaining time: 0:33:22
pred is:
 ['']
 label is:
 ['1489']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:28,313 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:28,313 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 130, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:28,313 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:28,313 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:28,314 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:29,253 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:29,255 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409277439117432 s; generated tokens: 1 tokens; generate speed: 1.0627808633239724 tokens/s
2024-06-05 16:18:29,259 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:29,260 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[138/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0506 tokens/s, avg speed: 1.0901 tokens/s, remaining time: 0:33:20
pred is:
 ['']
 label is:
 ['Africa']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:29,340 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:29,341 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 109, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:29,341 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:29,341 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:29,341 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:30,280 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:30,282 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9401078224182129 s; generated tokens: 1 tokens; generate speed: 1.063707774952588 tokens/s
2024-06-05 16:18:30,286 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:30,286 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[139/2067], cost time 0.9510s, every example cost time is 0.9510, generate speed: 1.0515 tokens/s, avg speed: 1.0898 tokens/s, remaining time: 0:33:18
pred is:
 ['']
 label is:
 ['Bethencourt']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:30,368 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:30,368 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 175, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:30,369 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:30,369 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:30,369 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:31,309 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:31,311 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419636726379395 s; generated tokens: 1 tokens; generate speed: 1.0616120653565457 tokens/s
2024-06-05 16:18:31,316 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:31,316 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[140/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.0896 tokens/s, remaining time: 0:33:15
pred is:
 ['']
 label is:
 ['Channel Islands']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 1.0714285714285714, Em score: 0.7142857142857143, current_count: 140
2024-06-05 16:18:31,420 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:31,421 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 123, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:31,421 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:31,421 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:31,421 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:32,361 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:32,363 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416177272796631 s; generated tokens: 1 tokens; generate speed: 1.0620020959981324 tokens/s
2024-06-05 16:18:32,368 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:32,368 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[141/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.0893 tokens/s, remaining time: 0:33:13
pred is:
 ['']
 label is:
 ['Romanesque']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:32,449 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:32,449 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 112, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:32,449 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:32,450 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:32,450 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:33,388 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:33,390 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.940331220626831 s; generated tokens: 1 tokens; generate speed: 1.0634550656878046 tokens/s
2024-06-05 16:18:33,395 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:33,395 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[142/2067], cost time 0.9512s, every example cost time is 0.9512, generate speed: 1.0513 tokens/s, avg speed: 1.0891 tokens/s, remaining time: 0:33:11
pred is:
 ['']
 label is:
 ['Early Gothic']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:33,476 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:33,476 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 273, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:33,477 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:33,477 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:33,477 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:34,418 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:34,420 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430346488952637 s; generated tokens: 1 tokens; generate speed: 1.060406424272395 tokens/s
2024-06-05 16:18:34,425 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:34,425 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[143/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0482 tokens/s, avg speed: 1.0888 tokens/s, remaining time: 0:33:09
pred is:
 ['']
 label is:
 ['early 11th century']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:34,506 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:34,507 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 140, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:34,507 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:34,507 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:34,508 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:35,447 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:35,449 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410581588745117 s; generated tokens: 1 tokens; generate speed: 1.0626335796248572 tokens/s
2024-06-05 16:18:35,453 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:35,454 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[144/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.0885 tokens/s, remaining time: 0:33:07
pred is:
 ['']
 label is:
 ['16th century']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:35,534 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:35,535 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 127, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:35,535 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:35,535 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:35,535 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:36,475 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:36,477 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410297870635986 s; generated tokens: 1 tokens; generate speed: 1.0626656177594684 tokens/s
2024-06-05 16:18:36,481 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:36,482 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[145/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0506 tokens/s, avg speed: 1.0883 tokens/s, remaining time: 0:33:05
pred is:
 ['']
 label is:
 ['embroidery']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:36,563 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:36,563 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 243, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:36,564 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:36,564 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:36,564 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:37,505 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:37,507 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428060054779053 s; generated tokens: 1 tokens; generate speed: 1.0606635874079984 tokens/s
2024-06-05 16:18:37,512 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:37,512 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[146/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.0881 tokens/s, remaining time: 0:33:03
pred is:
 ['']
 label is:
 ['mosaics']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:37,594 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:37,594 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 198, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:37,595 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:37,595 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:37,595 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:38,535 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:38,537 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418706893920898 s; generated tokens: 1 tokens; generate speed: 1.0617168696962302 tokens/s
2024-06-05 16:18:38,542 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:38,542 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[147/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.0878 tokens/s, remaining time: 0:33:01
pred is:
 ['']
 label is:
 ['11th']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:38,624 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:38,624 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 119, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:38,624 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:38,625 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:38,625 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:39,564 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:39,566 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409389495849609 s; generated tokens: 1 tokens; generate speed: 1.062768206631355 tokens/s
2024-06-05 16:18:39,571 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:39,571 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[148/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.0876 tokens/s, remaining time: 0:32:59
pred is:
 ['']
 label is:
 ['southern Italy']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:39,659 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:39,660 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 116, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:39,660 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:39,660 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:39,661 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:40,600 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:40,630 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:40,660 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:40,689 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:40,718 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:40,747 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:40,776 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:40,805 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:40,834 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:40,863 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:41,152 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.491086721420288 s; generated tokens: 20 tokens; generate speed: 13.413036084815795 tokens/s
2024-06-05 16:18:41,157 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:41,157 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[149/2067], cost time 1.5029s, every example cost time is 1.5029, generate speed: 13.3077 tokens/s, avg speed: 1.2067 tokens/s, remaining time: 0:33:04
pred is:
 ['1856']
 label is:
 ['1856']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:18:41,238 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:41,238 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 168, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:41,238 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:41,239 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:41,239 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:42,179 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:42,181 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423999786376953 s; generated tokens: 1 tokens; generate speed: 1.0611205673471784 tokens/s
2024-06-05 16:18:42,186 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:42,187 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[150/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.2058 tokens/s, remaining time: 0:33:02
pred is:
 ['']
 label is:
 ['1884']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 1.6666666666666667, Em score: 1.3333333333333333, current_count: 150
2024-06-05 16:18:42,284 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:42,284 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 171, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:42,284 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:42,285 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:42,285 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:43,225 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:43,227 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417986869812012 s; generated tokens: 1 tokens; generate speed: 1.061798040094274 tokens/s
2024-06-05 16:18:43,231 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:43,232 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[151/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.2048 tokens/s, remaining time: 0:32:59
pred is:
 ['']
 label is:
 ['1893']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:43,316 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:43,317 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 187, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:43,317 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:43,318 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:43,318 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:44,258 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:44,289 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:44,319 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:44,348 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:44,377 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:44,406 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:44,435 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:44,465 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:44,494 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:44,523 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:44,756 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4384827613830566 s; generated tokens: 18 tokens; generate speed: 12.513184365653126 tokens/s
2024-06-05 16:18:44,761 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:44,761 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[152/2067], cost time 1.4501s, every example cost time is 1.4501, generate speed: 12.4130 tokens/s, avg speed: 1.3080 tokens/s, remaining time: 0:33:04
pred is:
 ['1943']
 label is:
 ['1943']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:18:44,843 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:44,843 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:44,843 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:44,843 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:44,844 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:45,783 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:45,785 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941215991973877 s; generated tokens: 1 tokens; generate speed: 1.0624553859341508 tokens/s
2024-06-05 16:18:45,790 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:45,790 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[153/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.3064 tokens/s, remaining time: 0:33:02
pred is:
 ['']
 label is:
 ['Croatia']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:45,870 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:45,871 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 170, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:45,871 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:45,871 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:45,872 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:46,811 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:46,813 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417276382446289 s; generated tokens: 1 tokens; generate speed: 1.0618781475544141 tokens/s
2024-06-05 16:18:46,818 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:46,818 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[154/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.3049 tokens/s, remaining time: 0:33:00
pred is:
 ['']
 label is:
 ['four']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:46,899 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:46,899 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 147, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:46,899 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:46,899 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:46,900 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:47,839 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:47,841 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412610530853271 s; generated tokens: 1 tokens; generate speed: 1.0624045228708172 tokens/s
2024-06-05 16:18:47,846 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:47,846 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[155/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.3034 tokens/s, remaining time: 0:32:57
pred is:
 ['']
 label is:
 ['Martin Sekulić']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:47,927 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:47,928 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 126, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:47,929 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:47,929 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:47,929 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:48,868 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:48,871 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414727687835693 s; generated tokens: 1 tokens; generate speed: 1.062165612386273 tokens/s
2024-06-05 16:18:48,875 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:48,876 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[156/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.3019 tokens/s, remaining time: 0:32:55
pred is:
 ['']
 label is:
 ['cholera']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:48,957 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:48,957 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 143, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:48,957 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:48,958 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:48,958 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:49,897 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:49,898 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9405879974365234 s; generated tokens: 1 tokens; generate speed: 1.0631647466535805 tokens/s
2024-06-05 16:18:49,903 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:49,903 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[157/2067], cost time 0.9514s, every example cost time is 0.9514, generate speed: 1.0511 tokens/s, avg speed: 1.3004 tokens/s, remaining time: 0:32:53
pred is:
 ['']
 label is:
 ['Tomingaj']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:49,985 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:49,985 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 369, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:49,986 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:49,986 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:49,986 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:50,929 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:50,931 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94472336769104 s; generated tokens: 1 tokens; generate speed: 1.0585109188566588 tokens/s
2024-06-05 16:18:50,935 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:50,936 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[158/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0463 tokens/s, avg speed: 1.2989 tokens/s, remaining time: 0:32:51
pred is:
 ['']
 label is:
 ['1875']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:51,017 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:51,017 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 165, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:51,017 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:51,018 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:51,018 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:51,958 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:51,960 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941540002822876 s; generated tokens: 1 tokens; generate speed: 1.0620897646428749 tokens/s
2024-06-05 16:18:51,966 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:51,966 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[159/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.2975 tokens/s, remaining time: 0:32:49
pred is:
 ['']
 label is:
 ['left Graz']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:52,047 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:52,047 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 135, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:52,048 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:52,048 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:52,048 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:52,988 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:52,989 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412736892700195 s; generated tokens: 1 tokens; generate speed: 1.0623902605580362 tokens/s
2024-06-05 16:18:52,994 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:52,994 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[160/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.2961 tokens/s, remaining time: 0:32:47
pred is:
 ['']
 label is:
 ['not having a residence permit']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.1875, Em score: 1.875, current_count: 160
2024-06-05 16:18:53,093 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:53,093 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 143, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:53,094 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:53,094 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:53,094 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:54,034 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:54,036 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419488906860352 s; generated tokens: 1 tokens; generate speed: 1.0616287251760395 tokens/s
2024-06-05 16:18:54,041 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:54,041 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[161/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.2946 tokens/s, remaining time: 0:32:46
pred is:
 ['']
 label is:
 ['Prague']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:54,122 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:54,122 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 161, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:54,123 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:54,123 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:54,123 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:55,063 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:55,065 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415595531463623 s; generated tokens: 1 tokens; generate speed: 1.062067711658121 tokens/s
2024-06-05 16:18:55,069 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:55,070 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[162/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.2932 tokens/s, remaining time: 0:32:44
pred is:
 ['']
 label is:
 ['Budapest']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:55,150 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:55,151 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 130, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:55,151 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:55,151 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:55,151 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:56,099 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:56,101 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.949012041091919 s; generated tokens: 1 tokens; generate speed: 1.0537274098750264 tokens/s
2024-06-05 16:18:56,105 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:56,105 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[163/2067], cost time 0.9599s, every example cost time is 0.9599, generate speed: 1.0418 tokens/s, avg speed: 1.2918 tokens/s, remaining time: 0:32:42
pred is:
 ['']
 label is:
 ['1882']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:56,187 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:56,187 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:56,187 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:56,187 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:56,188 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:57,128 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:57,130 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421253204345703 s; generated tokens: 1 tokens; generate speed: 1.0614299162862262 tokens/s
2024-06-05 16:18:57,135 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:57,135 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[164/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.2904 tokens/s, remaining time: 0:32:40
pred is:
 ['']
 label is:
 ['fifty thousand dollars']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:57,216 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:57,216 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 125, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:57,217 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:57,217 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:57,217 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:58,156 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:58,158 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409446716308594 s; generated tokens: 1 tokens; generate speed: 1.0627617437556505 tokens/s
2024-06-05 16:18:58,163 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:58,163 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[165/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0506 tokens/s, avg speed: 1.2891 tokens/s, remaining time: 0:32:38
pred is:
 ['']
 label is:
 ['Robert Lane and Benjamin Vail']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:58,244 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:58,245 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 174, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:58,245 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:58,245 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:58,245 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:18:59,185 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:59,188 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424710273742676 s; generated tokens: 1 tokens; generate speed: 1.0610405741447657 tokens/s
2024-06-05 16:18:59,193 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:18:59,193 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[166/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.2878 tokens/s, remaining time: 0:32:36
pred is:
 ['']
 label is:
 ['forced Tesla out']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:18:59,274 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:18:59,274 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 186, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:18:59,275 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:18:59,275 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:18:59,275 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:00,215 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:00,217 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941849946975708 s; generated tokens: 1 tokens; generate speed: 1.0617402519488508 tokens/s
2024-06-05 16:19:00,222 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:00,222 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[167/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.2864 tokens/s, remaining time: 0:32:34
pred is:
 ['']
 label is:
 ['a Western Union superintendent']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:00,303 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:00,304 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 172, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:00,304 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:00,304 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:00,304 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:01,244 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:01,246 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410655498504639 s; generated tokens: 1 tokens; generate speed: 1.062625233873348 tokens/s
2024-06-05 16:19:01,250 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:01,251 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[168/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0506 tokens/s, avg speed: 1.2851 tokens/s, remaining time: 0:32:32
pred is:
 ['']
 label is:
 ['an induction motor']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:01,331 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:01,332 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 190, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:01,332 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:01,332 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:01,332 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:02,272 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:02,274 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417929649353027 s; generated tokens: 1 tokens; generate speed: 1.0618044912542917 tokens/s
2024-06-05 16:19:02,279 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:02,279 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[169/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.2838 tokens/s, remaining time: 0:32:30
pred is:
 ['']
 label is:
 ['editor of Electrical World magazine']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:02,361 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:02,361 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 155, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:02,361 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:02,361 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:02,362 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:03,302 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:03,304 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417064189910889 s; generated tokens: 1 tokens; generate speed: 1.061902074609797 tokens/s
2024-06-05 16:19:03,308 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:03,308 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[170/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.2826 tokens/s, remaining time: 0:32:28
pred is:
 ['']
 label is:
 ['1888']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.0588235294117645, Em score: 1.7647058823529411, current_count: 170
2024-06-05 16:19:03,409 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:03,410 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 161, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:03,410 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:03,410 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:03,410 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:04,350 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:04,353 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942152738571167 s; generated tokens: 1 tokens; generate speed: 1.0613990269948819 tokens/s
2024-06-05 16:19:04,357 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:04,358 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[171/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.2813 tokens/s, remaining time: 0:32:27
pred is:
 ['']
 label is:
 ['Pittsburgh']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:04,439 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:04,439 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 300, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:04,439 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:04,439 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:04,440 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:05,381 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:05,420 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:05,449 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:05,479 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:05,509 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:05,538 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:05,568 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:05,597 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:05,627 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:05,656 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:05,976 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5358185768127441 s; generated tokens: 20 tokens; generate speed: 13.022371458421626 tokens/s
2024-06-05 16:19:05,980 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:05,981 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[172/2067], cost time 1.5469s, every example cost time is 1.5469, generate speed: 12.9293 tokens/s, avg speed: 1.3830 tokens/s, remaining time: 0:32:31
pred is:
 ['Thomas Edison and George Westinghouse']
 label is:
 ['Thomas Edison and George Westinghouse']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:19:06,062 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:06,063 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 203, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:06,063 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:06,064 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:06,064 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:07,004 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:07,006 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418070316314697 s; generated tokens: 1 tokens; generate speed: 1.0617886322930972 tokens/s
2024-06-05 16:19:07,010 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:07,011 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[173/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.3812 tokens/s, remaining time: 0:32:29
pred is:
 ['']
 label is:
 ['George Westinghouse']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:07,092 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:07,092 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 256, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:07,092 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:07,093 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:07,093 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:08,034 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:08,036 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429206848144531 s; generated tokens: 1 tokens; generate speed: 1.060534588014451 tokens/s
2024-06-05 16:19:08,067 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:08,067 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[174/2067], cost time 0.9800s, every example cost time is 0.9800, generate speed: 1.0204 tokens/s, avg speed: 1.3792 tokens/s, remaining time: 0:32:28
pred is:
 ['']
 label is:
 ['Richard Dean Adams']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:08,149 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:08,149 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 306, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:08,149 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:08,149 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:08,150 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:09,092 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:09,094 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9441804885864258 s; generated tokens: 1 tokens; generate speed: 1.0591195349706326 tokens/s
2024-06-05 16:19:09,099 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:09,099 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[175/2067], cost time 0.9553s, every example cost time is 0.9553, generate speed: 1.0468 tokens/s, avg speed: 1.3775 tokens/s, remaining time: 0:32:26
pred is:
 ['']
 label is:
 ['1896']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:09,180 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:09,180 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 129, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:09,180 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:09,180 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:09,181 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:10,120 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:10,122 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413878917694092 s; generated tokens: 1 tokens; generate speed: 1.0622613789098403 tokens/s
2024-06-05 16:19:10,127 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:10,127 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[176/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.3758 tokens/s, remaining time: 0:32:24
pred is:
 ['']
 label is:
 ['35']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:10,208 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:10,208 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 92, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:10,208 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:10,209 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:10,209 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:11,148 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:11,178 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:11,208 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:11,237 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:11,266 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:11,296 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:11,325 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:11,354 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:11,383 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:11,412 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:11,713 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.503687858581543 s; generated tokens: 20 tokens; generate speed: 13.300632764878728 tokens/s
2024-06-05 16:19:11,717 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:11,718 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[177/2067], cost time 1.5147s, every example cost time is 1.5147, generate speed: 13.2042 tokens/s, avg speed: 1.4739 tokens/s, remaining time: 0:32:28
pred is:
 ['American Institute of Electrical Engineers']
 label is:
 ['American Institute of Electrical Engineers']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:19:11,799 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:11,800 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 268, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:11,800 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:11,800 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:11,800 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:12,741 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:12,743 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942453145980835 s; generated tokens: 1 tokens; generate speed: 1.0610607055264 tokens/s
2024-06-05 16:19:12,772 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:12,772 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[178/2067], cost time 0.9777s, every example cost time is 0.9777, generate speed: 1.0228 tokens/s, avg speed: 1.4715 tokens/s, remaining time: 0:32:27
pred is:
 ['']
 label is:
 ['he had noticed damaged film in his laboratory in previous experiments']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:12,855 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:12,855 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:12,855 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:12,855 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:12,856 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:13,796 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:13,798 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420070648193359 s; generated tokens: 1 tokens; generate speed: 1.0615631637452596 tokens/s
2024-06-05 16:19:13,802 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:13,803 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[179/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.4693 tokens/s, remaining time: 0:32:25
pred is:
 ['']
 label is:
 ['X-ray imaging']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:13,884 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:13,884 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:13,884 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:13,885 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:13,885 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:14,825 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:14,826 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412755966186523 s; generated tokens: 1 tokens; generate speed: 1.0623881077893695 tokens/s
2024-06-05 16:19:14,831 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:14,831 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[180/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.4672 tokens/s, remaining time: 0:32:23
pred is:
 ['']
 label is:
 ['X-rays were longitudinal waves']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.0555555555555554, Em score: 2.7777777777777777, current_count: 180
2024-06-05 16:19:14,934 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:14,934 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 113, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:14,934 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:14,934 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:14,935 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:15,873 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:15,875 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.940209150314331 s; generated tokens: 1 tokens; generate speed: 1.06359313740531 tokens/s
2024-06-05 16:19:15,880 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:15,880 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[181/2067], cost time 0.9512s, every example cost time is 0.9512, generate speed: 1.0513 tokens/s, avg speed: 1.4651 tokens/s, remaining time: 0:32:21
pred is:
 ['']
 label is:
 ['Benjamin Lamme']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:15,961 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:15,961 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 83, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:15,962 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:15,962 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:15,962 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:16,900 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:16,902 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9402093887329102 s; generated tokens: 1 tokens; generate speed: 1.0635928676990427 tokens/s
2024-06-05 16:19:16,907 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:16,907 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[182/2067], cost time 0.9511s, every example cost time is 0.9511, generate speed: 1.0515 tokens/s, avg speed: 1.4630 tokens/s, remaining time: 0:32:19
pred is:
 ['']
 label is:
 ['Egg of Columbus']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:17,013 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:17,013 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 181, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:17,014 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:17,014 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:17,014 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:17,955 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:17,956 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420409202575684 s; generated tokens: 1 tokens; generate speed: 1.0615250128694884 tokens/s
2024-06-05 16:19:17,961 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:17,961 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[183/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0489 tokens/s, avg speed: 1.4609 tokens/s, remaining time: 0:32:17
pred is:
 ['']
 label is:
 ['1934']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:18,042 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:18,042 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 126, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:18,043 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:18,043 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:18,043 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:18,982 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:18,984 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409120082855225 s; generated tokens: 1 tokens; generate speed: 1.062798637060807 tokens/s
2024-06-05 16:19:18,989 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:18,989 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[184/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0507 tokens/s, avg speed: 1.4588 tokens/s, remaining time: 0:32:16
pred is:
 ['']
 label is:
 ['National Electric Light Association']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:19,070 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:19,071 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 208, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:19,071 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:19,071 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:19,071 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:20,012 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:20,014 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422824382781982 s; generated tokens: 1 tokens; generate speed: 1.0612529315809676 tokens/s
2024-06-05 16:19:20,018 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:20,019 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[185/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.4567 tokens/s, remaining time: 0:32:14
pred is:
 ['']
 label is:
 ['1898']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:20,100 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:20,100 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 261, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:20,100 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:20,100 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:20,101 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:21,041 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:21,044 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427750110626221 s; generated tokens: 1 tokens; generate speed: 1.0606984574961087 tokens/s
2024-06-05 16:19:21,048 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:21,048 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[186/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.4547 tokens/s, remaining time: 0:32:12
pred is:
 ['']
 label is:
 ['1900']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:21,129 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:21,129 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 216, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:21,130 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:21,130 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:21,130 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:22,071 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:22,073 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422516822814941 s; generated tokens: 1 tokens; generate speed: 1.0612875718923405 tokens/s
2024-06-05 16:19:22,077 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:22,077 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[187/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.4527 tokens/s, remaining time: 0:32:10
pred is:
 ['']
 label is:
 ['1899']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:22,158 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:22,159 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 96, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:22,159 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:22,159 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:22,159 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:23,098 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:23,100 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9402952194213867 s; generated tokens: 1 tokens; generate speed: 1.063495782330312 tokens/s
2024-06-05 16:19:23,105 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:23,105 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[188/2067], cost time 0.9512s, every example cost time is 0.9512, generate speed: 1.0513 tokens/s, avg speed: 1.4507 tokens/s, remaining time: 0:32:09
pred is:
 ['']
 label is:
 ['atmospheric']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:23,186 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:23,186 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 172, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:23,187 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:23,187 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:23,187 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:24,127 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:24,157 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:24,187 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:24,216 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:24,246 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:24,278 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:24,308 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:24,338 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:24,368 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:24,397 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:24,712 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5250587463378906 s; generated tokens: 20 tokens; generate speed: 13.114248908788474 tokens/s
2024-06-05 16:19:24,717 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:24,717 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[189/2067], cost time 1.5361s, every example cost time is 1.5361, generate speed: 13.0202 tokens/s, avg speed: 1.5421 tokens/s, remaining time: 0:32:13
pred is:
 ['Artificial lightning']
 label is:
 ['lightning']
The F1/Em of this example is:  {'F1': 50.0, 'Em': 0.0}
2024-06-05 16:19:24,799 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:24,799 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 149, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:24,800 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:24,800 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:24,800 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:25,740 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:25,742 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417085647583008 s; generated tokens: 1 tokens; generate speed: 1.06189965497092 tokens/s
2024-06-05 16:19:25,747 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:25,747 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[190/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.5397 tokens/s, remaining time: 0:32:11
pred is:
 ['']
 label is:
 ['power outage']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.1578947368421053, Em score: 2.6315789473684212, current_count: 190
2024-06-05 16:19:25,875 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:25,876 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 286, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:25,876 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:25,876 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:25,876 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:26,819 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:26,821 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445006847381592 s; generated tokens: 1 tokens; generate speed: 1.0587604817642104 tokens/s
2024-06-05 16:19:26,826 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:26,826 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[191/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0462 tokens/s, avg speed: 1.5373 tokens/s, remaining time: 0:32:09
pred is:
 ['']
 label is:
 ['communications from another planet']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:26,907 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:26,908 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 92, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:26,908 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:26,908 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:26,908 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:27,847 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:27,849 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9406106472015381 s; generated tokens: 1 tokens; generate speed: 1.0631391458040098 tokens/s
2024-06-05 16:19:27,854 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:27,854 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[192/2067], cost time 0.9515s, every example cost time is 0.9515, generate speed: 1.0509 tokens/s, avg speed: 1.5349 tokens/s, remaining time: 0:32:07
pred is:
 ['']
 label is:
 ['$100,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:27,935 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:27,935 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 86, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:27,935 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:27,936 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:27,936 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:28,874 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:28,876 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9403438568115234 s; generated tokens: 1 tokens; generate speed: 1.0634407751551183 tokens/s
2024-06-05 16:19:28,881 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:28,881 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[193/2067], cost time 0.9513s, every example cost time is 0.9513, generate speed: 1.0512 tokens/s, avg speed: 1.5326 tokens/s, remaining time: 0:32:05
pred is:
 ['']
 label is:
 ['1900']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:28,962 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:28,963 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 78, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:28,963 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:28,963 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:28,963 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:29,902 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:29,904 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404277801513672 s; generated tokens: 1 tokens; generate speed: 1.0633458741925343 tokens/s
2024-06-05 16:19:29,909 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:29,909 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[194/2067], cost time 0.9513s, every example cost time is 0.9513, generate speed: 1.0512 tokens/s, avg speed: 1.5303 tokens/s, remaining time: 0:32:04
pred is:
 ['']
 label is:
 ['Wardenclyffe']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:30,008 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:30,008 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 163, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:30,009 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:30,009 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:30,009 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:30,949 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:30,951 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418833255767822 s; generated tokens: 1 tokens; generate speed: 1.0617026258402322 tokens/s
2024-06-05 16:19:30,956 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:30,956 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[195/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.5280 tokens/s, remaining time: 0:32:02
pred is:
 ['']
 label is:
 ['Morgan']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:31,036 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:31,037 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 228, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:31,037 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:31,037 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:31,038 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:31,978 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:31,981 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432880878448486 s; generated tokens: 1 tokens; generate speed: 1.0601215184268067 tokens/s
2024-06-05 16:19:31,986 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:31,986 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[196/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.5257 tokens/s, remaining time: 0:32:00
pred is:
 ['']
 label is:
 ['over 50 letters']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:32,067 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:32,068 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 117, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:32,068 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:32,068 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:32,068 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:33,008 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:33,010 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411823749542236 s; generated tokens: 1 tokens; generate speed: 1.0624933345661483 tokens/s
2024-06-05 16:19:33,014 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:33,015 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[197/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.5235 tokens/s, remaining time: 0:31:59
pred is:
 ['']
 label is:
 ['200']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:33,095 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:33,096 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 232, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:33,096 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:33,096 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:33,097 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:34,037 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:34,039 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425458908081055 s; generated tokens: 1 tokens; generate speed: 1.0609562990536572 tokens/s
2024-06-05 16:19:34,044 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:34,044 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[198/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.5213 tokens/s, remaining time: 0:31:57
pred is:
 ['']
 label is:
 ['steam']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:34,131 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:34,131 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 166, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:34,132 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:34,132 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:34,132 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:35,072 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:35,074 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419903755187988 s; generated tokens: 1 tokens; generate speed: 1.061581971524128 tokens/s
2024-06-05 16:19:35,079 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:35,079 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[199/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.5191 tokens/s, remaining time: 0:31:55
pred is:
 ['']
 label is:
 ['application of electricity']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:35,160 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:35,160 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 145, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:35,161 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:35,161 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:35,161 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:36,101 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:36,102 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941342830657959 s; generated tokens: 1 tokens; generate speed: 1.0623122282676143 tokens/s
2024-06-05 16:19:36,107 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:36,107 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[200/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0500 tokens/s, avg speed: 1.5169 tokens/s, remaining time: 0:31:53
pred is:
 ['']
 label is:
 ['overseas']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.0, Em score: 2.5, current_count: 200
2024-06-05 16:19:36,218 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:36,219 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 226, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:36,219 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:36,219 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:36,219 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:37,161 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:37,163 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432528018951416 s; generated tokens: 1 tokens; generate speed: 1.0601611762942496 tokens/s
2024-06-05 16:19:37,167 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:37,168 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[201/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0476 tokens/s, avg speed: 1.5147 tokens/s, remaining time: 0:31:52
pred is:
 ['']
 label is:
 ['Electrical Experimenter']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:37,249 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:37,249 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 203, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:37,249 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:37,249 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:37,250 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:38,190 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:38,192 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422893524169922 s; generated tokens: 1 tokens; generate speed: 1.0612451445354645 tokens/s
2024-06-05 16:19:38,197 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:38,197 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[202/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.5126 tokens/s, remaining time: 0:31:50
pred is:
 ['']
 label is:
 ['Thomas Edison and Nikola Tesla']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:38,278 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:38,278 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 151, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:38,278 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:38,279 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:38,279 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:39,219 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:39,221 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419064521789551 s; generated tokens: 1 tokens; generate speed: 1.0616765578860348 tokens/s
2024-06-05 16:19:39,225 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:39,226 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[203/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.5104 tokens/s, remaining time: 0:31:48
pred is:
 ['']
 label is:
 ['animosity toward each other']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:39,307 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:39,307 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 97, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:39,308 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:39,308 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:39,308 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:40,247 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:40,249 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9405090808868408 s; generated tokens: 1 tokens; generate speed: 1.0632539550357802 tokens/s
2024-06-05 16:19:40,253 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:40,254 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[204/2067], cost time 0.9514s, every example cost time is 0.9514, generate speed: 1.0510 tokens/s, avg speed: 1.5084 tokens/s, remaining time: 0:31:47
pred is:
 ['']
 label is:
 ['38']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:40,334 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:40,334 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 174, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:40,335 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:40,335 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:40,335 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:41,276 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:41,277 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421582221984863 s; generated tokens: 1 tokens; generate speed: 1.0613928493523543 tokens/s
2024-06-05 16:19:41,282 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:41,282 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[205/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0493 tokens/s, avg speed: 1.5063 tokens/s, remaining time: 0:31:45
pred is:
 ['']
 label is:
 ['U.S. Patent 1,655,114']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:41,363 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:41,363 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:41,364 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:41,364 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:41,364 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:42,304 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:42,306 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420623779296875 s; generated tokens: 1 tokens; generate speed: 1.0615008341566918 tokens/s
2024-06-05 16:19:42,311 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:42,311 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[206/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.5042 tokens/s, remaining time: 0:31:43
pred is:
 ['']
 label is:
 ['$125 per month']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:42,392 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:42,392 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 97, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:42,392 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:42,392 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:42,393 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:43,337 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:43,339 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9461629390716553 s; generated tokens: 1 tokens; generate speed: 1.056900411868983 tokens/s
2024-06-05 16:19:43,344 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:43,344 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[207/2067], cost time 0.9570s, every example cost time is 0.9570, generate speed: 1.0449 tokens/s, avg speed: 1.5021 tokens/s, remaining time: 0:31:42
pred is:
 ['']
 label is:
 ['mechanical energy']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:43,425 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:43,425 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 253, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:43,425 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:43,426 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:43,426 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:44,367 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:44,369 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430491924285889 s; generated tokens: 1 tokens; generate speed: 1.06039007087716 tokens/s
2024-06-05 16:19:44,374 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:44,374 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[208/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.5001 tokens/s, remaining time: 0:31:40
pred is:
 ['']
 label is:
 ['feed the pigeons']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:44,455 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:44,455 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 108, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:44,456 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:44,456 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:44,456 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:45,395 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:45,397 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9405467510223389 s; generated tokens: 1 tokens; generate speed: 1.0632113703152317 tokens/s
2024-06-05 16:19:45,402 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:45,402 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[209/2067], cost time 0.9515s, every example cost time is 0.9515, generate speed: 1.0510 tokens/s, avg speed: 1.4981 tokens/s, remaining time: 0:31:38
pred is:
 ['']
 label is:
 ['"teleforce" weapon']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:45,488 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:45,488 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 134, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:45,489 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:45,489 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:45,489 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:46,430 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:46,431 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419045448303223 s; generated tokens: 1 tokens; generate speed: 1.0616787077719678 tokens/s
2024-06-05 16:19:46,436 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:46,436 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[210/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.4961 tokens/s, remaining time: 0:31:37
pred is:
 ['']
 label is:
 ['1937']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.857142857142857, Em score: 2.380952380952381, current_count: 210
2024-06-05 16:19:46,542 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:46,543 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 198, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:46,543 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:46,543 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:46,543 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:47,484 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:47,486 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427840709686279 s; generated tokens: 1 tokens; generate speed: 1.0606882644639803 tokens/s
2024-06-05 16:19:47,491 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:47,491 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[211/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.4941 tokens/s, remaining time: 0:31:35
pred is:
 ['']
 label is:
 ['charged particle beam weapons']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:47,573 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:47,574 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 140, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:47,574 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:47,574 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:47,574 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:48,525 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:48,527 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9524919986724854 s; generated tokens: 1 tokens; generate speed: 1.0498775857369174 tokens/s
2024-06-05 16:19:48,532 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:48,532 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[212/2067], cost time 0.9637s, every example cost time is 0.9637, generate speed: 1.0376 tokens/s, avg speed: 1.4921 tokens/s, remaining time: 0:31:34
pred is:
 ['']
 label is:
 ['steal the invention']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:48,613 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:48,613 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 195, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:48,613 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:48,614 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:48,614 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:49,554 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:49,556 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421861171722412 s; generated tokens: 1 tokens; generate speed: 1.0613614250667098 tokens/s
2024-06-05 16:19:49,561 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:49,561 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[213/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.4901 tokens/s, remaining time: 0:31:32
pred is:
 ['']
 label is:
 ['86']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:49,642 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:49,642 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:49,643 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:49,643 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:49,643 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:50,583 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:50,585 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419136047363281 s; generated tokens: 1 tokens; generate speed: 1.0616684958913318 tokens/s
2024-06-05 16:19:50,590 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:50,590 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[214/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.4882 tokens/s, remaining time: 0:31:30
pred is:
 ['']
 label is:
 ["FBI ordered the Alien Property Custodian to seize Tesla's belongings"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:50,676 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:50,677 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 193, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:50,677 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:50,677 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:50,678 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:51,618 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:51,649 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:51,678 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:51,708 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:51,740 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:51,770 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:51,799 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:51,829 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:51,859 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:51,888 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:52,181 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5032134056091309 s; generated tokens: 20 tokens; generate speed: 13.304830788078036 tokens/s
2024-06-05 16:19:52,186 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:52,186 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[215/2067], cost time 1.5145s, every example cost time is 1.5145, generate speed: 13.2054 tokens/s, avg speed: 1.5689 tokens/s, remaining time: 0:31:34
pred is:
 ['Fiorello La Guardia']
 label is:
 ['New York City mayor Fiorello La Guardia']
The F1/Em of this example is:  {'F1': 55.55555555555556, 'Em': 0.0}
2024-06-05 16:19:52,268 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:52,268 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 130, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:52,269 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:52,269 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:52,269 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:53,208 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:53,210 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9406352043151855 s; generated tokens: 1 tokens; generate speed: 1.0631113904864256 tokens/s
2024-06-05 16:19:53,214 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:53,215 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[216/2067], cost time 0.9516s, every example cost time is 0.9516, generate speed: 1.0509 tokens/s, avg speed: 1.5667 tokens/s, remaining time: 0:31:32
pred is:
 ['']
 label is:
 ['Belgrade']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:53,296 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:53,296 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 147, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:53,297 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:53,297 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:53,297 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:54,236 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:54,238 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409849643707275 s; generated tokens: 1 tokens; generate speed: 1.0627162365646703 tokens/s
2024-06-05 16:19:54,243 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:54,243 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[217/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.5645 tokens/s, remaining time: 0:31:30
pred is:
 ['']
 label is:
 ['around 300']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:54,324 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:54,325 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:54,325 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:54,325 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:54,325 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:55,265 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:55,267 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418213367462158 s; generated tokens: 1 tokens; generate speed: 1.0617725050217897 tokens/s
2024-06-05 16:19:55,272 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:55,272 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[218/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.5623 tokens/s, remaining time: 0:31:29
pred is:
 ['']
 label is:
 ['8:10 p.m']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:55,353 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:55,354 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 85, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:55,354 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:55,354 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:55,354 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:56,293 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:56,295 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9401021003723145 s; generated tokens: 1 tokens; generate speed: 1.0637142493394747 tokens/s
2024-06-05 16:19:56,299 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:56,300 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[219/2067], cost time 0.9510s, every example cost time is 0.9510, generate speed: 1.0515 tokens/s, avg speed: 1.5601 tokens/s, remaining time: 0:31:27
pred is:
 ['']
 label is:
 ['between 8 to 10 miles per day']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:56,381 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:56,381 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 135, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:56,381 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:56,382 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:56,382 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:57,321 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:57,323 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411709308624268 s; generated tokens: 1 tokens; generate speed: 1.0625062538678987 tokens/s
2024-06-05 16:19:57,328 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:57,328 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[220/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0504 tokens/s, avg speed: 1.5579 tokens/s, remaining time: 0:31:26
pred is:
 ['']
 label is:
 ['telepathy']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.9797979797979797, Em score: 2.272727272727273, current_count: 220
2024-06-05 16:19:57,437 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:57,437 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 128, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:57,437 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:57,437 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:57,438 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:58,377 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:58,379 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410278797149658 s; generated tokens: 1 tokens; generate speed: 1.062667771652947 tokens/s
2024-06-05 16:19:58,383 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:58,384 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[221/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0506 tokens/s, avg speed: 1.5558 tokens/s, remaining time: 0:31:24
pred is:
 ['']
 label is:
 ['pigeons']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:19:58,464 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:19:58,464 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 112, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:19:58,465 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:58,465 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:19:58,465 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:19:59,404 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:59,434 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:59,463 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:59,492 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:59,521 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:59,551 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:59,580 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:59,609 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:59,638 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:59,667 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:19:59,956 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4904959201812744 s; generated tokens: 20 tokens; generate speed: 13.418352730256112 tokens/s
2024-06-05 16:19:59,961 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:19:59,961 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[222/2067], cost time 1.5015s, every example cost time is 1.5015, generate speed: 13.3204 tokens/s, avg speed: 1.6336 tokens/s, remaining time: 0:31:27
pred is:
 ['142 pounds (64 kg)']
 label is:
 ['142 pounds']
The F1/Em of this example is:  {'F1': 50.0, 'Em': 0.0}
2024-06-05 16:20:00,042 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:00,042 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 268, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:00,043 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:00,043 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:00,043 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:00,985 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:00,987 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432146549224854 s; generated tokens: 1 tokens; generate speed: 1.0602040530023162 tokens/s
2024-06-05 16:20:00,991 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:00,991 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[223/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.6311 tokens/s, remaining time: 0:31:25
pred is:
 ['']
 label is:
 ['eight']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:01,072 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:01,072 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 220, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:01,073 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:01,073 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:01,073 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:02,014 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:02,016 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426779747009277 s; generated tokens: 1 tokens; generate speed: 1.0608076425221011 tokens/s
2024-06-05 16:20:02,020 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:02,021 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[224/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.6287 tokens/s, remaining time: 0:31:24
pred is:
 ['']
 label is:
 ['more than 48 hours']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:02,102 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:02,102 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 142, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:02,103 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:02,103 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:02,103 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:03,043 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:03,045 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415493011474609 s; generated tokens: 1 tokens; generate speed: 1.0620792759139701 tokens/s
2024-06-05 16:20:03,049 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:03,050 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[225/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.6263 tokens/s, remaining time: 0:31:22
pred is:
 ['']
 label is:
 ['chastity']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:03,131 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:03,131 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 200, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:03,131 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:03,132 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:03,132 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:04,072 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:04,103 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:04,133 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:04,162 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:04,196 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:04,225 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:04,254 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:04,283 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:04,312 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:04,342 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:04,632 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4996423721313477 s; generated tokens: 20 tokens; generate speed: 13.33651300581435 tokens/s
2024-06-05 16:20:04,636 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:04,637 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[226/2067], cost time 1.5107s, every example cost time is 1.5107, generate speed: 13.2389 tokens/s, avg speed: 1.7021 tokens/s, remaining time: 0:31:25
pred is:
 ['Dorothy Skerrit']
 label is:
 ['Dorothy Skerrit']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:20:04,718 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:04,719 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:04,719 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:04,719 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:04,719 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:05,659 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:05,661 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415311813354492 s; generated tokens: 1 tokens; generate speed: 1.0620997156797503 tokens/s
2024-06-05 16:20:05,666 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:05,666 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[227/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.6994 tokens/s, remaining time: 0:31:24
pred is:
 ['']
 label is:
 ['Mark Twain']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:05,751 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:05,751 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 98, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:05,751 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:05,752 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:05,752 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:06,690 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:06,692 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9401421546936035 s; generated tokens: 1 tokens; generate speed: 1.0636689302862974 tokens/s
2024-06-05 16:20:06,697 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:06,697 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[228/2067], cost time 0.9513s, every example cost time is 0.9513, generate speed: 1.0511 tokens/s, avg speed: 1.6968 tokens/s, remaining time: 0:31:22
pred is:
 ['']
 label is:
 ['overweight people']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:06,778 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:06,778 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 175, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:06,778 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:06,779 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:06,779 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:07,719 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:07,721 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94169020652771 s; generated tokens: 1 tokens; generate speed: 1.0619203566821571 tokens/s
2024-06-05 16:20:07,725 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:07,725 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[229/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.6941 tokens/s, remaining time: 0:31:20
pred is:
 ['']
 label is:
 ['electron']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:07,806 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:07,806 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 77, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:07,806 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:07,807 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:07,807 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:08,745 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:08,747 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9399824142456055 s; generated tokens: 1 tokens; generate speed: 1.0638496899993202 tokens/s
2024-06-05 16:20:08,751 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:08,752 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[230/2067], cost time 0.9508s, every example cost time is 0.9508, generate speed: 1.0518 tokens/s, avg speed: 1.6915 tokens/s, remaining time: 0:31:19
pred is:
 ['']
 label is:
 ["Einstein's"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.502415458937198, Em score: 2.608695652173913, current_count: 230
2024-06-05 16:20:08,861 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:08,862 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 164, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:08,862 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:08,863 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:08,863 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:09,803 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:09,805 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421207904815674 s; generated tokens: 1 tokens; generate speed: 1.0614350199074234 tokens/s
2024-06-05 16:20:09,810 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:09,810 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[231/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.6890 tokens/s, remaining time: 0:31:17
pred is:
 ['']
 label is:
 ['gravity']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:09,890 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:09,891 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 140, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:09,891 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:09,891 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:09,891 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:10,831 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:10,832 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9408271312713623 s; generated tokens: 1 tokens; generate speed: 1.0628945177725433 tokens/s
2024-06-05 16:20:10,837 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:10,837 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[232/2067], cost time 0.9516s, every example cost time is 0.9516, generate speed: 1.0508 tokens/s, avg speed: 1.6864 tokens/s, remaining time: 0:31:16
pred is:
 ['']
 label is:
 ['eugenics']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:10,919 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:10,919 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 107, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:10,919 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:10,919 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:10,920 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:11,859 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:11,860 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9406940937042236 s; generated tokens: 1 tokens; generate speed: 1.0630448375223067 tokens/s
2024-06-05 16:20:11,865 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:11,865 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[233/2067], cost time 0.9516s, every example cost time is 0.9516, generate speed: 1.0509 tokens/s, avg speed: 1.6839 tokens/s, remaining time: 0:31:14
pred is:
 ['']
 label is:
 ['women']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:11,947 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:11,947 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 118, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:11,947 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:11,948 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:11,948 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:12,887 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:12,889 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9408137798309326 s; generated tokens: 1 tokens; generate speed: 1.0629096017064115 tokens/s
2024-06-05 16:20:12,893 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:12,894 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[234/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0506 tokens/s, avg speed: 1.6813 tokens/s, remaining time: 0:31:12
pred is:
 ['']
 label is:
 ['post-World War I']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:12,974 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:12,975 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 95, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:12,975 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:12,975 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:12,975 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:13,914 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:13,945 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:13,975 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:14,005 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:14,035 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:14,064 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:14,094 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:14,123 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:14,152 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:14,181 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:14,469 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4939484596252441 s; generated tokens: 20 tokens; generate speed: 13.387342696559282 tokens/s
2024-06-05 16:20:14,474 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:14,475 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[235/2067], cost time 1.5051s, every example cost time is 1.5051, generate speed: 13.2881 tokens/s, avg speed: 1.7539 tokens/s, remaining time: 0:31:15
pred is:
 ['Orthodox Christianity']
 label is:
 ['Orthodox Christian']
The F1/Em of this example is:  {'F1': 66.66666666666666, 'Em': 0.0}
2024-06-05 16:20:14,557 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:14,557 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 86, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:14,557 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:14,558 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:14,558 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:15,496 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:15,498 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404110908508301 s; generated tokens: 1 tokens; generate speed: 1.0633647451937824 tokens/s
2024-06-05 16:20:15,503 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:15,503 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[236/2067], cost time 0.9517s, every example cost time is 0.9517, generate speed: 1.0508 tokens/s, avg speed: 1.7512 tokens/s, remaining time: 0:31:14
pred is:
 ['']
 label is:
 ['"A Machine to End War"']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:15,586 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:15,586 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 103, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:15,587 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:15,587 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:15,587 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:16,527 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:16,529 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411101341247559 s; generated tokens: 1 tokens; generate speed: 1.062574892926865 tokens/s
2024-06-05 16:20:16,533 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:16,534 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[237/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.7484 tokens/s, remaining time: 0:31:12
pred is:
 ['']
 label is:
 ['books and articles']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:16,615 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:16,615 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 116, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:16,615 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:16,615 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:16,616 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:17,555 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:17,557 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410462379455566 s; generated tokens: 1 tokens; generate speed: 1.0626470407906292 tokens/s
2024-06-05 16:20:17,561 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:17,562 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[238/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0506 tokens/s, avg speed: 1.7457 tokens/s, remaining time: 0:31:10
pred is:
 ['']
 label is:
 ['the web']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:17,646 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:17,646 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 95, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:17,647 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:17,647 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:17,647 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:18,586 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:18,588 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9406094551086426 s; generated tokens: 1 tokens; generate speed: 1.0631404931864072 tokens/s
2024-06-05 16:20:18,593 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:18,593 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[239/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0505 tokens/s, avg speed: 1.7430 tokens/s, remaining time: 0:31:09
pred is:
 ['']
 label is:
 ['science fiction']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:18,674 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:18,674 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 112, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:18,675 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:18,675 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:18,675 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:19,615 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:19,617 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418869018554688 s; generated tokens: 1 tokens; generate speed: 1.0616985946296222 tokens/s
2024-06-05 16:20:19,622 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:19,622 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[240/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.7403 tokens/s, remaining time: 0:31:07
pred is:
 ['']
 label is:
 ['Time magazine']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.634259259259259, Em score: 2.5, current_count: 240
2024-06-05 16:20:19,734 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:19,734 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 141, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:19,735 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:19,735 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:19,735 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:20,675 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:20,677 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941554069519043 s; generated tokens: 1 tokens; generate speed: 1.0620738971589936 tokens/s
2024-06-05 16:20:20,682 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:20,682 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[241/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.7376 tokens/s, remaining time: 0:31:06
pred is:
 ['']
 label is:
 ['Computational complexity theory']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:20,763 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:20,763 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 173, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:20,763 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:20,763 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:20,764 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:21,704 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:21,706 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420559406280518 s; generated tokens: 1 tokens; generate speed: 1.0615080876548775 tokens/s
2024-06-05 16:20:21,711 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:21,711 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[242/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.7350 tokens/s, remaining time: 0:31:04
pred is:
 ['']
 label is:
 ['if its solution requires significant resources']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:21,792 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:21,793 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 182, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:21,793 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:21,793 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:21,793 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:22,734 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:22,736 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419870376586914 s; generated tokens: 1 tokens; generate speed: 1.0615857331598744 tokens/s
2024-06-05 16:20:22,740 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:22,741 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[243/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7323 tokens/s, remaining time: 0:31:03
pred is:
 ['']
 label is:
 ['analysis of algorithms and computability theory']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:22,822 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:22,822 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 214, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:22,822 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:22,823 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:22,823 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:23,764 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:23,766 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427289962768555 s; generated tokens: 1 tokens; generate speed: 1.0607502303942347 tokens/s
2024-06-05 16:20:23,770 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:23,771 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[244/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0485 tokens/s, avg speed: 1.7297 tokens/s, remaining time: 0:31:01
pred is:
 ['']
 label is:
 ['problem instance']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:23,851 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:23,851 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 167, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:23,852 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:23,852 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:23,852 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:24,793 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:24,794 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942084550857544 s; generated tokens: 1 tokens; generate speed: 1.0614758506439128 tokens/s
2024-06-05 16:20:24,799 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:24,799 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[245/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7271 tokens/s, remaining time: 0:31:00
pred is:
 ['']
 label is:
 ['2000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:24,880 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:24,880 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 150, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:24,881 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:24,881 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:24,881 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:25,821 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:25,823 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941852331161499 s; generated tokens: 1 tokens; generate speed: 1.061737564281221 tokens/s
2024-06-05 16:20:25,828 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:25,828 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[246/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7245 tokens/s, remaining time: 0:30:58
pred is:
 ['']
 label is:
 ['problem instance']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:25,909 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:25,909 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 192, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:25,910 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:25,910 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:25,910 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:26,850 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:26,852 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420833587646484 s; generated tokens: 1 tokens; generate speed: 1.0614771938136107 tokens/s
2024-06-05 16:20:26,857 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:26,857 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[247/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7220 tokens/s, remaining time: 0:30:57
pred is:
 ['']
 label is:
 ['Decision problems']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:26,940 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:26,941 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 128, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:26,941 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:26,941 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:26,941 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:27,881 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:27,883 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410390853881836 s; generated tokens: 1 tokens; generate speed: 1.062655117653795 tokens/s
2024-06-05 16:20:27,887 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:27,888 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[248/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.7194 tokens/s, remaining time: 0:30:55
pred is:
 ['']
 label is:
 ['arbitrary graph']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:27,969 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:27,969 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 110, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:27,969 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:27,969 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:27,970 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:28,909 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:28,911 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9408285617828369 s; generated tokens: 1 tokens; generate speed: 1.062892901662164 tokens/s
2024-06-05 16:20:28,915 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:28,916 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[249/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0506 tokens/s, avg speed: 1.7169 tokens/s, remaining time: 0:30:54
pred is:
 ['']
 label is:
 ['a computational problem']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:28,997 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:28,997 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 145, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:28,998 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:28,998 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:28,998 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:29,938 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:29,940 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417853355407715 s; generated tokens: 1 tokens; generate speed: 1.0618130929229237 tokens/s
2024-06-05 16:20:29,945 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:29,945 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[250/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.7144 tokens/s, remaining time: 0:30:52
pred is:
 ['']
 label is:
 ['decision problems']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.4888888888888885, Em score: 2.4, current_count: 250
2024-06-05 16:20:30,059 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:30,059 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 216, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:30,060 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:30,060 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:30,060 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:31,001 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:31,003 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432070255279541 s; generated tokens: 1 tokens; generate speed: 1.060212628760114 tokens/s
2024-06-05 16:20:31,008 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:31,008 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[251/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.7120 tokens/s, remaining time: 0:30:51
pred is:
 ['']
 label is:
 ['how much time the best algorithm requires to solve the problem']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:31,090 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:31,090 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 168, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:31,090 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:31,091 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:31,091 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:32,031 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:32,033 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418628215789795 s; generated tokens: 1 tokens; generate speed: 1.0617257387052998 tokens/s
2024-06-05 16:20:32,037 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:32,038 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[252/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.7095 tokens/s, remaining time: 0:30:49
pred is:
 ['']
 label is:
 ["Cobham's thesis"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:32,119 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:32,120 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 246, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:32,120 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:32,120 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:32,121 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:33,063 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:33,065 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438393115997314 s; generated tokens: 1 tokens; generate speed: 1.0595023832023702 tokens/s
2024-06-05 16:20:33,069 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:33,070 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[253/2067], cost time 0.9552s, every example cost time is 0.9552, generate speed: 1.0469 tokens/s, avg speed: 1.7070 tokens/s, remaining time: 0:30:48
pred is:
 ['']
 label is:
 ['A Turing machine']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:33,151 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:33,152 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 245, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:33,152 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:33,152 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:33,152 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:34,094 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:34,096 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435741901397705 s; generated tokens: 1 tokens; generate speed: 1.0598000776726113 tokens/s
2024-06-05 16:20:34,101 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:34,101 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[254/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0473 tokens/s, avg speed: 1.7046 tokens/s, remaining time: 0:30:46
pred is:
 ['']
 label is:
 ['A deterministic Turing machine']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:34,207 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:34,208 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 123, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:34,208 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:34,208 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:34,208 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:35,148 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:35,187 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:35,217 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:35,246 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:35,275 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:35,303 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:35,332 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:35,362 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:35,391 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:35,420 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:35,729 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5204920768737793 s; generated tokens: 20 tokens; generate speed: 13.1536364471699 tokens/s
2024-06-05 16:20:35,734 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:35,734 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[255/2067], cost time 1.5320s, every example cost time is 1.5320, generate speed: 13.0550 tokens/s, avg speed: 1.7714 tokens/s, remaining time: 0:30:49
pred is:
 ['A. complexity classes']
 label is:
 ['complexity classes']
The F1/Em of this example is:  {'F1': 66.66666666666666, 'Em': 0.0}
2024-06-05 16:20:35,816 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:35,817 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 131, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:35,817 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:35,817 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:35,818 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:36,756 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:36,759 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409692287445068 s; generated tokens: 1 tokens; generate speed: 1.0627340081399423 tokens/s
2024-06-05 16:20:36,763 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:36,764 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[256/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.7688 tokens/s, remaining time: 0:30:47
pred is:
 ['']
 label is:
 ['random access machines']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:36,846 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:36,846 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 153, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:36,846 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:36,846 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:36,847 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:37,786 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:37,788 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413697719573975 s; generated tokens: 1 tokens; generate speed: 1.06228182568545 tokens/s
2024-06-05 16:20:37,793 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:37,793 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[257/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.7662 tokens/s, remaining time: 0:30:46
pred is:
 ['']
 label is:
 ['non-deterministic']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:37,873 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:37,874 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 244, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:37,874 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:37,874 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:37,874 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:38,815 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:38,817 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425663948059082 s; generated tokens: 1 tokens; generate speed: 1.0609332196761783 tokens/s
2024-06-05 16:20:38,822 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:38,822 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[258/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.7636 tokens/s, remaining time: 0:30:44
pred is:
 ['']
 label is:
 ['state transitions']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:38,930 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:38,930 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 118, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:38,931 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:38,931 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:38,931 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:39,870 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:39,872 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409670829772949 s; generated tokens: 1 tokens; generate speed: 1.0627364315826227 tokens/s
2024-06-05 16:20:39,877 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:39,877 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[259/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.7610 tokens/s, remaining time: 0:30:43
pred is:
 ['']
 label is:
 ['complexity resources']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:39,957 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:39,958 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 104, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:39,958 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:39,958 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:39,958 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:40,898 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:40,899 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407682418823242 s; generated tokens: 1 tokens; generate speed: 1.0629610519155734 tokens/s
2024-06-05 16:20:40,904 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:40,904 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[260/2067], cost time 0.9517s, every example cost time is 0.9517, generate speed: 1.0507 tokens/s, avg speed: 1.7585 tokens/s, remaining time: 0:30:41
pred is:
 ['']
 label is:
 ['best, worst and average']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.6111111111111107, Em score: 2.3076923076923075, current_count: 260
2024-06-05 16:20:41,021 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:41,021 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 163, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:41,022 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:41,022 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:41,022 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:41,962 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:41,964 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418618679046631 s; generated tokens: 1 tokens; generate speed: 1.061726813746771 tokens/s
2024-06-05 16:20:41,969 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:41,969 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[261/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.7559 tokens/s, remaining time: 0:30:40
pred is:
 ['']
 label is:
 ['deterministic sorting algorithm quicksort']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:42,050 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:42,051 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 246, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:42,051 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:42,051 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:42,051 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:42,993 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:43,023 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:43,052 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:43,082 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:43,111 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:43,140 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:43,169 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:43,198 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:43,228 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:43,258 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:43,551 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4995272159576416 s; generated tokens: 20 tokens; generate speed: 13.337537183163041 tokens/s
2024-06-05 16:20:43,556 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:43,556 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[262/2067], cost time 1.5108s, every example cost time is 1.5108, generate speed: 13.2380 tokens/s, avg speed: 1.8208 tokens/s, remaining time: 0:30:42
pred is:
 ['A. The most efficient algorithm solving a given problem']
 label is:
 ['the most efficient algorithm']
The F1/Em of this example is:  {'F1': 56.00000000000001, 'Em': 0.0}
2024-06-05 16:20:43,664 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:43,665 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 122, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:43,665 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:43,665 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:43,666 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:44,605 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:44,607 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411256313323975 s; generated tokens: 1 tokens; generate speed: 1.0625573958539958 tokens/s
2024-06-05 16:20:44,611 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:44,612 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[263/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.8181 tokens/s, remaining time: 0:30:41
pred is:
 ['']
 label is:
 ['big O notation']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:44,692 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:44,693 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 80, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:44,693 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:44,693 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:44,693 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:45,632 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:45,634 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9402694702148438 s; generated tokens: 1 tokens; generate speed: 1.0635249060798584 tokens/s
2024-06-05 16:20:45,638 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:45,639 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[264/2067], cost time 0.9511s, every example cost time is 0.9511, generate speed: 1.0514 tokens/s, avg speed: 1.8153 tokens/s, remaining time: 0:30:39
pred is:
 ['']
 label is:
 ['complexity classes']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:45,719 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:45,720 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 205, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:45,720 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:45,720 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:45,720 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:46,662 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:46,664 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429035186767578 s; generated tokens: 1 tokens; generate speed: 1.0605538956980134 tokens/s
2024-06-05 16:20:46,668 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:46,668 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[265/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.8126 tokens/s, remaining time: 0:30:38
pred is:
 ['']
 label is:
 ['chosen machine model']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:46,749 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:46,749 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 87, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:46,750 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:46,750 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:46,750 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:47,689 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:47,691 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404559135437012 s; generated tokens: 1 tokens; generate speed: 1.0633140645922814 tokens/s
2024-06-05 16:20:47,695 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:47,695 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[266/2067], cost time 0.9512s, every example cost time is 0.9512, generate speed: 1.0513 tokens/s, avg speed: 1.8100 tokens/s, remaining time: 0:30:36
pred is:
 ['']
 label is:
 ['time or space']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:47,776 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:47,776 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 140, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:47,777 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:47,777 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:47,777 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:48,717 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:48,718 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412398338317871 s; generated tokens: 1 tokens; generate speed: 1.0624284736537342 tokens/s
2024-06-05 16:20:48,723 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:48,723 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[267/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.8073 tokens/s, remaining time: 0:30:35
pred is:
 ['']
 label is:
 ['BPP, ZPP and RP']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:48,828 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:48,829 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 228, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:48,829 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:48,829 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:48,830 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:49,771 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:49,773 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428653717041016 s; generated tokens: 1 tokens; generate speed: 1.0605968041785598 tokens/s
2024-06-05 16:20:49,777 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:49,777 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[268/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.8047 tokens/s, remaining time: 0:30:33
pred is:
 ['']
 label is:
 ['computation time']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:49,857 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:49,858 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 104, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:49,858 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:49,858 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:49,858 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:50,798 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:50,800 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410734176635742 s; generated tokens: 1 tokens; generate speed: 1.0626163498303078 tokens/s
2024-06-05 16:20:50,804 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:50,805 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[269/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0506 tokens/s, avg speed: 1.8020 tokens/s, remaining time: 0:30:32
pred is:
 ['']
 label is:
 ['time and space hierarchy theorems']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:50,887 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:50,887 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 169, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:50,887 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:50,888 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:50,888 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:51,828 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:51,830 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418292045593262 s; generated tokens: 1 tokens; generate speed: 1.0617636352313915 tokens/s
2024-06-05 16:20:51,834 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:51,835 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[270/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0492 tokens/s, avg speed: 1.7994 tokens/s, remaining time: 0:30:30
pred is:
 ['']
 label is:
 ['reduction']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.68477366255144, Em score: 2.2222222222222223, current_count: 270
2024-06-05 16:20:51,952 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:51,952 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 148, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:51,953 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:51,953 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:51,953 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:52,893 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:52,895 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417979717254639 s; generated tokens: 1 tokens; generate speed: 1.0617988464849892 tokens/s
2024-06-05 16:20:52,900 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:52,900 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[271/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.7968 tokens/s, remaining time: 0:30:29
pred is:
 ['']
 label is:
 ['polynomial-time reduction']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:52,983 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:52,983 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:52,983 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:52,984 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:52,984 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:53,926 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:53,928 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437856674194336 s; generated tokens: 1 tokens; generate speed: 1.0595626046475908 tokens/s
2024-06-05 16:20:53,932 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:53,933 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[272/2067], cost time 0.9554s, every example cost time is 0.9554, generate speed: 1.0467 tokens/s, avg speed: 1.7943 tokens/s, remaining time: 0:30:27
pred is:
 ['']
 label is:
 ['the type of reduction being used']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:54,014 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:54,014 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 238, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:54,014 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:54,015 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:54,015 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:54,956 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:54,958 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430017471313477 s; generated tokens: 1 tokens; generate speed: 1.0604434223394001 tokens/s
2024-06-05 16:20:54,963 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:54,963 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[273/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0484 tokens/s, avg speed: 1.7917 tokens/s, remaining time: 0:30:26
pred is:
 ['']
 label is:
 ['NP-complete']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:55,044 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:55,044 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 164, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:55,044 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:55,044 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:55,045 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:55,985 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:55,987 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417710304260254 s; generated tokens: 1 tokens; generate speed: 1.0618292214272442 tokens/s
2024-06-05 16:20:55,991 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:55,991 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[274/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.7892 tokens/s, remaining time: 0:30:25
pred is:
 ['']
 label is:
 ['P']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:56,072 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:56,072 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 179, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:56,073 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:56,073 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:56,073 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:57,014 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:57,016 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421591758728027 s; generated tokens: 1 tokens; generate speed: 1.0613917749870816 tokens/s
2024-06-05 16:20:57,020 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:57,020 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[275/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7866 tokens/s, remaining time: 0:30:23
pred is:
 ['']
 label is:
 ['more efficient solutions']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:57,101 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:57,101 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 140, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:57,102 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:57,102 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:57,102 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:58,042 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:58,044 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418437480926514 s; generated tokens: 1 tokens; generate speed: 1.0617472399483696 tokens/s
2024-06-05 16:20:58,049 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:58,049 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[276/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.7841 tokens/s, remaining time: 0:30:22
pred is:
 ['']
 label is:
 ['Ladner']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:58,130 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:58,130 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 208, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:58,131 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:58,131 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:58,131 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:20:59,072 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:59,074 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942669153213501 s; generated tokens: 1 tokens; generate speed: 1.0608175695481938 tokens/s
2024-06-05 16:20:59,078 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:20:59,079 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[277/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.7817 tokens/s, remaining time: 0:30:20
pred is:
 ['']
 label is:
 ['The graph isomorphism problem']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:20:59,160 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:20:59,160 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 271, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:20:59,160 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:20:59,161 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:20:59,161 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:00,103 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:00,105 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9440996646881104 s; generated tokens: 1 tokens; generate speed: 1.059210205662298 tokens/s
2024-06-05 16:21:00,110 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:00,110 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[278/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.7792 tokens/s, remaining time: 0:30:19
pred is:
 ['']
 label is:
 ['The integer factorization problem']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:00,191 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:00,191 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:00,191 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:00,192 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:00,192 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:01,132 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:01,134 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417498111724854 s; generated tokens: 1 tokens; generate speed: 1.0618531462777707 tokens/s
2024-06-05 16:21:01,138 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:01,139 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[279/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7767 tokens/s, remaining time: 0:30:17
pred is:
 ['']
 label is:
 ['suspected to be unequal']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:01,220 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:01,220 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 125, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:01,221 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:01,221 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:01,221 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:02,161 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:02,163 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412868022918701 s; generated tokens: 1 tokens; generate speed: 1.0623754604496456 tokens/s
2024-06-05 16:21:02,167 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:02,168 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[280/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.7743 tokens/s, remaining time: 0:30:16
pred is:
 ['']
 label is:
 ['co-NP']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.553174603174603, Em score: 2.142857142857143, current_count: 280
2024-06-05 16:21:02,310 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:02,310 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 115, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:02,311 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:02,311 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:02,311 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:03,250 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:03,253 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413213729858398 s; generated tokens: 1 tokens; generate speed: 1.0623364439585956 tokens/s
2024-06-05 16:21:03,257 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:03,258 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[281/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.7719 tokens/s, remaining time: 0:30:15
pred is:
 ['']
 label is:
 ['L']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:03,338 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:03,339 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 351, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:03,339 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:03,339 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:03,339 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:04,283 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:04,285 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.945091962814331 s; generated tokens: 1 tokens; generate speed: 1.0580980892294987 tokens/s
2024-06-05 16:21:04,289 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:04,290 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[282/2067], cost time 0.9559s, every example cost time is 0.9559, generate speed: 1.0461 tokens/s, avg speed: 1.7695 tokens/s, remaining time: 0:30:13
pred is:
 ['']
 label is:
 ['intractable problems']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:04,370 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:04,370 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 170, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:04,371 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:04,371 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:04,371 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:05,311 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:05,313 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417526721954346 s; generated tokens: 1 tokens; generate speed: 1.0618499203923446 tokens/s
2024-06-05 16:21:05,318 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:05,318 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[283/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7671 tokens/s, remaining time: 0:30:12
pred is:
 ['']
 label is:
 ['Presburger arithmetic']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:05,399 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:05,399 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 118, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:05,399 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:05,400 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:05,400 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:06,339 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:06,341 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407551288604736 s; generated tokens: 1 tokens; generate speed: 1.0629758683444959 tokens/s
2024-06-05 16:21:06,345 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:06,346 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[284/2067], cost time 0.9516s, every example cost time is 0.9516, generate speed: 1.0509 tokens/s, avg speed: 1.7647 tokens/s, remaining time: 0:30:10
pred is:
 ['']
 label is:
 ['foundations were laid out']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:06,427 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:06,427 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 151, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:06,427 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:06,427 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:06,428 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:07,368 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:07,370 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425563812255859 s; generated tokens: 1 tokens; generate speed: 1.0609444908746162 tokens/s
2024-06-05 16:21:07,375 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:07,375 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[285/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.7623 tokens/s, remaining time: 0:30:09
pred is:
 ['']
 label is:
 ['On the Computational Complexity of Algorithms']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:07,456 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:07,456 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 150, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:07,457 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:07,457 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:07,457 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:08,397 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:08,399 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417099952697754 s; generated tokens: 1 tokens; generate speed: 1.0618980418844615 tokens/s
2024-06-05 16:21:08,404 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:08,404 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[286/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.7600 tokens/s, remaining time: 0:30:08
pred is:
 ['']
 label is:
 ['John Myhill']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:08,485 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:08,485 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 111, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:08,485 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:08,486 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:08,486 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:09,425 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:09,426 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.940467357635498 s; generated tokens: 1 tokens; generate speed: 1.0633011256384035 tokens/s
2024-06-05 16:21:09,431 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:09,431 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[287/2067], cost time 0.9512s, every example cost time is 0.9512, generate speed: 1.0513 tokens/s, avg speed: 1.7577 tokens/s, remaining time: 0:30:06
pred is:
 ['']
 label is:
 ['input encoding']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:09,512 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:09,512 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:09,513 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:09,513 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:09,513 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:10,453 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:10,455 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416592121124268 s; generated tokens: 1 tokens; generate speed: 1.061955309454996 tokens/s
2024-06-05 16:21:10,460 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:10,460 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[288/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.7554 tokens/s, remaining time: 0:30:05
pred is:
 ['']
 label is:
 ['Manuel Blum']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:10,540 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:10,540 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 158, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:10,541 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:10,541 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:10,541 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:11,481 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:11,483 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417111873626709 s; generated tokens: 1 tokens; generate speed: 1.0618966976494897 tokens/s
2024-06-05 16:21:11,488 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:11,488 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[289/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.7531 tokens/s, remaining time: 0:30:03
pred is:
 ['']
 label is:
 ['the curriculum.']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:11,569 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:11,569 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 88, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:11,570 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:11,570 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:11,570 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:12,509 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:12,511 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404816627502441 s; generated tokens: 1 tokens; generate speed: 1.0632849523888714 tokens/s
2024-06-05 16:21:12,516 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:12,516 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[290/2067], cost time 0.9513s, every example cost time is 0.9513, generate speed: 1.0512 tokens/s, avg speed: 1.7508 tokens/s, remaining time: 0:30:02
pred is:
 ['']
 label is:
 ['cultures']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.4306513409961683, Em score: 2.0689655172413794, current_count: 290
2024-06-05 16:21:12,637 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:12,637 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 98, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:12,638 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:12,638 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:12,638 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:13,577 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:13,580 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941256046295166 s; generated tokens: 1 tokens; generate speed: 1.0624101740818062 tokens/s
2024-06-05 16:21:13,584 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:13,585 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[291/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.7486 tokens/s, remaining time: 0:30:01
pred is:
 ['']
 label is:
 ['family member']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:13,665 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:13,666 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 89, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:13,666 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:13,666 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:13,667 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:14,606 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:14,608 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9408025741577148 s; generated tokens: 1 tokens; generate speed: 1.0629222617670702 tokens/s
2024-06-05 16:21:14,612 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:14,613 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[292/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.7463 tokens/s, remaining time: 0:29:59
pred is:
 ['']
 label is:
 ['spiritual']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:14,693 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:14,694 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 111, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:14,694 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:14,694 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:14,694 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:15,634 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:15,635 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407632350921631 s; generated tokens: 1 tokens; generate speed: 1.0629667090487795 tokens/s
2024-06-05 16:21:15,640 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:15,640 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[293/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0507 tokens/s, avg speed: 1.7441 tokens/s, remaining time: 0:29:58
pred is:
 ['']
 label is:
 ['homeschooling']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:15,720 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:15,720 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 106, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:15,721 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:15,721 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:15,721 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:16,660 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:16,662 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404013156890869 s; generated tokens: 1 tokens; generate speed: 1.0633757985198495 tokens/s
2024-06-05 16:21:16,666 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:16,667 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[294/2067], cost time 0.9512s, every example cost time is 0.9512, generate speed: 1.0513 tokens/s, avg speed: 1.7419 tokens/s, remaining time: 0:29:56
pred is:
 ['']
 label is:
 ['school functions']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:16,747 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:16,748 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 107, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:16,748 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:16,748 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:16,748 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:17,688 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:17,689 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407191276550293 s; generated tokens: 1 tokens; generate speed: 1.0630165483003866 tokens/s
2024-06-05 16:21:17,694 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:17,694 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[295/2067], cost time 0.9515s, every example cost time is 0.9515, generate speed: 1.0509 tokens/s, avg speed: 1.7397 tokens/s, remaining time: 0:29:55
pred is:
 ['']
 label is:
 ["teacher's colleges"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:17,781 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:17,781 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:17,782 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:17,782 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:17,782 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:18,723 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:18,725 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426217079162598 s; generated tokens: 1 tokens; generate speed: 1.0608709640377152 tokens/s
2024-06-05 16:21:18,730 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:18,730 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[296/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.7375 tokens/s, remaining time: 0:29:54
pred is:
 ['']
 label is:
 ['members']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:18,811 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:18,811 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 89, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:18,812 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:18,812 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:18,812 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:19,751 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:19,752 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9403400421142578 s; generated tokens: 1 tokens; generate speed: 1.0634450892377219 tokens/s
2024-06-05 16:21:19,757 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:19,757 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[297/2067], cost time 0.9511s, every example cost time is 0.9511, generate speed: 1.0514 tokens/s, avg speed: 1.7353 tokens/s, remaining time: 0:29:52
pred is:
 ['']
 label is:
 ['outdoors']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:19,843 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:19,843 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:19,844 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:19,844 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:19,844 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:20,784 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:20,786 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417374134063721 s; generated tokens: 1 tokens; generate speed: 1.0618671253411134 tokens/s
2024-06-05 16:21:20,790 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:20,791 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[298/2067], cost time 0.9574s, every example cost time is 0.9574, generate speed: 1.0445 tokens/s, avg speed: 1.7331 tokens/s, remaining time: 0:29:51
pred is:
 ['']
 label is:
 ['informal']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:20,872 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:20,872 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 103, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:20,872 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:20,873 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:20,873 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:21,812 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:21,814 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9408109188079834 s; generated tokens: 1 tokens; generate speed: 1.0629128340336544 tokens/s
2024-06-05 16:21:21,818 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:21,819 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[299/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0505 tokens/s, avg speed: 1.7310 tokens/s, remaining time: 0:29:49
pred is:
 ['']
 label is:
 ['skill']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:21,899 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:21,899 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 279, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:21,900 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:21,900 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:21,900 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:22,842 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:22,844 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437210559844971 s; generated tokens: 1 tokens; generate speed: 1.0596351471217227 tokens/s
2024-06-05 16:21:22,849 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:22,849 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[300/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0477 tokens/s, avg speed: 1.7288 tokens/s, remaining time: 0:29:48
pred is:
 ['']
 label is:
 ['particular skills']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.316296296296296, Em score: 2.0, current_count: 300
2024-06-05 16:21:22,971 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:22,971 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 158, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:22,972 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:22,972 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:22,972 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:23,912 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:23,914 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942213773727417 s; generated tokens: 1 tokens; generate speed: 1.0613302712015973 tokens/s
2024-06-05 16:21:23,919 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:23,919 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[301/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.7267 tokens/s, remaining time: 0:29:47
pred is:
 ['']
 label is:
 ['the relationship between teachers and children']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:24,001 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:24,001 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 166, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:24,001 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:24,001 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:24,002 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:24,942 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:24,944 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418525695800781 s; generated tokens: 1 tokens; generate speed: 1.0617372955152065 tokens/s
2024-06-05 16:21:24,948 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:24,949 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[302/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.7246 tokens/s, remaining time: 0:29:45
pred is:
 ['']
 label is:
 ['alternative']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:25,029 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:25,029 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 124, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:25,030 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:25,030 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:25,030 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:25,970 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:25,972 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411323070526123 s; generated tokens: 1 tokens; generate speed: 1.0625498588309505 tokens/s
2024-06-05 16:21:25,976 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:25,976 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[303/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.7225 tokens/s, remaining time: 0:29:44
pred is:
 ['']
 label is:
 ['Co-teaching']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:26,057 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:26,057 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 95, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:26,058 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:26,058 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:26,058 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:26,997 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:26,999 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9405713081359863 s; generated tokens: 1 tokens; generate speed: 1.0631836112264457 tokens/s
2024-06-05 16:21:27,004 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:27,004 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[304/2067], cost time 0.9513s, every example cost time is 0.9513, generate speed: 1.0512 tokens/s, avg speed: 1.7204 tokens/s, remaining time: 0:29:43
pred is:
 ['']
 label is:
 ['corporal punishment']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:27,090 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:27,090 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 142, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:27,091 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:27,091 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:27,091 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:28,031 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:28,033 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417831897735596 s; generated tokens: 1 tokens; generate speed: 1.0618155121673365 tokens/s
2024-06-05 16:21:28,038 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:28,038 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[305/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.7183 tokens/s, remaining time: 0:29:41
pred is:
 ['']
 label is:
 ['one of the most common']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:28,119 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:28,119 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 167, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:28,119 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:28,120 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:28,120 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:29,059 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:29,061 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415249824523926 s; generated tokens: 1 tokens; generate speed: 1.0621067084118123 tokens/s
2024-06-05 16:21:29,066 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:29,066 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[306/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.7163 tokens/s, remaining time: 0:29:40
pred is:
 ['']
 label is:
 ['30']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:29,147 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:29,147 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 84, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:29,147 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:29,148 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:29,148 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:30,086 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:30,088 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9400978088378906 s; generated tokens: 1 tokens; generate speed: 1.063719105181362 tokens/s
2024-06-05 16:21:30,093 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:30,093 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[307/2067], cost time 0.9509s, every example cost time is 0.9509, generate speed: 1.0516 tokens/s, avg speed: 1.7142 tokens/s, remaining time: 0:29:39
pred is:
 ['']
 label is:
 ['caning']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:30,173 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:30,173 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 148, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:30,174 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:30,174 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:30,174 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:31,114 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:31,115 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410812854766846 s; generated tokens: 1 tokens; generate speed: 1.062607465935816 tokens/s
2024-06-05 16:21:31,120 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:31,120 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[308/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0506 tokens/s, avg speed: 1.7122 tokens/s, remaining time: 0:29:37
pred is:
 ['']
 label is:
 ['detention']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:31,201 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:31,201 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 140, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:31,201 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:31,202 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:31,202 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:32,142 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:32,144 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94158935546875 s; generated tokens: 1 tokens; generate speed: 1.06203409606534 tokens/s
2024-06-05 16:21:32,148 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:32,148 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[309/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.7102 tokens/s, remaining time: 0:29:36
pred is:
 ['']
 label is:
 ['assertive']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:32,229 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:32,229 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 142, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:32,229 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:32,230 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:32,230 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:33,169 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:33,171 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413573741912842 s; generated tokens: 1 tokens; generate speed: 1.062295816038086 tokens/s
2024-06-05 16:21:33,176 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:33,176 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[310/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.7082 tokens/s, remaining time: 0:29:35
pred is:
 ['']
 label is:
 ['some teachers and parents']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.2093189964157705, Em score: 1.935483870967742, current_count: 310
2024-06-05 16:21:33,301 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:33,301 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 146, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:33,301 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:33,301 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:33,302 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:34,241 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:34,243 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414713382720947 s; generated tokens: 1 tokens; generate speed: 1.0621672262857458 tokens/s
2024-06-05 16:21:34,248 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:34,248 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[311/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.7062 tokens/s, remaining time: 0:29:33
pred is:
 ['']
 label is:
 ['Japan']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:34,329 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:34,329 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 143, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:34,330 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:34,330 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:34,330 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:35,270 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:35,272 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414334297180176 s; generated tokens: 1 tokens; generate speed: 1.0622099964089065 tokens/s
2024-06-05 16:21:35,276 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:35,277 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[312/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.7042 tokens/s, remaining time: 0:29:32
pred is:
 ['']
 label is:
 ['40 to 50 students']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:35,358 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:35,358 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 225, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:35,358 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:35,358 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:35,359 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:36,300 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:36,302 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428389072418213 s; generated tokens: 1 tokens; generate speed: 1.0606265739768819 tokens/s
2024-06-05 16:21:36,306 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:36,306 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[313/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.7022 tokens/s, remaining time: 0:29:31
pred is:
 ['']
 label is:
 ['popularly based authority']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:36,387 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:36,388 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 200, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:36,388 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:36,388 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:36,388 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:37,329 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:37,331 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422261714935303 s; generated tokens: 1 tokens; generate speed: 1.061316306269536 tokens/s
2024-06-05 16:21:37,335 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:37,336 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[314/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.7003 tokens/s, remaining time: 0:29:29
pred is:
 ['']
 label is:
 ['enthusiasm']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:37,417 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:37,417 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 167, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:37,417 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:37,417 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:37,418 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:38,358 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:38,360 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419915676116943 s; generated tokens: 1 tokens; generate speed: 1.0615806280892504 tokens/s
2024-06-05 16:21:38,364 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:38,365 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[315/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.6983 tokens/s, remaining time: 0:29:28
pred is:
 ['']
 label is:
 ['teacher enthusiasm']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:38,445 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:38,446 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 217, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:38,446 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:38,446 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:38,446 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:39,387 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:39,390 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943178653717041 s; generated tokens: 1 tokens; generate speed: 1.0602445210767097 tokens/s
2024-06-05 16:21:39,394 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:39,395 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[316/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.6964 tokens/s, remaining time: 0:29:27
pred is:
 ['']
 label is:
 ['self-determined']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:39,482 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:39,482 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 187, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:39,483 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:39,483 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:39,483 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:40,424 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:40,426 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423866271972656 s; generated tokens: 1 tokens; generate speed: 1.0611356009731179 tokens/s
2024-06-05 16:21:40,430 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:40,431 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[317/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.6944 tokens/s, remaining time: 0:29:25
pred is:
 ['']
 label is:
 ['student-teacher relationships']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:40,512 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:40,512 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 123, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:40,512 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:40,513 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:40,513 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:41,453 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:41,454 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414284229278564 s; generated tokens: 1 tokens; generate speed: 1.062215645550604 tokens/s
2024-06-05 16:21:41,459 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:41,459 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[318/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.6925 tokens/s, remaining time: 0:29:24
pred is:
 ['']
 label is:
 ['friendly and supportive']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:41,540 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:41,540 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 220, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:41,540 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:41,541 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:41,541 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:42,481 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:42,483 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942394495010376 s; generated tokens: 1 tokens; generate speed: 1.0611267418205683 tokens/s
2024-06-05 16:21:42,488 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:42,488 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[319/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.6906 tokens/s, remaining time: 0:29:23
pred is:
 ['']
 label is:
 ['enthusiasm about the students']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:42,569 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:42,569 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 130, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:42,570 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:42,570 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:42,570 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:43,510 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:43,512 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414582252502441 s; generated tokens: 1 tokens; generate speed: 1.0621820205927832 tokens/s
2024-06-05 16:21:43,516 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:43,517 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[320/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.6887 tokens/s, remaining time: 0:29:21
pred is:
 ['']
 label is:
 ['sexual misconduct']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.1090277777777775, Em score: 1.875, current_count: 320
2024-06-05 16:21:43,641 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:43,641 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 279, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:43,642 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:43,642 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:43,642 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:44,584 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:44,587 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9444215297698975 s; generated tokens: 1 tokens; generate speed: 1.058849219843224 tokens/s
2024-06-05 16:21:44,591 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:44,591 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[321/2067], cost time 0.9556s, every example cost time is 0.9556, generate speed: 1.0465 tokens/s, avg speed: 1.6868 tokens/s, remaining time: 0:29:20
pred is:
 ['']
 label is:
 ['England']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:44,673 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:44,673 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 86, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:44,673 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:44,673 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:44,674 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:45,613 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:45,615 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409122467041016 s; generated tokens: 1 tokens; generate speed: 1.0627983677573285 tokens/s
2024-06-05 16:21:45,619 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:45,620 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[322/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0505 tokens/s, avg speed: 1.6850 tokens/s, remaining time: 0:29:19
pred is:
 ['']
 label is:
 ['United States']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:45,701 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:45,701 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 158, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:45,701 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:45,702 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:45,702 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:46,642 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:46,644 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416272640228271 s; generated tokens: 1 tokens; generate speed: 1.0619913401060548 tokens/s
2024-06-05 16:21:46,648 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:46,648 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[323/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.6831 tokens/s, remaining time: 0:29:17
pred is:
 ['']
 label is:
 ['Fears of being labelled a pedophile or hebephile']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:46,739 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:46,739 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 130, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:46,740 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:46,740 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:46,740 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:47,679 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:47,681 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410402774810791 s; generated tokens: 1 tokens; generate speed: 1.0626537715014077 tokens/s
2024-06-05 16:21:47,686 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:47,686 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[324/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.6813 tokens/s, remaining time: 0:29:16
pred is:
 ['']
 label is:
 ['occupational stress']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:47,766 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:47,767 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 104, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:47,767 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:47,767 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:47,768 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:48,707 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:48,709 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415600299835205 s; generated tokens: 1 tokens; generate speed: 1.0620671737918848 tokens/s
2024-06-05 16:21:48,714 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:48,714 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[325/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.6794 tokens/s, remaining time: 0:29:15
pred is:
 ['']
 label is:
 ['42%']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:48,795 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:48,795 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 124, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:48,795 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:48,796 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:48,796 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:49,735 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:49,737 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413270950317383 s; generated tokens: 1 tokens; generate speed: 1.062329986333054 tokens/s
2024-06-05 16:21:49,742 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:49,742 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[326/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.6776 tokens/s, remaining time: 0:29:14
pred is:
 ['']
 label is:
 ['several']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:49,823 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:49,824 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 191, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:49,824 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:49,824 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:49,825 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:50,767 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:50,768 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435906410217285 s; generated tokens: 1 tokens; generate speed: 1.0597816007555891 tokens/s
2024-06-05 16:21:50,773 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:50,773 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[327/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0473 tokens/s, avg speed: 1.6758 tokens/s, remaining time: 0:29:12
pred is:
 ['']
 label is:
 ['a university or college']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:50,854 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:50,855 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 105, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:50,855 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:50,855 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:50,855 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:51,795 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:51,796 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.940955638885498 s; generated tokens: 1 tokens; generate speed: 1.0627493567969222 tokens/s
2024-06-05 16:21:51,801 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:51,801 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[328/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0505 tokens/s, avg speed: 1.6740 tokens/s, remaining time: 0:29:11
pred is:
 ['']
 label is:
 ['the individual states and territories']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:51,882 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:51,882 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 138, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:51,883 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:51,883 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:51,883 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:52,823 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:52,825 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413421154022217 s; generated tokens: 1 tokens; generate speed: 1.0623130354395274 tokens/s
2024-06-05 16:21:52,829 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:52,829 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[329/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.6722 tokens/s, remaining time: 0:29:10
pred is:
 ['']
 label is:
 ["a post-secondary degree Bachelor's Degree"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:52,911 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:52,912 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 144, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:52,912 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:52,912 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:52,913 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:53,854 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:53,856 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430718421936035 s; generated tokens: 1 tokens; generate speed: 1.0603646034791798 tokens/s
2024-06-05 16:21:53,860 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:53,861 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[330/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0477 tokens/s, avg speed: 1.6704 tokens/s, remaining time: 0:29:08
pred is:
 ['']
 label is:
 ['civil servants']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.0148148148148146, Em score: 1.8181818181818181, current_count: 330
2024-06-05 16:21:53,988 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:53,989 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 166, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:53,989 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:53,989 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:53,989 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:54,940 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:54,942 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9527745246887207 s; generated tokens: 1 tokens; generate speed: 1.0495662657717557 tokens/s
2024-06-05 16:21:54,947 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:54,947 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[331/2067], cost time 0.9643s, every example cost time is 0.9643, generate speed: 1.0370 tokens/s, avg speed: 1.6686 tokens/s, remaining time: 0:29:07
pred is:
 ['']
 label is:
 ['Extra pay']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:55,028 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:55,028 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 103, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:55,029 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:55,029 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:55,029 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:55,968 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:55,970 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9406473636627197 s; generated tokens: 1 tokens; generate speed: 1.063097648098615 tokens/s
2024-06-05 16:21:55,975 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:55,975 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[332/2067], cost time 0.9514s, every example cost time is 0.9514, generate speed: 1.0510 tokens/s, avg speed: 1.6668 tokens/s, remaining time: 0:29:06
pred is:
 ['']
 label is:
 ['the Teaching Council']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:56,056 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:56,056 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 112, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:56,056 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:56,056 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:56,057 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:56,995 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:56,997 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404101371765137 s; generated tokens: 1 tokens; generate speed: 1.0633658235569416 tokens/s
2024-06-05 16:21:57,002 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:57,002 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[333/2067], cost time 0.9513s, every example cost time is 0.9513, generate speed: 1.0512 tokens/s, avg speed: 1.6651 tokens/s, remaining time: 0:29:05
pred is:
 ['']
 label is:
 ['2006']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:57,084 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:57,084 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 133, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:57,084 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:57,085 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:57,085 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:58,024 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:58,026 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410622119903564 s; generated tokens: 1 tokens; generate speed: 1.0626290029061836 tokens/s
2024-06-05 16:21:58,031 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:58,031 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[334/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.6633 tokens/s, remaining time: 0:29:03
pred is:
 ['']
 label is:
 ['41,004']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:58,112 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:58,112 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 101, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:58,112 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:58,113 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:58,113 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:21:59,052 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:59,054 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407784938812256 s; generated tokens: 1 tokens; generate speed: 1.0629494684497445 tokens/s
2024-06-05 16:21:59,058 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:21:59,059 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[335/2067], cost time 0.9517s, every example cost time is 0.9517, generate speed: 1.0507 tokens/s, avg speed: 1.6616 tokens/s, remaining time: 0:29:02
pred is:
 ['']
 label is:
 ['alternative licensing programs']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:21:59,140 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:21:59,141 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 158, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:21:59,141 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:21:59,141 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:21:59,141 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:00,081 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:00,083 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410967826843262 s; generated tokens: 1 tokens; generate speed: 1.062589967790201 tokens/s
2024-06-05 16:22:00,087 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:00,087 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[336/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.6599 tokens/s, remaining time: 0:29:01
pred is:
 ['']
 label is:
 ['the General Teaching Council for Scotland (GTCS)']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:00,168 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:00,168 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:00,169 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:00,169 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:00,169 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:01,110 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:01,112 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425210952758789 s; generated tokens: 1 tokens; generate speed: 1.0609842103399254 tokens/s
2024-06-05 16:22:01,117 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:01,117 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[337/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.6581 tokens/s, remaining time: 0:28:59
pred is:
 ['']
 label is:
 ['April 2008']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:01,198 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:01,199 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 158, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:01,199 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:01,199 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:01,200 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:02,140 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:02,142 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418139457702637 s; generated tokens: 1 tokens; generate speed: 1.0617808373841278 tokens/s
2024-06-05 16:22:02,146 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:02,146 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[338/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.6564 tokens/s, remaining time: 0:28:58
pred is:
 ['']
 label is:
 ['Wales']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:02,226 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:02,227 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 121, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:02,227 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:02,227 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:02,227 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:03,167 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:03,168 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407918453216553 s; generated tokens: 1 tokens; generate speed: 1.0629343833843516 tokens/s
2024-06-05 16:22:03,173 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:03,173 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[339/2067], cost time 0.9517s, every example cost time is 0.9517, generate speed: 1.0508 tokens/s, avg speed: 1.6547 tokens/s, remaining time: 0:28:57
pred is:
 ['']
 label is:
 ['trade unions']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:03,256 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:03,256 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 205, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:03,256 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:03,257 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:03,257 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:04,198 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:04,199 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424505233764648 s; generated tokens: 1 tokens; generate speed: 1.0610636581932766 tokens/s
2024-06-05 16:22:04,204 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:04,204 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[340/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.6531 tokens/s, remaining time: 0:28:56
pred is:
 ['']
 label is:
 ['each state']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.926143790849673, Em score: 1.7647058823529411, current_count: 340
2024-06-05 16:22:04,333 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:04,333 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 467, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:04,334 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:04,334 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:04,334 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:05,279 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:05,281 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9468507766723633 s; generated tokens: 1 tokens; generate speed: 1.0561326289602102 tokens/s
2024-06-05 16:22:05,286 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:05,286 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[341/2067], cost time 0.9582s, every example cost time is 0.9582, generate speed: 1.0436 tokens/s, avg speed: 1.6513 tokens/s, remaining time: 0:28:54
pred is:
 ['']
 label is:
 ['relatively low salaries']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:05,368 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:05,368 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 471, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:05,368 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:05,368 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:05,369 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:06,313 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:06,315 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9461362361907959 s; generated tokens: 1 tokens; generate speed: 1.0569302408562884 tokens/s
2024-06-05 16:22:06,320 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:06,320 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[342/2067], cost time 0.9569s, every example cost time is 0.9569, generate speed: 1.0450 tokens/s, avg speed: 1.6497 tokens/s, remaining time: 0:28:53
pred is:
 ['']
 label is:
 ['many']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:06,401 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:06,401 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 309, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:06,401 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:06,401 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:06,401 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:07,344 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:07,346 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.944267749786377 s; generated tokens: 1 tokens; generate speed: 1.0590216601448386 tokens/s
2024-06-05 16:22:07,351 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:07,351 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[343/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.6480 tokens/s, remaining time: 0:28:52
pred is:
 ['']
 label is:
 ['LDS Church']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:07,431 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:07,431 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 106, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:07,432 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:07,432 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:07,432 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:08,371 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:08,373 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404194355010986 s; generated tokens: 1 tokens; generate speed: 1.0633553096094341 tokens/s
2024-06-05 16:22:08,377 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:08,378 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[344/2067], cost time 0.9513s, every example cost time is 0.9513, generate speed: 1.0512 tokens/s, avg speed: 1.6463 tokens/s, remaining time: 0:28:51
pred is:
 ['']
 label is:
 ['guru']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:08,458 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:08,458 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 105, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:08,458 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:08,459 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:08,459 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:09,399 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:09,400 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415435791015625 s; generated tokens: 1 tokens; generate speed: 1.0620857304918565 tokens/s
2024-06-05 16:22:09,405 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:09,405 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[345/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0500 tokens/s, avg speed: 1.6447 tokens/s, remaining time: 0:28:49
pred is:
 ['']
 label is:
 ['a Lama']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:09,486 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:09,486 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 222, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:09,486 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:09,487 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:09,487 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:10,427 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:10,430 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429891109466553 s; generated tokens: 1 tokens; generate speed: 1.060457632428133 tokens/s
2024-06-05 16:22:10,435 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:10,435 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[346/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.6431 tokens/s, remaining time: 0:28:48
pred is:
 ['']
 label is:
 ['ulemas']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:10,516 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:10,517 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 248, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:10,517 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:10,517 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:10,517 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:11,458 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:11,460 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426703453063965 s; generated tokens: 1 tokens; generate speed: 1.0608162280473241 tokens/s
2024-06-05 16:22:11,465 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:11,465 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[347/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.6414 tokens/s, remaining time: 0:28:47
pred is:
 ['']
 label is:
 ['German']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:11,546 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:11,546 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:11,547 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:11,547 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:11,547 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:12,487 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:12,489 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418604373931885 s; generated tokens: 1 tokens; generate speed: 1.0617284263130595 tokens/s
2024-06-05 16:22:12,494 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:12,494 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[348/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.6398 tokens/s, remaining time: 0:28:46
pred is:
 ['']
 label is:
 ["gift of God's grace"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:12,575 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:12,576 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 156, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:12,576 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:12,576 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:12,576 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:13,517 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:13,518 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417893886566162 s; generated tokens: 1 tokens; generate speed: 1.0618085232691106 tokens/s
2024-06-05 16:22:13,523 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:13,523 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[349/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.6382 tokens/s, remaining time: 0:28:44
pred is:
 ['']
 label is:
 ['Bible']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:13,604 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:13,604 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 321, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:13,605 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:13,605 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:13,605 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:14,548 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:14,550 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9443559646606445 s; generated tokens: 1 tokens; generate speed: 1.0589227340342486 tokens/s
2024-06-05 16:22:14,554 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:14,554 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[350/2067], cost time 0.9552s, every example cost time is 0.9552, generate speed: 1.0469 tokens/s, avg speed: 1.6366 tokens/s, remaining time: 0:28:43
pred is:
 ['']
 label is:
 ['10 November 1483']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.8425396825396825, Em score: 1.7142857142857142, current_count: 350
2024-06-05 16:22:14,683 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:14,683 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 119, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:14,684 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:14,684 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:14,684 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:15,623 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:15,654 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:15,684 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:15,714 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:15,743 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:15,772 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:15,802 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:15,832 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:15,861 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:15,890 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:16,181 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4969513416290283 s; generated tokens: 20 tokens; generate speed: 13.360487708461777 tokens/s
2024-06-05 16:22:16,186 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:16,186 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[351/2067], cost time 1.5081s, every example cost time is 1.5081, generate speed: 13.2620 tokens/s, avg speed: 1.6863 tokens/s, remaining time: 0:28:45
pred is:
 ['University of Erfurt']
 label is:
 ['University of Erfurt']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:22:16,268 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:16,269 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 256, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:16,269 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:16,269 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:16,269 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:17,210 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:17,212 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942371129989624 s; generated tokens: 1 tokens; generate speed: 1.061153051251698 tokens/s
2024-06-05 16:22:17,216 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:17,217 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[352/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.6846 tokens/s, remaining time: 0:28:43
pred is:
 ['']
 label is:
 ['law']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:17,297 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:17,298 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 243, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:17,298 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:17,298 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:17,298 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:18,239 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:18,241 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426844120025635 s; generated tokens: 1 tokens; generate speed: 1.0608003985932895 tokens/s
2024-06-05 16:22:18,246 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:18,246 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[353/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.6829 tokens/s, remaining time: 0:28:42
pred is:
 ['']
 label is:
 ['death and divine judgment,']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:18,327 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:18,327 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 170, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:18,327 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:18,327 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:18,328 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:19,267 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:19,269 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414153099060059 s; generated tokens: 1 tokens; generate speed: 1.062230441206489 tokens/s
2024-06-05 16:22:19,274 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:19,274 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[354/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.6812 tokens/s, remaining time: 0:28:41
pred is:
 ['']
 label is:
 ['Augustinian order']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:19,359 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:19,359 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 126, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:19,360 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:19,360 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:19,360 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:20,300 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:20,302 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413914680480957 s; generated tokens: 1 tokens; generate speed: 1.062257343455029 tokens/s
2024-06-05 16:22:20,306 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:20,306 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[355/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.6795 tokens/s, remaining time: 0:28:39
pred is:
 ['']
 label is:
 ['1507']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:20,387 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:20,387 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 122, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:20,388 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:20,388 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:20,388 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:21,327 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:21,329 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9405820369720459 s; generated tokens: 1 tokens; generate speed: 1.0631714839241821 tokens/s
2024-06-05 16:22:21,337 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:21,338 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[356/2067], cost time 0.9556s, every example cost time is 0.9556, generate speed: 1.0464 tokens/s, avg speed: 1.6778 tokens/s, remaining time: 0:28:38
pred is:
 ['']
 label is:
 ['19 October 1512']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:21,419 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:21,420 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 166, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:21,420 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:21,420 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:21,421 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:22,361 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:22,363 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420619010925293 s; generated tokens: 1 tokens; generate speed: 1.0615013714494543 tokens/s
2024-06-05 16:22:22,368 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:22,368 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[357/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.6761 tokens/s, remaining time: 0:28:37
pred is:
 ['']
 label is:
 ['1516']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:22,448 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:22,448 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 238, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:22,449 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:22,449 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:22,449 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:23,390 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:23,429 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:23,459 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:23,488 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:23,518 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:23,547 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:23,576 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:23,605 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:23,634 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:23,663 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:23,723 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.2731435298919678 s; generated tokens: 12 tokens; generate speed: 9.425488735758062 tokens/s
2024-06-05 16:22:23,727 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:23,727 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[358/2067], cost time 1.2841s, every example cost time is 1.2841, generate speed: 9.3447 tokens/s, avg speed: 1.7035 tokens/s, remaining time: 0:28:37
pred is:
 ['31 October 1517']
 label is:
 ['31 October 1517']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:22:23,809 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:23,809 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 93, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:23,809 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:23,809 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:23,810 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:24,748 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:24,750 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9405968189239502 s; generated tokens: 1 tokens; generate speed: 1.0631547756497917 tokens/s
2024-06-05 16:22:24,755 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:24,755 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[359/2067], cost time 0.9517s, every example cost time is 0.9517, generate speed: 1.0507 tokens/s, avg speed: 1.7018 tokens/s, remaining time: 0:28:36
pred is:
 ['']
 label is:
 ['Johann Tetzel']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:24,837 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:24,837 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 105, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:24,838 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:24,838 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:24,838 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:25,778 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:25,780 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412031173706055 s; generated tokens: 1 tokens; generate speed: 1.0624699191324956 tokens/s
2024-06-05 16:22:25,784 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:25,784 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[360/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.7001 tokens/s, remaining time: 0:28:35
pred is:
 ['']
 label is:
 ['God']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.3191358024691353, Em score: 2.2222222222222223, current_count: 360
2024-06-05 16:22:25,917 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:25,917 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 126, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:25,917 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:25,918 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:25,918 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:26,857 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:26,859 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415416717529297 s; generated tokens: 1 tokens; generate speed: 1.0620878820352524 tokens/s
2024-06-05 16:22:26,864 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:26,864 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[361/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.6984 tokens/s, remaining time: 0:28:34
pred is:
 ['']
 label is:
 ['Tetzel']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:26,945 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:26,946 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 130, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:26,946 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:26,946 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:26,946 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:27,886 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:27,888 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415268898010254 s; generated tokens: 1 tokens; generate speed: 1.0621045567921399 tokens/s
2024-06-05 16:22:27,893 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:27,893 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[362/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.6967 tokens/s, remaining time: 0:28:32
pred is:
 ['']
 label is:
 ['the posting on the door']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:27,974 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:27,974 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 121, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:27,975 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:27,975 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:27,975 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:28,915 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:28,916 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412569999694824 s; generated tokens: 1 tokens; generate speed: 1.0624090976560303 tokens/s
2024-06-05 16:22:28,921 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:28,921 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[363/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0501 tokens/s, avg speed: 1.6950 tokens/s, remaining time: 0:28:31
pred is:
 ['']
 label is:
 ['January 1518']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:29,002 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:29,002 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:29,002 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:29,003 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:29,003 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:29,943 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:29,944 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415264129638672 s; generated tokens: 1 tokens; generate speed: 1.0621050946962407 tokens/s
2024-06-05 16:22:29,949 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:29,949 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[364/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.6933 tokens/s, remaining time: 0:28:30
pred is:
 ['']
 label is:
 ['1519']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:30,031 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:30,031 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 238, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:30,031 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:30,032 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:30,032 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:30,973 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:31,004 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:31,033 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:31,063 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:31,114 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:31,144 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:31,173 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:31,203 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:31,232 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:31,261 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:31,557 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5252680778503418 s; generated tokens: 20 tokens; generate speed: 13.112449077271245 tokens/s
2024-06-05 16:22:31,562 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:31,562 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[365/2067], cost time 1.5365s, every example cost time is 1.5365, generate speed: 13.0168 tokens/s, avg speed: 1.7407 tokens/s, remaining time: 0:28:31
pred is:
 ['He lectured on the Psalms, the books of Hebrews, Romans, and Gal']
 label is:
 ['lectured']
The F1/Em of this example is:  {'F1': 7.4074074074074066, 'Em': 0.0}
2024-06-05 16:22:31,670 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:31,671 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 313, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:31,671 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:31,671 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:31,672 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:32,614 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:32,615 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437198638916016 s; generated tokens: 1 tokens; generate speed: 1.05963648563708 tokens/s
2024-06-05 16:22:32,620 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:32,620 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[366/2067], cost time 0.9551s, every example cost time is 0.9551, generate speed: 1.0470 tokens/s, avg speed: 1.7389 tokens/s, remaining time: 0:28:30
pred is:
 ['']
 label is:
 ['God']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:32,701 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:32,701 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 90, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:32,702 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:32,702 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:32,702 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:33,641 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:33,643 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404840469360352 s; generated tokens: 1 tokens; generate speed: 1.0632822568951164 tokens/s
2024-06-05 16:22:33,647 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:33,648 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[367/2067], cost time 0.9516s, every example cost time is 0.9516, generate speed: 1.0509 tokens/s, avg speed: 1.7371 tokens/s, remaining time: 0:28:29
pred is:
 ['']
 label is:
 ['Christ and His salvation']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:33,729 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:33,729 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:33,729 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:33,729 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:33,730 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:34,669 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:34,671 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413504600524902 s; generated tokens: 1 tokens; generate speed: 1.062303618510198 tokens/s
2024-06-05 16:22:34,676 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:34,676 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[368/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.7353 tokens/s, remaining time: 0:28:28
pred is:
 ['']
 label is:
 ['Archbishop Albrecht']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:34,757 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:34,757 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 307, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:34,758 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:34,758 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:34,758 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:35,700 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:35,702 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437649250030518 s; generated tokens: 1 tokens; generate speed: 1.0595858921084256 tokens/s
2024-06-05 16:22:35,707 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:35,707 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[369/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0473 tokens/s, avg speed: 1.7336 tokens/s, remaining time: 0:28:26
pred is:
 ['']
 label is:
 ['Pope Leo X']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:35,788 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:35,788 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 247, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:35,789 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:35,789 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:35,789 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:36,730 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:36,732 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428844451904297 s; generated tokens: 1 tokens; generate speed: 1.0605753495042916 tokens/s
2024-06-05 16:22:36,737 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:36,737 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[370/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.7318 tokens/s, remaining time: 0:28:25
pred is:
 ['']
 label is:
 ['January 1519']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.2494494494494495, Em score: 2.1621621621621623, current_count: 370
2024-06-05 16:22:36,894 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:36,895 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 235, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:36,895 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:36,895 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:36,896 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:37,836 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:37,867 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:37,897 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:37,927 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:37,956 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:37,985 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:38,014 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:38,044 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:38,073 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:38,102 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:38,392 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4962644577026367 s; generated tokens: 20 tokens; generate speed: 13.366621052208902 tokens/s
2024-06-05 16:22:38,397 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:38,397 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[371/2067], cost time 1.5076s, every example cost time is 1.5076, generate speed: 13.2661 tokens/s, avg speed: 1.7784 tokens/s, remaining time: 0:28:26
pred is:
 ['15 June 1520']
 label is:
 ['15 June 1520']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:22:38,478 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:38,478 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 158, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:38,479 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:38,479 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:38,479 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:39,419 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:39,421 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415977001190186 s; generated tokens: 1 tokens; generate speed: 1.0620246840806846 tokens/s
2024-06-05 16:22:39,425 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:39,426 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[372/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.7765 tokens/s, remaining time: 0:28:25
pred is:
 ['']
 label is:
 ['secular authorities']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:39,506 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:39,506 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 135, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:39,507 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:39,507 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:39,507 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:40,447 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:40,449 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411921501159668 s; generated tokens: 1 tokens; generate speed: 1.062482299578027 tokens/s
2024-06-05 16:22:40,453 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:40,454 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[373/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.7747 tokens/s, remaining time: 0:28:24
pred is:
 ['']
 label is:
 ['Johann Eck']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:40,535 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:40,536 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 91, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:40,536 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:40,537 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:40,537 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:41,475 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:41,477 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404435157775879 s; generated tokens: 1 tokens; generate speed: 1.0633280821476758 tokens/s
2024-06-05 16:22:41,482 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:41,482 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[374/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0506 tokens/s, avg speed: 1.7729 tokens/s, remaining time: 0:28:23
pred is:
 ['']
 label is:
 ['raised his arm']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:41,563 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:41,564 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 144, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:41,564 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:41,564 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:41,564 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:42,505 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:42,507 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420390129089355 s; generated tokens: 1 tokens; generate speed: 1.06152716214171 tokens/s
2024-06-05 16:22:42,511 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:42,511 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[375/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.7710 tokens/s, remaining time: 0:28:21
pred is:
 ['']
 label is:
 ['recant his writings']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:42,593 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:42,593 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 141, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:42,594 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:42,594 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:42,594 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:43,534 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:43,536 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414074420928955 s; generated tokens: 1 tokens; generate speed: 1.0622393187978674 tokens/s
2024-06-05 16:22:43,540 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:43,541 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[376/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.7692 tokens/s, remaining time: 0:28:20
pred is:
 ['']
 label is:
 ['private conferences']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:43,621 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:43,622 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 223, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:43,622 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:43,622 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:43,622 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:44,564 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:44,565 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428315162658691 s; generated tokens: 1 tokens; generate speed: 1.060634888363246 tokens/s
2024-06-05 16:22:44,570 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:44,570 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[377/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.7674 tokens/s, remaining time: 0:28:19
pred is:
 ['']
 label is:
 ["Luther's disappearance"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:44,652 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:44,652 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 190, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:44,652 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:44,653 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:44,653 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:45,593 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:45,595 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942049503326416 s; generated tokens: 1 tokens; generate speed: 1.0615153412521936 tokens/s
2024-06-05 16:22:45,600 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:45,600 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[378/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7656 tokens/s, remaining time: 0:28:18
pred is:
 ['']
 label is:
 ['a sin']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:45,703 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:45,703 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 208, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:45,704 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:45,704 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:45,704 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:46,645 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:46,647 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427299499511719 s; generated tokens: 1 tokens; generate speed: 1.0607491573295136 tokens/s
2024-06-05 16:22:46,652 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:46,652 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[379/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.7638 tokens/s, remaining time: 0:28:16
pred is:
 ['']
 label is:
 ['summer of 1521']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:46,733 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:46,733 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 150, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:46,733 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:46,734 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:46,734 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:47,674 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:47,675 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413526058197021 s; generated tokens: 1 tokens; generate speed: 1.0623011970410698 tokens/s
2024-06-05 16:22:47,680 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:47,680 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[380/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.7620 tokens/s, remaining time: 0:28:15
pred is:
 ['']
 label is:
 ['prophetic faith']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.4270955165692008, Em score: 2.3684210526315788, current_count: 380
2024-06-05 16:22:47,813 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:47,814 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 255, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:47,814 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:47,814 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:47,814 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:48,756 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:48,758 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434845447540283 s; generated tokens: 1 tokens; generate speed: 1.0599007748035825 tokens/s
2024-06-05 16:22:48,763 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:48,763 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[381/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.7602 tokens/s, remaining time: 0:28:14
pred is:
 ['']
 label is:
 ['Gabriel Zwilling']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:48,844 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:48,844 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 183, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:48,845 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:48,845 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:48,845 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:49,786 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:49,787 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942115068435669 s; generated tokens: 1 tokens; generate speed: 1.0614414666569827 tokens/s
2024-06-05 16:22:49,792 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:49,792 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[382/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7585 tokens/s, remaining time: 0:28:13
pred is:
 ['']
 label is:
 ['6 March 1522']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:49,873 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:49,874 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 114, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:49,874 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:49,874 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:49,874 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:50,814 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:50,815 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409322738647461 s; generated tokens: 1 tokens; generate speed: 1.0627757467523582 tokens/s
2024-06-05 16:22:50,820 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:50,820 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[383/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0506 tokens/s, avg speed: 1.7567 tokens/s, remaining time: 0:28:11
pred is:
 ['']
 label is:
 ['immediate']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:50,901 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:50,901 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 124, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:50,902 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:50,902 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:50,902 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:51,842 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:51,844 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419758319854736 s; generated tokens: 1 tokens; generate speed: 1.0615983617034255 tokens/s
2024-06-05 16:22:51,849 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:51,849 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[384/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.7550 tokens/s, remaining time: 0:28:10
pred is:
 ['']
 label is:
 ['public order']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:51,929 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:51,930 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 245, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:51,930 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:51,930 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:51,930 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:52,872 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:52,874 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430434703826904 s; generated tokens: 1 tokens; generate speed: 1.0603965049396888 tokens/s
2024-06-05 16:22:52,878 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:52,879 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[385/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.7532 tokens/s, remaining time: 0:28:09
pred is:
 ['']
 label is:
 ['Zwickau prophet']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:52,959 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:52,960 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:52,960 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:52,960 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:52,960 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:53,901 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:53,903 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423847198486328 s; generated tokens: 1 tokens; generate speed: 1.0611377486687406 tokens/s
2024-06-05 16:22:53,908 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:53,908 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[386/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.7515 tokens/s, remaining time: 0:28:08
pred is:
 ['']
 label is:
 ['temporal authorities']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:53,989 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:53,989 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 231, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:53,990 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:53,990 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:53,990 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:54,931 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:54,962 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:54,992 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:55,021 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:55,050 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:55,079 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:55,108 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:55,137 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:55,166 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:55,195 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:55,485 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4947588443756104 s; generated tokens: 20 tokens; generate speed: 13.380084737584802 tokens/s
2024-06-05 16:22:55,490 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:55,490 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[387/2067], cost time 1.5062s, every example cost time is 1.5062, generate speed: 13.2787 tokens/s, avg speed: 1.7961 tokens/s, remaining time: 0:28:09
pred is:
 ['3']
 label is:
 ['on three grounds']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:55,571 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:55,571 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 142, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:55,571 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:55,571 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:55,572 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:56,511 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:56,512 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404819011688232 s; generated tokens: 1 tokens; generate speed: 1.063284682838881 tokens/s
2024-06-05 16:22:56,517 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:56,517 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[388/2067], cost time 0.9513s, every example cost time is 0.9513, generate speed: 1.0511 tokens/s, avg speed: 1.7943 tokens/s, remaining time: 0:28:08
pred is:
 ['']
 label is:
 ['backing for the uprising']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:56,598 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:56,598 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 149, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:56,598 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:56,599 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:56,599 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:57,538 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:57,540 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9409904479980469 s; generated tokens: 1 tokens; generate speed: 1.0627100435796089 tokens/s
2024-06-05 16:22:57,545 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:57,545 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[389/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0506 tokens/s, avg speed: 1.7925 tokens/s, remaining time: 0:28:06
pred is:
 ['']
 label is:
 ['Katharina von Bora']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:57,626 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:57,626 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 133, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:57,626 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:57,626 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:57,627 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:58,566 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:58,568 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941211462020874 s; generated tokens: 1 tokens; generate speed: 1.0624604994215658 tokens/s
2024-06-05 16:22:58,573 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:58,573 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[390/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0504 tokens/s, avg speed: 1.7907 tokens/s, remaining time: 0:28:05
pred is:
 ['']
 label is:
 ['13 June 1525']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.3392212725546058, Em score: 2.3076923076923075, current_count: 390
2024-06-05 16:22:58,726 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:58,727 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 216, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:58,727 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:58,727 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:58,727 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:22:59,668 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:59,670 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421031475067139 s; generated tokens: 1 tokens; generate speed: 1.061454897636751 tokens/s
2024-06-05 16:22:59,674 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:22:59,675 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[391/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.7889 tokens/s, remaining time: 0:28:04
pred is:
 ['']
 label is:
 ['seal of approval']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:22:59,756 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:22:59,756 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 233, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:22:59,756 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:22:59,756 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:22:59,757 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:00,697 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:00,699 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424705505371094 s; generated tokens: 1 tokens; generate speed: 1.0610411109716955 tokens/s
2024-06-05 16:23:00,704 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:00,704 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[392/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.7871 tokens/s, remaining time: 0:28:03
pred is:
 ['']
 label is:
 ['The Black Cloister']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:00,785 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:00,785 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 253, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:00,786 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:00,786 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:00,786 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:01,727 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:01,729 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427788257598877 s; generated tokens: 1 tokens; generate speed: 1.0606941656692295 tokens/s
2024-06-05 16:23:01,734 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:01,734 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[393/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.7853 tokens/s, remaining time: 0:28:02
pred is:
 ['']
 label is:
 ['choosing their own ministers']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:01,815 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:01,815 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 316, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:01,816 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:01,816 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:01,816 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:02,758 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:02,760 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439001083374023 s; generated tokens: 1 tokens; generate speed: 1.0594341405060466 tokens/s
2024-06-05 16:23:02,765 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:02,765 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[394/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0475 tokens/s, avg speed: 1.7835 tokens/s, remaining time: 0:28:00
pred is:
 ['']
 label is:
 ['extreme change']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:02,852 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:02,852 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 296, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:02,853 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:02,853 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:02,853 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:03,795 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:03,797 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9440314769744873 s; generated tokens: 1 tokens; generate speed: 1.0592867127745416 tokens/s
2024-06-05 16:23:03,802 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:03,802 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[395/2067], cost time 0.9553s, every example cost time is 0.9553, generate speed: 1.0468 tokens/s, avg speed: 1.7818 tokens/s, remaining time: 0:27:59
pred is:
 ['']
 label is:
 ['early 1526']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:03,883 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:03,884 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 134, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:03,884 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:03,884 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:03,884 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:04,823 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:04,825 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.940901517868042 s; generated tokens: 1 tokens; generate speed: 1.062810486548972 tokens/s
2024-06-05 16:23:04,830 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:04,830 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[396/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.7800 tokens/s, remaining time: 0:27:58
pred is:
 ['']
 label is:
 ['1527']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:04,911 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:04,911 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 192, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:04,911 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:04,911 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:04,912 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:05,852 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:05,882 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:05,911 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:05,941 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:05,970 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:05,999 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:06,028 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:06,057 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:06,086 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:06,115 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:06,404 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4926705360412598 s; generated tokens: 20 tokens; generate speed: 13.39880403417246 tokens/s
2024-06-05 16:23:06,409 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:06,409 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[397/2067], cost time 1.5035s, every example cost time is 1.5035, generate speed: 13.3020 tokens/s, avg speed: 1.8234 tokens/s, remaining time: 0:27:59
pred is:
 ['catechism']
 label is:
 ['catechism']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:23:06,490 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:06,491 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 173, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:06,491 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:06,491 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:06,492 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:07,431 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:07,439 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9474809169769287 s; generated tokens: 1 tokens; generate speed: 1.0554302277566083 tokens/s
2024-06-05 16:23:07,444 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:07,444 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[398/2067], cost time 0.9587s, every example cost time is 0.9587, generate speed: 1.0431 tokens/s, avg speed: 1.8215 tokens/s, remaining time: 0:27:58
pred is:
 ['']
 label is:
 ['The catechism']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:07,526 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:07,526 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 270, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:07,526 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:07,526 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:07,527 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:08,468 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:08,470 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432616233825684 s; generated tokens: 1 tokens; generate speed: 1.0601512615492252 tokens/s
2024-06-05 16:23:08,475 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:08,475 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[399/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.8197 tokens/s, remaining time: 0:27:57
pred is:
 ['']
 label is:
 ['Small Catechism']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:08,556 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:08,556 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 253, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:08,557 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:08,557 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:08,557 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:09,499 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:09,501 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436442852020264 s; generated tokens: 1 tokens; generate speed: 1.0597213544147182 tokens/s
2024-06-05 16:23:09,506 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:09,506 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[400/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0474 tokens/s, avg speed: 1.8179 tokens/s, remaining time: 0:27:55
pred is:
 ['']
 label is:
 ['1522']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.5057407407407406, Em score: 2.5, current_count: 400
2024-06-05 16:23:09,648 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:09,648 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 113, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:09,649 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:09,649 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:09,649 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:10,588 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:10,590 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94065260887146 s; generated tokens: 1 tokens; generate speed: 1.063091720119441 tokens/s
2024-06-05 16:23:10,594 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:10,595 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[401/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0507 tokens/s, avg speed: 1.8160 tokens/s, remaining time: 0:27:54
pred is:
 ['']
 label is:
 ['Saxon chancellery']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:10,676 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:10,676 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 164, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:10,676 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:10,677 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:10,677 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:11,617 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:11,618 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414658546447754 s; generated tokens: 1 tokens; generate speed: 1.062173412945826 tokens/s
2024-06-05 16:23:11,623 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:11,623 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[402/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.8142 tokens/s, remaining time: 0:27:53
pred is:
 ['']
 label is:
 ['German-language publications']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:11,704 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:11,705 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 204, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:11,705 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:11,705 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:11,705 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:12,646 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:12,648 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424843788146973 s; generated tokens: 1 tokens; generate speed: 1.0610255432112694 tokens/s
2024-06-05 16:23:12,653 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:12,653 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[403/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.8124 tokens/s, remaining time: 0:27:52
pred is:
 ['']
 label is:
 ['authoring hymns']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:12,734 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:12,734 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:12,735 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:12,735 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:12,735 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:13,676 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:13,678 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421846866607666 s; generated tokens: 1 tokens; generate speed: 1.0613630365232734 tokens/s
2024-06-05 16:23:13,682 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:13,683 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[404/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.8106 tokens/s, remaining time: 0:27:50
pred is:
 ['']
 label is:
 ['events in his life']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:13,763 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:13,764 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 217, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:13,764 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:13,764 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:13,764 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:14,705 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:14,707 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425292015075684 s; generated tokens: 1 tokens; generate speed: 1.0609750853347648 tokens/s
2024-06-05 16:23:14,712 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:14,712 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[405/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.8089 tokens/s, remaining time: 0:27:49
pred is:
 ['']
 label is:
 ['1524']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:14,793 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:14,793 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 200, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:14,794 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:14,794 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:14,794 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:15,734 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:15,737 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425861835479736 s; generated tokens: 1 tokens; generate speed: 1.0609109463454216 tokens/s
2024-06-05 16:23:15,741 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:15,742 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[406/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.8071 tokens/s, remaining time: 0:27:48
pred is:
 ['']
 label is:
 ['1538']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:15,822 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:15,823 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 270, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:15,823 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:15,823 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:15,823 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:16,765 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:16,767 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431774616241455 s; generated tokens: 1 tokens; generate speed: 1.060245861132015 tokens/s
2024-06-05 16:23:16,771 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:16,772 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[407/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.8053 tokens/s, remaining time: 0:27:47
pred is:
 ['']
 label is:
 ['1523']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:16,852 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:16,852 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 363, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:16,853 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:16,853 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:16,853 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:17,796 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:17,798 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9446842670440674 s; generated tokens: 1 tokens; generate speed: 1.0585547308086505 tokens/s
2024-06-05 16:23:17,803 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:17,803 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[408/2067], cost time 0.9555s, every example cost time is 0.9555, generate speed: 1.0466 tokens/s, avg speed: 1.8035 tokens/s, remaining time: 0:27:46
pred is:
 ['']
 label is:
 ['Nun komm, der Heiden Heiland']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:17,884 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:17,885 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 208, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:17,885 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:17,885 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:17,885 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:18,826 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:18,828 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425685405731201 s; generated tokens: 1 tokens; generate speed: 1.0609308044505275 tokens/s
2024-06-05 16:23:18,833 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:18,833 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[409/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.8018 tokens/s, remaining time: 0:27:44
pred is:
 ['']
 label is:
 ['baptism']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:18,913 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:18,914 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 143, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:18,914 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:18,914 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:18,914 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:19,854 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:19,856 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413855075836182 s; generated tokens: 1 tokens; generate speed: 1.0622640692300815 tokens/s
2024-06-05 16:23:19,861 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:19,861 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[410/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0499 tokens/s, avg speed: 1.8000 tokens/s, remaining time: 0:27:43
pred is:
 ['']
 label is:
 ['early Lutheran hymnals']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.420234869015357, Em score: 2.4390243902439024, current_count: 410
2024-06-05 16:23:19,998 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:19,998 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 226, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:19,998 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:19,999 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:19,999 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:20,940 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:20,942 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943204402923584 s; generated tokens: 1 tokens; generate speed: 1.0602155767088985 tokens/s
2024-06-05 16:23:20,947 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:20,947 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[411/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.7983 tokens/s, remaining time: 0:27:42
pred is:
 ['']
 label is:
 ['Johann Sebastian Bach']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:21,028 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:21,029 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 231, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:21,029 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:21,029 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:21,029 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:21,970 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:22,001 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:22,034 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:22,064 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:22,093 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:22,122 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:22,151 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:22,180 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:22,209 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:22,238 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:22,528 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4981131553649902 s; generated tokens: 20 tokens; generate speed: 13.350126409595099 tokens/s
2024-06-05 16:23:22,532 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:22,533 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[412/2067], cost time 1.5091s, every example cost time is 1.5091, generate speed: 13.2525 tokens/s, avg speed: 1.8400 tokens/s, remaining time: 0:27:43
pred is:
 ['It sleeps in peace.']
 label is:
 ['sleeps']
The F1/Em of this example is:  {'F1': 22.22222222222222, 'Em': 0.0}
2024-06-05 16:23:22,615 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:22,615 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 114, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:22,616 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:22,616 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:22,616 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:23,555 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:23,556 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9402627944946289 s; generated tokens: 1 tokens; generate speed: 1.063532456941975 tokens/s
2024-06-05 16:23:23,561 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:23,561 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[413/2067], cost time 0.9514s, every example cost time is 0.9514, generate speed: 1.0510 tokens/s, avg speed: 1.8382 tokens/s, remaining time: 0:27:42
pred is:
 ['']
 label is:
 ['Franz Pieper']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:23,642 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:23,642 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 193, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:23,642 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:23,643 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:23,643 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:24,583 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:24,585 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941931962966919 s; generated tokens: 1 tokens; generate speed: 1.0616478039986847 tokens/s
2024-06-05 16:23:24,589 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:24,590 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[414/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.8364 tokens/s, remaining time: 0:27:41
pred is:
 ['']
 label is:
 ['Commentary on Genesis']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:24,670 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:24,671 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 136, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:24,671 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:24,671 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:24,671 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:25,611 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:25,613 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411106109619141 s; generated tokens: 1 tokens; generate speed: 1.0625743545467996 tokens/s
2024-06-05 16:23:25,617 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:25,618 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[415/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.8346 tokens/s, remaining time: 0:27:39
pred is:
 ['']
 label is:
 ['October 1529']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:25,698 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:25,698 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 304, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:25,698 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:25,699 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:25,699 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:26,641 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:26,671 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:26,700 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:26,730 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:26,759 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:26,788 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:26,817 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:26,846 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:26,876 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:26,906 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:27,201 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5021913051605225 s; generated tokens: 20 tokens; generate speed: 13.313883478950654 tokens/s
2024-06-05 16:23:27,206 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:27,206 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[416/2067], cost time 1.5131s, every example cost time is 1.5131, generate speed: 13.2178 tokens/s, avg speed: 1.8758 tokens/s, remaining time: 0:27:40
pred is:
 ['The significance of the words spoken by Jesus at the Last Supper']
 label is:
 ['words spoken by Jesus']
The F1/Em of this example is:  {'F1': 46.666666666666664, 'Em': 0.0}
2024-06-05 16:23:27,288 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:27,288 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 138, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:27,288 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:27,289 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:27,289 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:28,228 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:28,230 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9408478736877441 s; generated tokens: 1 tokens; generate speed: 1.0628710846530411 tokens/s
2024-06-05 16:23:28,234 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:28,235 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[417/2067], cost time 0.9517s, every example cost time is 0.9517, generate speed: 1.0508 tokens/s, avg speed: 1.8739 tokens/s, remaining time: 0:27:39
pred is:
 ['']
 label is:
 ['1530']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:28,315 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:28,315 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 415, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:28,316 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:28,316 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:28,316 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:29,260 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:29,262 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9459030628204346 s; generated tokens: 1 tokens; generate speed: 1.0571907833961998 tokens/s
2024-06-05 16:23:29,267 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:29,267 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[418/2067], cost time 0.9568s, every example cost time is 0.9568, generate speed: 1.0452 tokens/s, avg speed: 1.8720 tokens/s, remaining time: 0:27:38
pred is:
 ['']
 label is:
 ['antithetical']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:29,348 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:29,349 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 262, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:29,349 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:29,349 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:29,349 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:30,291 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:30,293 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433238506317139 s; generated tokens: 1 tokens; generate speed: 1.0600813276695293 tokens/s
2024-06-05 16:23:30,297 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:30,298 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[419/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.8702 tokens/s, remaining time: 0:27:37
pred is:
 ['']
 label is:
 ['Jesus Christ was born a Jew']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:30,379 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:30,380 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 333, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:30,380 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:30,380 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:30,381 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:31,323 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:31,325 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9443364143371582 s; generated tokens: 1 tokens; generate speed: 1.0589446566051492 tokens/s
2024-06-05 16:23:31,330 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:31,330 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[420/2067], cost time 0.9554s, every example cost time is 0.9554, generate speed: 1.0467 tokens/s, avg speed: 1.8683 tokens/s, remaining time: 0:27:36
pred is:
 ['']
 label is:
 ['as a scourge']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.502821869488536, Em score: 2.380952380952381, current_count: 420
2024-06-05 16:23:31,481 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:31,481 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 149, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:31,481 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:31,482 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:31,482 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:32,422 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:32,423 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412729740142822 s; generated tokens: 1 tokens; generate speed: 1.0623910678485353 tokens/s
2024-06-05 16:23:32,428 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:32,428 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[421/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.8665 tokens/s, remaining time: 0:27:34
pred is:
 ['']
 label is:
 ["Qur'an"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:32,509 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:32,510 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 258, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:32,510 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:32,510 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:32,510 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:33,452 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:33,454 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434406757354736 s; generated tokens: 1 tokens; generate speed: 1.0599500590966513 tokens/s
2024-06-05 16:23:33,458 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:33,459 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[422/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.8646 tokens/s, remaining time: 0:27:33
pred is:
 ['']
 label is:
 ["God's wrath to Christians"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:33,540 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:33,540 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 243, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:33,541 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:33,541 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:33,541 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:34,482 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:34,484 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428119659423828 s; generated tokens: 1 tokens; generate speed: 1.0606568818846664 tokens/s
2024-06-05 16:23:34,489 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:34,489 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[423/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.8628 tokens/s, remaining time: 0:27:32
pred is:
 ['']
 label is:
 ['second use of the law']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:34,570 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:34,570 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 156, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:34,571 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:34,571 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:34,571 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:35,511 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:35,513 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413845539093018 s; generated tokens: 1 tokens; generate speed: 1.0622651453619936 tokens/s
2024-06-05 16:23:35,517 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:35,517 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[424/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.8610 tokens/s, remaining time: 0:27:31
pred is:
 ['']
 label is:
 ['ought to live']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:35,599 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:35,599 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 150, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:35,599 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:35,599 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:35,600 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:36,540 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:36,542 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423534870147705 s; generated tokens: 1 tokens; generate speed: 1.0611729184213503 tokens/s
2024-06-05 16:23:36,547 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:36,547 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[425/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.8592 tokens/s, remaining time: 0:27:30
pred is:
 ['']
 label is:
 ['baptism']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:36,628 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:36,628 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 329, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:36,628 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:36,628 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:36,629 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:37,571 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:37,574 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.944756031036377 s; generated tokens: 1 tokens; generate speed: 1.0584743226280562 tokens/s
2024-06-05 16:23:37,578 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:37,578 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[426/2067], cost time 0.9557s, every example cost time is 0.9557, generate speed: 1.0463 tokens/s, avg speed: 1.8574 tokens/s, remaining time: 0:27:28
pred is:
 ['']
 label is:
 ['wanted to marry']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:37,659 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:37,660 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 300, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:37,660 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:37,660 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:37,660 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:38,602 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:38,604 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94388747215271 s; generated tokens: 1 tokens; generate speed: 1.0594483235584375 tokens/s
2024-06-05 16:23:38,609 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:38,609 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[427/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.8555 tokens/s, remaining time: 0:27:27
pred is:
 ['']
 label is:
 ['expelled Jews']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:38,691 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:38,691 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 351, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:38,691 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:38,692 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:38,692 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:39,635 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:39,637 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9449710845947266 s; generated tokens: 1 tokens; generate speed: 1.0582334383584593 tokens/s
2024-06-05 16:23:39,642 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:39,642 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[428/2067], cost time 0.9559s, every example cost time is 0.9559, generate speed: 1.0462 tokens/s, avg speed: 1.8537 tokens/s, remaining time: 0:27:26
pred is:
 ['']
 label is:
 ['Von den Juden und Ihren Lügen']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:39,723 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:39,723 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 217, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:39,724 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:39,724 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:39,724 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:40,665 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:40,667 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427731037139893 s; generated tokens: 1 tokens; generate speed: 1.0607006034225726 tokens/s
2024-06-05 16:23:40,672 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:40,672 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[429/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.8520 tokens/s, remaining time: 0:27:25
pred is:
 ['']
 label is:
 ['the Jews']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:40,753 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:40,753 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 305, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:40,754 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:40,754 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:40,754 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:41,696 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:41,698 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439375400543213 s; generated tokens: 1 tokens; generate speed: 1.059392128786882 tokens/s
2024-06-05 16:23:41,703 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:41,703 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[430/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0474 tokens/s, avg speed: 1.8502 tokens/s, remaining time: 0:27:24
pred is:
 ['']
 label is:
 ['Luther']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.4213608957795, Em score: 2.3255813953488373, current_count: 430
2024-06-05 16:23:41,844 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:41,844 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 256, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:41,845 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:41,845 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:41,845 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:42,787 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:42,789 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438388347625732 s; generated tokens: 1 tokens; generate speed: 1.0595029184739515 tokens/s
2024-06-05 16:23:42,794 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:42,794 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[431/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.8484 tokens/s, remaining time: 0:27:22
pred is:
 ['']
 label is:
 ['17 December 1941']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:42,876 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:42,876 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 332, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:42,877 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:42,877 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:42,877 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:43,821 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:43,822 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9448778629302979 s; generated tokens: 1 tokens; generate speed: 1.0583378436856958 tokens/s
2024-06-05 16:23:43,827 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:43,827 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[432/2067], cost time 0.9564s, every example cost time is 0.9564, generate speed: 1.0456 tokens/s, avg speed: 1.8466 tokens/s, remaining time: 0:27:21
pred is:
 ['']
 label is:
 ['opportunistic']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:43,908 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:43,908 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 237, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:43,908 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:43,909 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:43,909 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:44,850 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:44,852 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427206516265869 s; generated tokens: 1 tokens; generate speed: 1.0607596198031541 tokens/s
2024-06-05 16:23:44,856 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:44,857 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[433/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.8449 tokens/s, remaining time: 0:27:20
pred is:
 ['']
 label is:
 ['violence']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:44,938 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:44,938 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 166, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:44,939 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:44,939 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:44,939 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:45,879 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:45,881 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414651393890381 s; generated tokens: 1 tokens; generate speed: 1.0621742199068018 tokens/s
2024-06-05 16:23:45,885 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:45,886 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[434/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0499 tokens/s, avg speed: 1.8432 tokens/s, remaining time: 0:27:19
pred is:
 ['']
 label is:
 ['declining state of mind']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:45,966 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:45,967 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:45,967 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:45,967 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:45,967 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:46,908 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:46,910 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426681995391846 s; generated tokens: 1 tokens; generate speed: 1.0608186427513324 tokens/s
2024-06-05 16:23:46,915 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:46,915 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[435/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.8414 tokens/s, remaining time: 0:27:18
pred is:
 ['']
 label is:
 ['Since the 1980s']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:46,998 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:46,999 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 200, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:46,999 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:46,999 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:46,999 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:47,942 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:47,944 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9444229602813721 s; generated tokens: 1 tokens; generate speed: 1.058847616011019 tokens/s
2024-06-05 16:23:47,949 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:47,949 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[436/2067], cost time 0.9564s, every example cost time is 0.9564, generate speed: 1.0456 tokens/s, avg speed: 1.8397 tokens/s, remaining time: 0:27:16
pred is:
 ['']
 label is:
 ['his health deteriorated']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:48,030 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:48,030 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 131, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:48,030 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:48,031 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:48,031 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:48,970 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:48,972 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411699771881104 s; generated tokens: 1 tokens; generate speed: 1.0625073304905597 tokens/s
2024-06-05 16:23:48,977 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:48,977 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[437/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.8380 tokens/s, remaining time: 0:27:15
pred is:
 ['']
 label is:
 ['poor physical health']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:49,057 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:49,057 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 205, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:49,058 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:49,058 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:49,058 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:49,999 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:50,001 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942197322845459 s; generated tokens: 1 tokens; generate speed: 1.0613488021595896 tokens/s
2024-06-05 16:23:50,005 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:50,006 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[438/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.8363 tokens/s, remaining time: 0:27:14
pred is:
 ['']
 label is:
 ['Eisleben']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:50,086 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:50,086 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 159, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:50,087 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:50,087 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:50,087 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:51,027 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:51,029 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417428970336914 s; generated tokens: 1 tokens; generate speed: 1.0618609422484706 tokens/s
2024-06-05 16:23:51,034 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:51,034 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[439/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.8346 tokens/s, remaining time: 0:27:13
pred is:
 ['']
 label is:
 ['Mansfeld']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:51,114 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:51,114 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 207, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:51,115 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:51,115 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:51,115 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:52,056 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:52,058 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426181316375732 s; generated tokens: 1 tokens; generate speed: 1.060874988965828 tokens/s
2024-06-05 16:23:52,063 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:52,063 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[440/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.8329 tokens/s, remaining time: 0:27:12
pred is:
 ['']
 label is:
 ['17 February 1546']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.3436026936026932, Em score: 2.272727272727273, current_count: 440
2024-06-05 16:23:52,206 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:52,206 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 159, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:52,207 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:52,207 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:52,207 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:53,147 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:53,150 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422898292541504 s; generated tokens: 1 tokens; generate speed: 1.0612446075020558 tokens/s
2024-06-05 16:23:53,154 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:53,154 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[441/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.8312 tokens/s, remaining time: 0:27:10
pred is:
 ['']
 label is:
 ['apoplectic stroke']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:53,235 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:53,235 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 82, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:53,236 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:53,236 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:53,236 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:54,175 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:54,177 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407813549041748 s; generated tokens: 1 tokens; generate speed: 1.0629462358996868 tokens/s
2024-06-05 16:23:54,182 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:54,183 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[442/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0499 tokens/s, avg speed: 1.8295 tokens/s, remaining time: 0:27:09
pred is:
 ['']
 label is:
 ['his last statement']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:54,264 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:54,264 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 220, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:54,264 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:54,265 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:54,265 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:55,206 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:55,236 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:55,265 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:55,294 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:55,323 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:55,352 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:55,381 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:55,410 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:55,439 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:55,469 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:55,732 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4666826725006104 s; generated tokens: 19 tokens; generate speed: 12.954404082245059 tokens/s
2024-06-05 16:23:55,736 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:55,737 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[443/2067], cost time 1.4778s, every example cost time is 1.4778, generate speed: 12.8567 tokens/s, avg speed: 1.8661 tokens/s, remaining time: 0:27:10
pred is:
 ['Images of Luther that emphasized his monumental size were crucial to the spread of Protestantism.']
 label is:
 ['monumental']
The F1/Em of this example is:  {'F1': 6.451612903225806, 'Em': 0.0}
2024-06-05 16:23:55,821 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:55,821 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 99, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:55,821 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:55,821 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:55,822 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:56,761 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:56,762 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9406578540802002 s; generated tokens: 1 tokens; generate speed: 1.0630857922063768 tokens/s
2024-06-05 16:23:56,767 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:56,767 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[444/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0506 tokens/s, avg speed: 1.8644 tokens/s, remaining time: 0:27:09
pred is:
 ['']
 label is:
 ['18 February']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:56,848 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:56,849 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 155, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:56,849 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:56,849 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:56,849 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:57,790 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:57,791 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419453144073486 s; generated tokens: 1 tokens; generate speed: 1.061632755856085 tokens/s
2024-06-05 16:23:57,796 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:57,796 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[445/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.8627 tokens/s, remaining time: 0:27:08
pred is:
 ['']
 label is:
 ['SoCal']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:57,877 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:57,877 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 126, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:57,878 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:57,878 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:57,878 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:58,818 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:58,820 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415919780731201 s; generated tokens: 1 tokens; generate speed: 1.0620311379950438 tokens/s
2024-06-05 16:23:58,825 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:58,825 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[446/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.8609 tokens/s, remaining time: 0:27:06
pred is:
 ['']
 label is:
 ['Southern California Megaregion']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:58,905 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:58,906 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 268, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:58,906 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:58,906 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:58,906 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:23:59,848 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:59,850 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436583518981934 s; generated tokens: 1 tokens; generate speed: 1.0597055576188925 tokens/s
2024-06-05 16:23:59,855 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:23:59,855 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[447/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0476 tokens/s, avg speed: 1.8592 tokens/s, remaining time: 0:27:05
pred is:
 ['']
 label is:
 ['Pacific']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:23:59,936 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:23:59,936 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 96, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:23:59,936 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:23:59,937 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:23:59,937 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:00,876 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:00,878 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9406661987304688 s; generated tokens: 1 tokens; generate speed: 1.06307636157184 tokens/s
2024-06-05 16:24:00,882 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:00,882 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[448/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0506 tokens/s, avg speed: 1.8575 tokens/s, remaining time: 0:27:04
pred is:
 ['']
 label is:
 ['Colorado River']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:00,963 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:00,963 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 145, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:00,963 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:00,964 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:00,964 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:01,903 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:01,905 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411976337432861 s; generated tokens: 1 tokens; generate speed: 1.0624761093191957 tokens/s
2024-06-05 16:24:01,910 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:01,910 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[449/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.8558 tokens/s, remaining time: 0:27:03
pred is:
 ['']
 label is:
 ['California']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:01,991 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:01,991 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 105, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:01,992 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:01,992 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:01,992 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:02,931 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:02,933 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407365322113037 s; generated tokens: 1 tokens; generate speed: 1.0629968814428743 tokens/s
2024-06-05 16:24:02,938 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:02,938 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[450/2067], cost time 0.9516s, every example cost time is 0.9516, generate speed: 1.0509 tokens/s, avg speed: 1.8541 tokens/s, remaining time: 0:27:02
pred is:
 ['']
 label is:
 ['Los Angeles']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.2836373290853573, Em score: 2.2222222222222223, current_count: 450
2024-06-05 16:24:03,087 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:03,088 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 145, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:03,088 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:03,088 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:03,089 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:04,029 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:04,032 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427645206451416 s; generated tokens: 1 tokens; generate speed: 1.0607102601991127 tokens/s
2024-06-05 16:24:04,036 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:04,036 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[451/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.8524 tokens/s, remaining time: 0:27:00
pred is:
 ['']
 label is:
 ['Hollywood']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:04,117 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:04,117 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 304, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:04,117 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:04,118 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:04,118 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:05,060 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:05,062 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9440486431121826 s; generated tokens: 1 tokens; generate speed: 1.059267451201843 tokens/s
2024-06-05 16:24:05,067 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:05,067 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[452/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0473 tokens/s, avg speed: 1.8507 tokens/s, remaining time: 0:26:59
pred is:
 ['']
 label is:
 ['skateboard']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:05,173 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:05,173 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 80, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:05,174 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:05,174 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:05,174 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:06,114 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:06,115 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410178661346436 s; generated tokens: 1 tokens; generate speed: 1.0626790797369592 tokens/s
2024-06-05 16:24:06,120 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:06,120 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[453/2067], cost time 0.9773s, every example cost time is 0.9773, generate speed: 1.0233 tokens/s, avg speed: 1.8489 tokens/s, remaining time: 0:26:58
pred is:
 ['']
 label is:
 ['Palm Springs']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:06,201 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:06,202 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:06,202 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:06,202 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:06,203 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:07,144 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:07,145 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426455497741699 s; generated tokens: 1 tokens; generate speed: 1.0608441319640989 tokens/s
2024-06-05 16:24:07,150 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:07,150 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[454/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0484 tokens/s, avg speed: 1.8472 tokens/s, remaining time: 0:26:57
pred is:
 ['']
 label is:
 ['37° 9\' 58.23"']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:07,232 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:07,232 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 183, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:07,232 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:07,233 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:07,233 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:08,173 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:08,175 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418671131134033 s; generated tokens: 1 tokens; generate speed: 1.0617209010456206 tokens/s
2024-06-05 16:24:08,179 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:08,180 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[455/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.8456 tokens/s, remaining time: 0:26:56
pred is:
 ['']
 label is:
 ['Mexico']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:08,260 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:08,260 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 253, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:08,261 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:08,261 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:08,261 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:09,202 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:09,205 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435882568359375 s; generated tokens: 1 tokens; generate speed: 1.0597842785297305 tokens/s
2024-06-05 16:24:09,210 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:09,210 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[456/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0477 tokens/s, avg speed: 1.8439 tokens/s, remaining time: 0:26:55
pred is:
 ['']
 label is:
 ['inequitable taxes']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:09,291 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:09,291 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 100, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:09,291 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:09,291 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:09,292 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:10,230 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:10,232 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9404556751251221 s; generated tokens: 1 tokens; generate speed: 1.063314334157169 tokens/s
2024-06-05 16:24:10,237 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:10,237 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[457/2067], cost time 0.9513s, every example cost time is 0.9513, generate speed: 1.0512 tokens/s, avg speed: 1.8422 tokens/s, remaining time: 0:26:54
pred is:
 ['']
 label is:
 ['Los Angeles Times']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:10,342 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:10,343 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 202, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:10,343 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:10,343 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:10,343 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:11,284 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:11,286 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942284345626831 s; generated tokens: 1 tokens; generate speed: 1.0612507834190699 tokens/s
2024-06-05 16:24:11,290 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:11,291 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[458/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.8406 tokens/s, remaining time: 0:26:52
pred is:
 ['']
 label is:
 ['regional tourism groups']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:11,371 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:11,371 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 217, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:11,372 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:11,372 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:11,372 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:12,313 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:12,315 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423079490661621 s; generated tokens: 1 tokens; generate speed: 1.0612242006352715 tokens/s
2024-06-05 16:24:12,319 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:12,320 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[459/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.8390 tokens/s, remaining time: 0:26:51
pred is:
 ['']
 label is:
 ['third']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:12,401 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:12,401 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 246, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:12,402 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:12,402 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:12,402 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:13,344 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:13,346 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439091682434082 s; generated tokens: 1 tokens; generate speed: 1.0594239717588245 tokens/s
2024-06-05 16:24:13,351 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:13,351 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[460/2067], cost time 0.9551s, every example cost time is 0.9551, generate speed: 1.0470 tokens/s, avg speed: 1.8373 tokens/s, remaining time: 0:26:50
pred is:
 ['']
 label is:
 ['Camp Pendleton']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.2122539088878495, Em score: 2.1739130434782608, current_count: 460
2024-06-05 16:24:13,497 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:13,497 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 139, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:13,498 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:13,498 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:13,498 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:14,438 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:14,440 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94150710105896 s; generated tokens: 1 tokens; generate speed: 1.0621268802702073 tokens/s
2024-06-05 16:24:14,444 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:14,445 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[461/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0500 tokens/s, avg speed: 1.8357 tokens/s, remaining time: 0:26:49
pred is:
 ['']
 label is:
 ['Mediterranean']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:14,526 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:14,526 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 134, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:14,526 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:14,527 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:14,527 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:15,466 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:15,468 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410684108734131 s; generated tokens: 1 tokens; generate speed: 1.0626220032950549 tokens/s
2024-06-05 16:24:15,473 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:15,473 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[462/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0505 tokens/s, avg speed: 1.8341 tokens/s, remaining time: 0:26:48
pred is:
 ['']
 label is:
 ['Pacific Ocean']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:15,553 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:15,554 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 157, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:15,554 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:15,554 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:15,555 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:16,494 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:16,496 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941192626953125 s; generated tokens: 1 tokens; generate speed: 1.062481761291787 tokens/s
2024-06-05 16:24:16,501 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:16,501 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[463/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.8325 tokens/s, remaining time: 0:26:46
pred is:
 ['']
 label is:
 ['10,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:16,581 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:16,582 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 126, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:16,582 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:16,582 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:16,582 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:17,522 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:17,524 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412665367126465 s; generated tokens: 1 tokens; generate speed: 1.062398333518239 tokens/s
2024-06-05 16:24:17,528 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:17,529 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[464/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.8309 tokens/s, remaining time: 0:26:45
pred is:
 ['']
 label is:
 ['San Andreas']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:17,610 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:17,610 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 131, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:17,610 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:17,610 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:17,611 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:18,550 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:18,552 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413471221923828 s; generated tokens: 1 tokens; generate speed: 1.0623073852618952 tokens/s
2024-06-05 16:24:18,557 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:18,557 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[465/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.8293 tokens/s, remaining time: 0:26:44
pred is:
 ['']
 label is:
 ['economically']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:18,638 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:18,638 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 144, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:18,639 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:18,639 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:18,639 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:19,579 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:19,581 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942035436630249 s; generated tokens: 1 tokens; generate speed: 1.0615311920505834 tokens/s
2024-06-05 16:24:19,586 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:19,586 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[466/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.8277 tokens/s, remaining time: 0:26:43
pred is:
 ['']
 label is:
 ['2010']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:19,667 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:19,668 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 218, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:19,668 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:19,668 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:19,668 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:20,609 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:20,611 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425086975097656 s; generated tokens: 1 tokens; generate speed: 1.0609981665337775 tokens/s
2024-06-05 16:24:20,616 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:20,616 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[467/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.8261 tokens/s, remaining time: 0:26:42
pred is:
 ['']
 label is:
 ['Metropolitan Statistical Areas']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:20,697 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:20,697 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 154, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:20,698 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:20,698 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:20,698 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:21,638 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:21,640 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412412643432617 s; generated tokens: 1 tokens; generate speed: 1.062426858960265 tokens/s
2024-06-05 16:24:21,644 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:21,645 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[468/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.8245 tokens/s, remaining time: 0:26:41
pred is:
 ['']
 label is:
 ['Los Angeles']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:21,726 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:21,726 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:21,726 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:21,726 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:21,727 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:22,667 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:22,669 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416999816894531 s; generated tokens: 1 tokens; generate speed: 1.0619093335925884 tokens/s
2024-06-05 16:24:22,673 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:22,673 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[469/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.8229 tokens/s, remaining time: 0:26:39
pred is:
 ['']
 label is:
 ['petroleum']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:22,754 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:22,755 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 118, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:22,755 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:22,755 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:22,755 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:23,695 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:23,697 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412014484405518 s; generated tokens: 1 tokens; generate speed: 1.062471803094725 tokens/s
2024-06-05 16:24:23,701 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:23,702 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[470/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.8214 tokens/s, remaining time: 0:26:38
pred is:
 ['']
 label is:
 ['1920s']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.143908081039172, Em score: 2.127659574468085, current_count: 470
2024-06-05 16:24:23,849 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:23,849 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 92, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:23,849 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:23,850 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:23,850 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:24,789 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:24,791 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412899017333984 s; generated tokens: 1 tokens; generate speed: 1.0623719623024597 tokens/s
2024-06-05 16:24:24,796 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:24,796 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[471/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.8198 tokens/s, remaining time: 0:26:37
pred is:
 ['']
 label is:
 ['business']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:24,902 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:24,902 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 120, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:24,902 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:24,903 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:24,903 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:25,842 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:25,844 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413495063781738 s; generated tokens: 1 tokens; generate speed: 1.062304694722243 tokens/s
2024-06-05 16:24:25,849 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:25,849 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[472/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.8183 tokens/s, remaining time: 0:26:36
pred is:
 ['']
 label is:
 ['business']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:25,930 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:25,930 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 84, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:25,930 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:25,930 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:25,931 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:26,869 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:26,871 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9405734539031982 s; generated tokens: 1 tokens; generate speed: 1.0631811857438598 tokens/s
2024-06-05 16:24:26,876 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:26,876 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[473/2067], cost time 0.9513s, every example cost time is 0.9513, generate speed: 1.0511 tokens/s, avg speed: 1.8167 tokens/s, remaining time: 0:26:35
pred is:
 ['']
 label is:
 ['business']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:26,957 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:26,957 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 112, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:26,958 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:26,958 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:26,958 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:27,897 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:27,899 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9406235218048096 s; generated tokens: 1 tokens; generate speed: 1.0631245942917338 tokens/s
2024-06-05 16:24:27,903 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:27,904 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[474/2067], cost time 0.9515s, every example cost time is 0.9515, generate speed: 1.0510 tokens/s, avg speed: 1.8152 tokens/s, remaining time: 0:26:34
pred is:
 ['']
 label is:
 ['Orange']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:27,985 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:27,985 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 115, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:27,986 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:27,986 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:27,986 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:28,926 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:28,928 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941460132598877 s; generated tokens: 1 tokens; generate speed: 1.0621798686679649 tokens/s
2024-06-05 16:24:28,932 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:28,933 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[475/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.8137 tokens/s, remaining time: 0:26:32
pred is:
 ['']
 label is:
 ['Downtown San Diego']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:29,014 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:29,014 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 158, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:29,014 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:29,015 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:29,015 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:29,955 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:29,957 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421980381011963 s; generated tokens: 1 tokens; generate speed: 1.061347996452308 tokens/s
2024-06-05 16:24:29,962 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:29,962 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[476/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.8121 tokens/s, remaining time: 0:26:31
pred is:
 ['']
 label is:
 ['Los Angeles International Airport']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:30,067 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:30,067 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 103, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:30,068 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:30,068 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:30,068 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:31,007 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:31,009 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9408073425292969 s; generated tokens: 1 tokens; generate speed: 1.062916874470354 tokens/s
2024-06-05 16:24:31,014 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:31,014 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[477/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.8106 tokens/s, remaining time: 0:26:30
pred is:
 ['']
 label is:
 ['Metrolink']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:31,094 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:31,095 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 91, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:31,095 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:31,095 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:31,095 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:32,035 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:32,036 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9408402442932129 s; generated tokens: 1 tokens; generate speed: 1.0628797036113498 tokens/s
2024-06-05 16:24:32,041 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:32,041 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[478/2067], cost time 0.9516s, every example cost time is 0.9516, generate speed: 1.0508 tokens/s, avg speed: 1.8091 tokens/s, remaining time: 0:26:29
pred is:
 ['']
 label is:
 ['Port of Los Angeles']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:32,123 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:32,123 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 255, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:32,124 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:32,124 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:32,124 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:33,065 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:33,067 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431307315826416 s; generated tokens: 1 tokens; generate speed: 1.0602983939691242 tokens/s
2024-06-05 16:24:33,072 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:33,072 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[479/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.8076 tokens/s, remaining time: 0:26:28
pred is:
 ['']
 label is:
 ['The Tech Coast']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:33,153 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:33,153 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 114, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:33,153 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:33,154 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:33,154 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:34,094 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:34,096 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417562484741211 s; generated tokens: 1 tokens; generate speed: 1.061845888063125 tokens/s
2024-06-05 16:24:34,100 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:34,101 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[480/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.8061 tokens/s, remaining time: 0:26:27
pred is:
 ['']
 label is:
 ['NFL']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.0784099960175224, Em score: 2.0833333333333335, current_count: 480
2024-06-05 16:24:34,271 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:34,272 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 115, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:34,272 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:34,272 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:34,273 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:35,212 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:35,214 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414002895355225 s; generated tokens: 1 tokens; generate speed: 1.0622473894642523 tokens/s
2024-06-05 16:24:35,219 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:35,219 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[481/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.8046 tokens/s, remaining time: 0:26:25
pred is:
 ['']
 label is:
 ['Chivas USA']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:35,300 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:35,300 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 92, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:35,301 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:35,301 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:35,301 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:36,240 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:36,242 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9408984184265137 s; generated tokens: 1 tokens; generate speed: 1.062813987584678 tokens/s
2024-06-05 16:24:36,247 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:36,247 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[482/2067], cost time 0.9517s, every example cost time is 0.9517, generate speed: 1.0508 tokens/s, avg speed: 1.8031 tokens/s, remaining time: 0:26:24
pred is:
 ['']
 label is:
 ['College']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:36,328 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:36,328 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 80, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:36,328 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:36,328 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:36,329 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:37,267 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:37,269 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9403810501098633 s; generated tokens: 1 tokens; generate speed: 1.06339871468398 tokens/s
2024-06-05 16:24:37,274 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:37,274 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[483/2067], cost time 0.9513s, every example cost time is 0.9513, generate speed: 1.0512 tokens/s, avg speed: 1.8016 tokens/s, remaining time: 0:26:23
pred is:
 ['']
 label is:
 ['Rugby']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:37,355 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:37,355 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 155, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:37,355 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:37,356 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:37,356 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:38,296 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:38,298 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416322708129883 s; generated tokens: 1 tokens; generate speed: 1.0619856933499296 tokens/s
2024-06-05 16:24:38,302 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:38,303 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[484/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.8001 tokens/s, remaining time: 0:26:22
pred is:
 ['']
 label is:
 ['BSkyB']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:38,383 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:38,383 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 236, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:38,384 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:38,384 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:38,384 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:39,326 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:39,327 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943018913269043 s; generated tokens: 1 tokens; generate speed: 1.0604241186779892 tokens/s
2024-06-05 16:24:39,332 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:39,332 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[485/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.7986 tokens/s, remaining time: 0:26:21
pred is:
 ['']
 label is:
 ['2006']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:39,413 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:39,413 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 185, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:39,413 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:39,414 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:39,414 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:40,354 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:40,356 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421532154083252 s; generated tokens: 1 tokens; generate speed: 1.0613984898057205 tokens/s
2024-06-05 16:24:40,361 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:40,361 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[486/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0494 tokens/s, avg speed: 1.7972 tokens/s, remaining time: 0:26:20
pred is:
 ['']
 label is:
 ['ONdigital']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:40,442 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:40,442 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 265, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:40,442 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:40,442 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:40,443 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:41,384 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:41,386 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432566165924072 s; generated tokens: 1 tokens; generate speed: 1.060156888814184 tokens/s
2024-06-05 16:24:41,391 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:41,391 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[487/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.7957 tokens/s, remaining time: 0:26:19
pred is:
 ['']
 label is:
 ['Sky+ PVR']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:41,471 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:41,472 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 165, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:41,472 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:41,472 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:41,472 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:42,413 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:42,414 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417264461517334 s; generated tokens: 1 tokens; generate speed: 1.061879491742422 tokens/s
2024-06-05 16:24:42,419 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:42,419 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[488/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.7943 tokens/s, remaining time: 0:26:17
pred is:
 ['']
 label is:
 ['VideoGuard']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:42,500 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:42,500 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 170, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:42,501 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:42,501 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:42,501 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:43,441 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:43,443 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416713714599609 s; generated tokens: 1 tokens; generate speed: 1.0619415969390753 tokens/s
2024-06-05 16:24:43,448 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:43,448 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[489/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.7928 tokens/s, remaining time: 0:26:16
pred is:
 ['']
 label is:
 ['basic channels']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:43,548 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:43,548 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 201, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:43,548 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:43,549 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:43,549 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:44,490 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:44,491 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424734115600586 s; generated tokens: 1 tokens; generate speed: 1.0610378900182644 tokens/s
2024-06-05 16:24:44,496 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:44,496 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[490/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.7913 tokens/s, remaining time: 0:26:15
pred is:
 ['']
 label is:
 ['July 2013']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.0155853022212464, Em score: 2.0408163265306123, current_count: 490
2024-06-05 16:24:44,645 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:44,645 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 272, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:44,646 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:44,646 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:44,646 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:45,588 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:45,590 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9440767765045166 s; generated tokens: 1 tokens; generate speed: 1.0592358851390682 tokens/s
2024-06-05 16:24:45,595 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:45,595 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[491/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.7899 tokens/s, remaining time: 0:26:14
pred is:
 ['']
 label is:
 ['Sam Chisholm']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:45,676 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:45,676 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 147, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:45,676 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:45,677 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:45,677 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:46,616 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:46,618 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412181377410889 s; generated tokens: 1 tokens; generate speed: 1.062452963773081 tokens/s
2024-06-05 16:24:46,623 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:46,623 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[492/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.7885 tokens/s, remaining time: 0:26:13
pred is:
 ['']
 label is:
 ['BSkyB']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:46,703 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:46,704 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 216, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:46,704 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:46,704 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:46,704 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:47,645 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:47,647 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426848888397217 s; generated tokens: 1 tokens; generate speed: 1.0607998620099057 tokens/s
2024-06-05 16:24:47,652 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:47,652 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[493/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.7870 tokens/s, remaining time: 0:26:12
pred is:
 ['']
 label is:
 ['Sky Q Hub']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:47,733 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:47,733 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 171, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:47,734 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:47,734 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:47,734 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:48,674 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:48,676 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416730403900146 s; generated tokens: 1 tokens; generate speed: 1.0619397148566851 tokens/s
2024-06-05 16:24:48,680 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:48,681 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[494/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.7856 tokens/s, remaining time: 0:26:11
pred is:
 ['']
 label is:
 ['DVB-compliant MPEG-2']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:48,762 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:48,762 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 193, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:48,762 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:48,762 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:48,763 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:49,704 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:49,705 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426097869873047 s; generated tokens: 1 tokens; generate speed: 1.0608843805835302 tokens/s
2024-06-05 16:24:49,710 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:49,710 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[495/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.7842 tokens/s, remaining time: 0:26:09
pred is:
 ['']
 label is:
 ['1998']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:49,791 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:49,792 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 209, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:49,792 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:49,792 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:49,792 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:50,733 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:50,735 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426755905151367 s; generated tokens: 1 tokens; generate speed: 1.0608103254838048 tokens/s
2024-06-05 16:24:50,740 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:50,740 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[496/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.7828 tokens/s, remaining time: 0:26:08
pred is:
 ['']
 label is:
 ['22 May 2006']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:50,820 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:50,821 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 199, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:50,821 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:50,821 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:50,821 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:51,762 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:51,764 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422054290771484 s; generated tokens: 1 tokens; generate speed: 1.0613396708820273 tokens/s
2024-06-05 16:24:51,768 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:51,769 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[497/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7814 tokens/s, remaining time: 0:26:07
pred is:
 ['']
 label is:
 ['8 February 2007']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:51,854 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:51,855 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 211, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:51,855 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:51,855 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:51,856 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:52,796 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:52,798 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421682357788086 s; generated tokens: 1 tokens; generate speed: 1.0613815686254662 tokens/s
2024-06-05 16:24:52,802 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:52,803 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[498/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.7800 tokens/s, remaining time: 0:26:06
pred is:
 ['']
 label is:
 ['free-to-view']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:52,885 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:52,886 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 317, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:52,886 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:52,886 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:52,887 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:53,830 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:53,832 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9455351829528809 s; generated tokens: 1 tokens; generate speed: 1.0576021051665438 tokens/s
2024-06-05 16:24:53,837 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:53,837 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[499/2067], cost time 0.9568s, every example cost time is 0.9568, generate speed: 1.0451 tokens/s, avg speed: 1.7786 tokens/s, remaining time: 0:26:05
pred is:
 ['']
 label is:
 ['1991']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:53,918 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:53,918 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 188, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:53,919 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:53,919 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:53,919 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:54,860 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:54,862 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428615570068359 s; generated tokens: 1 tokens; generate speed: 1.0606010952175768 tokens/s
2024-06-05 16:24:54,867 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:54,867 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[500/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.7772 tokens/s, remaining time: 0:26:04
pred is:
 ['']
 label is:
 ['Ofcom']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.9552735961768217, Em score: 2.0, current_count: 500
2024-06-05 16:24:55,016 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:55,016 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 195, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:55,017 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:55,017 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:55,017 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:55,958 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:55,960 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424188137054443 s; generated tokens: 1 tokens; generate speed: 1.061099359920623 tokens/s
2024-06-05 16:24:55,964 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:55,965 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[501/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.7758 tokens/s, remaining time: 0:26:03
pred is:
 ['']
 label is:
 ['1 October 1998']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:56,045 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:56,045 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 211, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:56,046 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:56,046 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:56,046 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:56,987 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:56,989 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422955513000488 s; generated tokens: 1 tokens; generate speed: 1.0612381631435472 tokens/s
2024-06-05 16:24:56,993 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:56,994 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[502/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.7744 tokens/s, remaining time: 0:26:01
pred is:
 ['']
 label is:
 ['2007']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:57,074 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:57,074 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:57,074 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:57,075 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:57,075 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:58,015 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:58,017 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415328502655029 s; generated tokens: 1 tokens; generate speed: 1.0620978330368505 tokens/s
2024-06-05 16:24:58,021 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:58,021 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[503/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.7730 tokens/s, remaining time: 0:26:00
pred is:
 ['']
 label is:
 ['10 million']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:58,102 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:58,102 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 195, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:58,103 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:58,103 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:58,103 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:24:59,044 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:59,046 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942439079284668 s; generated tokens: 1 tokens; generate speed: 1.0610765427501394 tokens/s
2024-06-05 16:24:59,050 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:24:59,051 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[504/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.7716 tokens/s, remaining time: 0:25:59
pred is:
 ['']
 label is:
 ['Welfare Cash Card']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:24:59,137 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:24:59,138 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 146, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:24:59,138 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:24:59,138 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:24:59,138 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:00,078 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:00,080 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412550926208496 s; generated tokens: 1 tokens; generate speed: 1.0624112505097634 tokens/s
2024-06-05 16:25:00,084 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:00,085 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[505/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0499 tokens/s, avg speed: 1.7703 tokens/s, remaining time: 0:25:58
pred is:
 ['']
 label is:
 ['£30m']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:00,165 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:00,165 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 244, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:00,166 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:00,166 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:00,166 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:01,107 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:01,110 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436252117156982 s; generated tokens: 1 tokens; generate speed: 1.059742774551139 tokens/s
2024-06-05 16:25:01,114 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:01,115 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[506/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0477 tokens/s, avg speed: 1.7689 tokens/s, remaining time: 0:25:57
pred is:
 ['']
 label is:
 ['diversified']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:01,195 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:01,195 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 173, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:01,196 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:01,196 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:01,196 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:02,136 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:02,138 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418179988861084 s; generated tokens: 1 tokens; generate speed: 1.0617762680079417 tokens/s
2024-06-05 16:25:02,143 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:02,143 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[507/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.7676 tokens/s, remaining time: 0:25:56
pred is:
 ['']
 label is:
 ['Bendigo']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:02,224 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:02,224 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:02,224 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:02,224 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:02,225 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:03,165 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:03,166 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416518211364746 s; generated tokens: 1 tokens; generate speed: 1.0619636446867435 tokens/s
2024-06-05 16:25:03,171 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:03,171 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[508/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.7662 tokens/s, remaining time: 0:25:55
pred is:
 ['']
 label is:
 ['multi-member proportional']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:03,252 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:03,252 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 179, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:03,253 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:03,253 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:03,253 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:04,193 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:04,195 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417629241943359 s; generated tokens: 1 tokens; generate speed: 1.0618383611305202 tokens/s
2024-06-05 16:25:04,200 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:04,200 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[509/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.7649 tokens/s, remaining time: 0:25:53
pred is:
 ['']
 label is:
 ['Australian Labor Party']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:04,286 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:04,286 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 168, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:04,287 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:04,287 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:04,287 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:05,227 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:05,229 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419703483581543 s; generated tokens: 1 tokens; generate speed: 1.0616045417384856 tokens/s
2024-06-05 16:25:05,234 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:05,234 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[510/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.7635 tokens/s, remaining time: 0:25:52
pred is:
 ['']
 label is:
 ['61.1%']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.897327055075315, Em score: 1.9607843137254901, current_count: 510
2024-06-05 16:25:05,384 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:05,384 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 163, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:05,385 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:05,385 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:05,385 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:06,325 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:06,328 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421024322509766 s; generated tokens: 1 tokens; generate speed: 1.061455703506346 tokens/s
2024-06-05 16:25:06,332 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:06,332 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[511/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7622 tokens/s, remaining time: 0:25:51
pred is:
 ['']
 label is:
 ['south-east']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:06,419 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:06,419 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 269, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:06,420 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:06,420 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:06,420 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:07,362 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:07,364 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432733058929443 s; generated tokens: 1 tokens; generate speed: 1.0601381314966352 tokens/s
2024-06-05 16:25:07,368 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:07,368 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[512/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0476 tokens/s, avg speed: 1.7608 tokens/s, remaining time: 0:25:50
pred is:
 ['']
 label is:
 ['Koori']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:07,449 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:07,449 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 219, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:07,450 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:07,450 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:07,450 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:08,392 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:08,394 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431145191192627 s; generated tokens: 1 tokens; generate speed: 1.0603166208636683 tokens/s
2024-06-05 16:25:08,398 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:08,398 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[513/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0484 tokens/s, avg speed: 1.7595 tokens/s, remaining time: 0:25:49
pred is:
 ['']
 label is:
 ['26,000 square kilometres']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:08,480 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:08,480 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 156, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:08,480 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:08,481 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:08,481 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:09,420 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:09,422 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413740634918213 s; generated tokens: 1 tokens; generate speed: 1.0622769829569327 tokens/s
2024-06-05 16:25:09,427 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:09,427 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[514/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.7582 tokens/s, remaining time: 0:25:48
pred is:
 ['']
 label is:
 ['1975']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:09,508 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:09,508 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 185, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:09,508 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:09,509 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:09,509 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:10,449 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:10,451 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423501491546631 s; generated tokens: 1 tokens; generate speed: 1.0611766771587523 tokens/s
2024-06-05 16:25:10,456 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:10,456 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[515/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.7569 tokens/s, remaining time: 0:25:47
pred is:
 ['']
 label is:
 ['warmest regions']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:10,537 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:10,537 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 230, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:10,537 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:10,538 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:10,538 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:11,479 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:11,481 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430546760559082 s; generated tokens: 1 tokens; generate speed: 1.0603839049738362 tokens/s
2024-06-05 16:25:11,486 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:11,486 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[516/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.7556 tokens/s, remaining time: 0:25:46
pred is:
 ['']
 label is:
 ['state or government']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:11,567 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:11,567 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:11,567 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:11,568 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:11,568 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:12,508 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:12,510 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416046142578125 s; generated tokens: 1 tokens; generate speed: 1.0620168857054886 tokens/s
2024-06-05 16:25:12,514 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:12,514 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[517/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.7543 tokens/s, remaining time: 0:25:44
pred is:
 ['']
 label is:
 ['major car brands']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:12,595 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:12,595 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 265, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:12,595 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:12,596 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:12,596 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:13,537 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:13,539 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433410167694092 s; generated tokens: 1 tokens; generate speed: 1.0600620371884462 tokens/s
2024-06-05 16:25:13,544 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:13,544 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[518/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.7530 tokens/s, remaining time: 0:25:43
pred is:
 ['']
 label is:
 ['2,000 m']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:13,633 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:13,633 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:13,634 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:13,634 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:13,634 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:14,574 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:14,576 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418659210205078 s; generated tokens: 1 tokens; generate speed: 1.0617222448355539 tokens/s
2024-06-05 16:25:14,581 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:14,581 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[519/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7517 tokens/s, remaining time: 0:25:42
pred is:
 ['']
 label is:
 ['Victorian Alps']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:14,662 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:14,662 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 159, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:14,662 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:14,663 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:14,663 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:15,603 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:15,605 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422793388366699 s; generated tokens: 1 tokens; generate speed: 1.0612564223625995 tokens/s
2024-06-05 16:25:15,610 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:15,610 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[520/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.7504 tokens/s, remaining time: 0:25:41
pred is:
 ['']
 label is:
 ['government-owned']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.8416092270930977, Em score: 1.9230769230769231, current_count: 520
2024-06-05 16:25:15,767 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:15,768 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 175, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:15,768 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:15,768 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:15,768 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:16,708 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:16,711 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420688152313232 s; generated tokens: 1 tokens; generate speed: 1.061493580757635 tokens/s
2024-06-05 16:25:16,715 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:16,715 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[521/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0489 tokens/s, avg speed: 1.7491 tokens/s, remaining time: 0:25:40
pred is:
 ['']
 label is:
 ['37']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:16,796 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:16,797 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 227, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:16,797 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:16,797 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:16,797 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:17,738 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:17,740 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426500797271729 s; generated tokens: 1 tokens; generate speed: 1.0608390340235538 tokens/s
2024-06-05 16:25:17,745 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:17,745 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[522/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.7478 tokens/s, remaining time: 0:25:39
pred is:
 ['']
 label is:
 ['1 July 1851']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:17,825 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:17,826 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:17,826 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:17,826 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:17,826 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:18,766 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:18,768 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416394233703613 s; generated tokens: 1 tokens; generate speed: 1.0619776266596312 tokens/s
2024-06-05 16:25:18,773 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:18,773 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[523/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.7465 tokens/s, remaining time: 0:25:38
pred is:
 ['']
 label is:
 ['1,548']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:18,854 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:18,854 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 197, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:18,854 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:18,855 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:18,855 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:19,796 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:19,797 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942530632019043 s; generated tokens: 1 tokens; generate speed: 1.0609734750560298 tokens/s
2024-06-05 16:25:19,802 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:19,802 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[524/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.7452 tokens/s, remaining time: 0:25:37
pred is:
 ['']
 label is:
 ['Victoria']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:19,883 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:19,884 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 175, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:19,884 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:19,884 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:19,884 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:20,825 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:20,827 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420382976531982 s; generated tokens: 1 tokens; generate speed: 1.0615279681210368 tokens/s
2024-06-05 16:25:20,831 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:20,832 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[525/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.7440 tokens/s, remaining time: 0:25:35
pred is:
 ['']
 label is:
 ['1,600 mm']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:20,913 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:20,913 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 231, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:20,913 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:20,914 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:20,914 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:21,855 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:21,857 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431343078613281 s; generated tokens: 1 tokens; generate speed: 1.0602943734149823 tokens/s
2024-06-05 16:25:21,862 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:21,862 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[526/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.7427 tokens/s, remaining time: 0:25:34
pred is:
 ['']
 label is:
 ['1788']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:21,943 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:21,943 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 159, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:21,943 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:21,944 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:21,944 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:22,884 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:22,920 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:22,950 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:22,980 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:23,009 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:23,038 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:23,068 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:23,097 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:23,127 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:23,157 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:23,452 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5083961486816406 s; generated tokens: 20 tokens; generate speed: 13.259116325297091 tokens/s
2024-06-05 16:25:23,457 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:23,457 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[527/2067], cost time 1.5197s, every example cost time is 1.5197, generate speed: 13.1605 tokens/s, avg speed: 1.7757 tokens/s, remaining time: 0:25:35
pred is:
 ['1854']
 label is:
 ['1854']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:25:23,539 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:23,539 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 146, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:23,540 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:23,540 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:23,540 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:24,480 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:24,510 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:24,540 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:24,569 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:24,598 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:24,627 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:24,656 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:24,685 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:24,714 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:24,743 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:25,032 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4920055866241455 s; generated tokens: 20 tokens; generate speed: 13.404775544609436 tokens/s
2024-06-05 16:25:25,037 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:25,038 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[528/2067], cost time 1.5034s, every example cost time is 1.5034, generate speed: 13.3028 tokens/s, avg speed: 1.8086 tokens/s, remaining time: 0:25:35
pred is:
 ['The Premier of Victoria needs to lead in the Legislative Assembly by setting the legislative and political agenda.']
 label is:
 ['most seats']
The F1/Em of this example is:  {'F1': 5.128205128205128, 'Em': 0.0}
2024-06-05 16:25:25,122 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:25,123 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 170, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:25,123 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:25,123 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:25,123 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:26,064 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:26,065 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417848587036133 s; generated tokens: 1 tokens; generate speed: 1.0618136305318404 tokens/s
2024-06-05 16:25:26,070 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:26,070 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[529/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.8073 tokens/s, remaining time: 0:25:34
pred is:
 ['']
 label is:
 ['$8.7 billion']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:26,158 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:26,158 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 156, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:26,159 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:26,159 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:26,159 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:27,099 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:27,130 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:27,160 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:27,189 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:27,218 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:27,247 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:27,276 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:27,305 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:27,334 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:27,363 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:27,654 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4947113990783691 s; generated tokens: 20 tokens; generate speed: 13.380509449738518 tokens/s
2024-06-05 16:25:27,659 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:27,660 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[530/2067], cost time 1.5070s, every example cost time is 1.5070, generate speed: 13.2712 tokens/s, avg speed: 1.8399 tokens/s, remaining time: 0:25:35
pred is:
 ["Events in Victoria's economy play a big part in tourism, particularly cultural tourism and sports tourism."]
 label is:
 ['tourism']
The F1/Em of this example is:  {'F1': 5.555555555555556, 'Em': 0.0}
F1 score: 2.9968312429663615, Em score: 2.0754716981132075, current_count: 530
2024-06-05 16:25:27,817 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:27,817 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:27,818 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:27,818 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:27,818 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:28,758 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:28,760 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419150352478027 s; generated tokens: 1 tokens; generate speed: 1.0616668835070842 tokens/s
2024-06-05 16:25:28,768 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:28,768 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[531/2067], cost time 0.9567s, every example cost time is 0.9567, generate speed: 1.0453 tokens/s, avg speed: 1.8385 tokens/s, remaining time: 0:25:34
pred is:
 ['']
 label is:
 ['the southern and central parts of France']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:28,850 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:28,851 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 355, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:28,851 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:28,851 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:28,851 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:29,794 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:29,796 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445693492889404 s; generated tokens: 1 tokens; generate speed: 1.0586835162000408 tokens/s
2024-06-05 16:25:29,801 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:29,801 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[532/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0462 tokens/s, avg speed: 1.8370 tokens/s, remaining time: 0:25:32
pred is:
 ['']
 label is:
 ['derision']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:29,882 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:29,882 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 151, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:29,883 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:29,883 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:29,883 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:30,823 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:30,825 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413156509399414 s; generated tokens: 1 tokens; generate speed: 1.0623429016626462 tokens/s
2024-06-05 16:25:30,829 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:30,830 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[533/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.8356 tokens/s, remaining time: 0:25:31
pred is:
 ['']
 label is:
 ['availability of the Bible in vernacular languages']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:30,911 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:30,911 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 191, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:30,911 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:30,911 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:30,912 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:31,852 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:31,853 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415886402130127 s; generated tokens: 1 tokens; generate speed: 1.0620349028146443 tokens/s
2024-06-05 16:25:31,858 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:31,858 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[534/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.8342 tokens/s, remaining time: 0:25:30
pred is:
 ['']
 label is:
 ['villes de sûreté']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:31,939 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:31,939 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 250, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:31,940 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:31,940 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:31,940 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:32,881 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:32,884 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434947967529297 s; generated tokens: 1 tokens; generate speed: 1.0598892579392434 tokens/s
2024-06-05 16:25:32,888 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:32,889 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[535/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0477 tokens/s, avg speed: 1.8328 tokens/s, remaining time: 0:25:29
pred is:
 ['']
 label is:
 ['at the Cape of Good Hope']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:32,976 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:32,976 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 275, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:32,977 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:32,977 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:32,977 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:33,919 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:33,921 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433770179748535 s; generated tokens: 1 tokens; generate speed: 1.0600215830429058 tokens/s
2024-06-05 16:25:33,925 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:33,926 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[536/2067], cost time 0.9597s, every example cost time is 0.9597, generate speed: 1.0420 tokens/s, avg speed: 1.8314 tokens/s, remaining time: 0:25:28
pred is:
 ['']
 label is:
 ['1624']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:34,007 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:34,007 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 299, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:34,007 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:34,008 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:34,008 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:34,950 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:34,952 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437546730041504 s; generated tokens: 1 tokens; generate speed: 1.0595974023808645 tokens/s
2024-06-05 16:25:34,957 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:34,957 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[537/2067], cost time 0.9551s, every example cost time is 0.9551, generate speed: 1.0470 tokens/s, avg speed: 1.8300 tokens/s, remaining time: 0:25:27
pred is:
 ['']
 label is:
 ['the Charleston Orange district']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:35,038 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:35,038 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 156, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:35,039 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:35,039 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:35,039 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:35,979 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:35,980 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413158893585205 s; generated tokens: 1 tokens; generate speed: 1.0623426325900767 tokens/s
2024-06-05 16:25:35,985 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:35,985 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[538/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.8286 tokens/s, remaining time: 0:25:26
pred is:
 ['']
 label is:
 ['William III of Orange']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:36,067 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:36,067 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 172, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:36,067 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:36,068 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:36,068 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:37,008 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:37,010 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419238567352295 s; generated tokens: 1 tokens; generate speed: 1.0616569405791103 tokens/s
2024-06-05 16:25:37,015 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:37,015 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[539/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.8272 tokens/s, remaining time: 0:25:25
pred is:
 ['']
 label is:
 ['Edict of Fontainebleau']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:37,101 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:37,101 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 167, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:37,101 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:37,102 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:37,102 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:38,042 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:38,045 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427366256713867 s; generated tokens: 1 tokens; generate speed: 1.0607416459372543 tokens/s
2024-06-05 16:25:38,049 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:38,050 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[540/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.8259 tokens/s, remaining time: 0:25:23
pred is:
 ['']
 label is:
 ['Catholic Church in France']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.941334368096614, Em score: 2.037037037037037, current_count: 540
2024-06-05 16:25:38,233 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:38,233 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 217, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:38,234 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:38,234 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:38,234 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:39,175 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:39,177 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421210289001465 s; generated tokens: 1 tokens; generate speed: 1.0614347512945579 tokens/s
2024-06-05 16:25:39,181 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:39,181 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[541/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.8245 tokens/s, remaining time: 0:25:22
pred is:
 ['']
 label is:
 ['between 1621 and 1629']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:39,262 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:39,262 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:39,263 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:39,263 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:39,263 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:40,203 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:40,205 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413716793060303 s; generated tokens: 1 tokens; generate speed: 1.0622796733562134 tokens/s
2024-06-05 16:25:40,209 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:40,210 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[542/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.8231 tokens/s, remaining time: 0:25:21
pred is:
 ['']
 label is:
 ['one million']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:40,291 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:40,291 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 191, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:40,292 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:40,292 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:40,292 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:41,233 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:41,234 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419443607330322 s; generated tokens: 1 tokens; generate speed: 1.0616338307092663 tokens/s
2024-06-05 16:25:41,239 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:41,239 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[543/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.8218 tokens/s, remaining time: 0:25:20
pred is:
 ['']
 label is:
 ['New Rochelle']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:41,320 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:41,320 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 230, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:41,320 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:41,321 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:41,321 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:42,262 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:42,264 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425191879272461 s; generated tokens: 1 tokens; generate speed: 1.0609863574227743 tokens/s
2024-06-05 16:25:42,268 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:42,268 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[544/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0489 tokens/s, avg speed: 1.8204 tokens/s, remaining time: 0:25:19
pred is:
 ['']
 label is:
 ['the Dutch Republic']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:42,350 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:42,350 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 220, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:42,350 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:42,351 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:42,351 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:43,292 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:43,295 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439313411712646 s; generated tokens: 1 tokens; generate speed: 1.0593990859114428 tokens/s
2024-06-05 16:25:43,300 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:43,300 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[545/2067], cost time 0.9552s, every example cost time is 0.9552, generate speed: 1.0469 tokens/s, avg speed: 1.8190 tokens/s, remaining time: 0:25:18
pred is:
 ['']
 label is:
 ['Tours']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:43,381 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:43,381 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 241, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:43,382 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:43,382 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:43,382 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:44,323 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:44,324 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422366619110107 s; generated tokens: 1 tokens; generate speed: 1.0613044900755992 tokens/s
2024-06-05 16:25:44,329 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:44,329 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[546/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.8177 tokens/s, remaining time: 0:25:17
pred is:
 ['']
 label is:
 ['Canterbury']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:44,410 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:44,410 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 200, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:44,410 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:44,411 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:44,411 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:45,351 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:45,353 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420871734619141 s; generated tokens: 1 tokens; generate speed: 1.061472895682543 tokens/s
2024-06-05 16:25:45,358 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:45,358 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[547/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0493 tokens/s, avg speed: 1.8163 tokens/s, remaining time: 0:25:16
pred is:
 ['']
 label is:
 ['Cork City']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:45,438 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:45,439 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 197, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:45,439 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:45,439 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:45,439 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:46,379 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:46,381 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416465759277344 s; generated tokens: 1 tokens; generate speed: 1.0619695600918788 tokens/s
2024-06-05 16:25:46,386 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:46,386 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[548/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.8150 tokens/s, remaining time: 0:25:14
pred is:
 ['']
 label is:
 ['brain drain']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:46,468 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:46,468 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:46,468 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:46,468 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:46,469 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:47,408 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:47,410 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413437843322754 s; generated tokens: 1 tokens; generate speed: 1.062311152040305 tokens/s
2024-06-05 16:25:47,415 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:47,415 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[549/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.8137 tokens/s, remaining time: 0:25:13
pred is:
 ['']
 label is:
 ['Henry of Navarre']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:47,496 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:47,496 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 199, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:47,496 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:47,496 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:47,497 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:48,437 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:48,439 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423952102661133 s; generated tokens: 1 tokens; generate speed: 1.0611259364503989 tokens/s
2024-06-05 16:25:48,444 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:48,444 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[550/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.8124 tokens/s, remaining time: 0:25:12
pred is:
 ['']
 label is:
 ['education of children as Catholics']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.8878555614039483, Em score: 2.0, current_count: 550
2024-06-05 16:25:48,602 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:48,602 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 278, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:48,603 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:48,603 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:48,603 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:49,545 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:49,547 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435443878173828 s; generated tokens: 1 tokens; generate speed: 1.0598335519892297 tokens/s
2024-06-05 16:25:49,551 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:49,552 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[551/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0476 tokens/s, avg speed: 1.8110 tokens/s, remaining time: 0:25:11
pred is:
 ['']
 label is:
 ['Switzerland and the Netherlands']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:49,634 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:49,635 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 346, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:49,635 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:49,635 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:49,635 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:50,578 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:50,580 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9447784423828125 s; generated tokens: 1 tokens; generate speed: 1.0584492142707171 tokens/s
2024-06-05 16:25:50,585 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:50,585 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[552/2067], cost time 0.9564s, every example cost time is 0.9564, generate speed: 1.0456 tokens/s, avg speed: 1.8097 tokens/s, remaining time: 0:25:10
pred is:
 ['']
 label is:
 ['Afrikaans']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:50,666 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:50,666 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 206, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:50,666 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:50,666 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:50,667 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:51,607 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:51,609 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419469833374023 s; generated tokens: 1 tokens; generate speed: 1.061630874868255 tokens/s
2024-06-05 16:25:51,613 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:51,614 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[553/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.8084 tokens/s, remaining time: 0:25:09
pred is:
 ['']
 label is:
 ['Paul Revere']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:51,695 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:51,695 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 233, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:51,695 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:51,696 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:51,696 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:52,636 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:52,638 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422528743743896 s; generated tokens: 1 tokens; generate speed: 1.0612862292024863 tokens/s
2024-06-05 16:25:52,643 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:52,643 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[554/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.8071 tokens/s, remaining time: 0:25:08
pred is:
 ['']
 label is:
 ['lace']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:52,723 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:52,724 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:52,724 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:52,724 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:52,725 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:53,665 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:53,667 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426429271697998 s; generated tokens: 1 tokens; generate speed: 1.0608470834257566 tokens/s
2024-06-05 16:25:53,672 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:53,672 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[555/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.8058 tokens/s, remaining time: 0:25:07
pred is:
 ['']
 label is:
 ['Dorotheenstadt and Friedrichstadt']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:53,778 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:53,778 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 215, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:53,779 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:53,779 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:53,779 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:54,720 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:54,722 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942406177520752 s; generated tokens: 1 tokens; generate speed: 1.0611135875942195 tokens/s
2024-06-05 16:25:54,726 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:54,727 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[556/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.8045 tokens/s, remaining time: 0:25:06
pred is:
 ['']
 label is:
 ['Prussia']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:54,808 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:54,808 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 212, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:54,809 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:54,809 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:54,809 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:55,749 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:55,751 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417934417724609 s; generated tokens: 1 tokens; generate speed: 1.0618039536546293 tokens/s
2024-06-05 16:25:55,756 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:55,756 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[557/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.8032 tokens/s, remaining time: 0:25:04
pred is:
 ['']
 label is:
 ['Jacksonville']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:55,836 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:55,837 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 241, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:55,837 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:55,837 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:55,837 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:56,778 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:56,780 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422111511230469 s; generated tokens: 1 tokens; generate speed: 1.0613332253689345 tokens/s
2024-06-05 16:25:56,784 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:56,785 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[558/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.8019 tokens/s, remaining time: 0:25:03
pred is:
 ['']
 label is:
 ['Charlesfort']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:56,866 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:56,867 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 305, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:56,867 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:56,867 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:56,868 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:57,810 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:57,812 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9441187381744385 s; generated tokens: 1 tokens; generate speed: 1.0591888070494335 tokens/s
2024-06-05 16:25:57,816 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:57,817 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[559/2067], cost time 0.9559s, every example cost time is 0.9559, generate speed: 1.0462 tokens/s, avg speed: 1.8006 tokens/s, remaining time: 0:25:02
pred is:
 ['']
 label is:
 ['Virginia']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:25:57,898 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:57,898 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 317, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:57,898 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:57,899 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:57,899 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:58,841 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:58,844 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445765018463135 s; generated tokens: 1 tokens; generate speed: 1.0586754995972831 tokens/s
2024-06-05 16:25:58,848 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:58,849 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[560/2067], cost time 0.9554s, every example cost time is 0.9554, generate speed: 1.0467 tokens/s, avg speed: 1.7993 tokens/s, remaining time: 0:25:01
pred is:
 ['']
 label is:
 ['1568–1609']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.8362867120931634, Em score: 1.9642857142857142, current_count: 560
2024-06-05 16:25:59,008 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:25:59,008 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 172, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:25:59,009 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:59,009 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:25:59,009 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:25:59,949 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:25:59,951 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414269924163818 s; generated tokens: 1 tokens; generate speed: 1.0622172596021253 tokens/s
2024-06-05 16:25:59,955 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:25:59,956 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[561/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7980 tokens/s, remaining time: 0:25:00
pred is:
 ['']
 label is:
 ['Foreign Protestants Naturalization Act']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:00,037 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:00,037 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:00,038 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:00,038 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:00,038 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:00,978 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:00,980 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419302940368652 s; generated tokens: 1 tokens; generate speed: 1.0616496850465051 tokens/s
2024-06-05 16:26:00,985 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:00,985 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[562/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.7967 tokens/s, remaining time: 0:24:59
pred is:
 ['']
 label is:
 ['Williamite war']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:01,089 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:01,090 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 206, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:01,090 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:01,090 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:01,090 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:02,031 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:02,033 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423973560333252 s; generated tokens: 1 tokens; generate speed: 1.0611235203472258 tokens/s
2024-06-05 16:26:02,038 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:02,038 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[563/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.7955 tokens/s, remaining time: 0:24:58
pred is:
 ['']
 label is:
 ['Prince Louis de Condé']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:02,119 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:02,119 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 168, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:02,120 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:02,120 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:02,120 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:03,060 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:03,062 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416358470916748 s; generated tokens: 1 tokens; generate speed: 1.061981659989462 tokens/s
2024-06-05 16:26:03,066 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:03,067 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[564/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.7942 tokens/s, remaining time: 0:24:57
pred is:
 ['']
 label is:
 ['Electorate of Brandenburg and Electorate of the Palatinate']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:03,148 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:03,148 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:03,148 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:03,149 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:03,149 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:04,089 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:04,091 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423315525054932 s; generated tokens: 1 tokens; generate speed: 1.0611976191831598 tokens/s
2024-06-05 16:26:04,096 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:04,096 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[565/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.7929 tokens/s, remaining time: 0:24:56
pred is:
 ['']
 label is:
 ['Hugues Capet']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:04,177 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:04,177 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 322, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:04,178 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:04,178 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:04,178 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:05,120 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:05,158 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:05,188 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:05,217 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:05,246 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:05,275 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:05,304 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:05,334 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:05,363 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:05,392 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:05,509 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.330437421798706 s; generated tokens: 14 tokens; generate speed: 10.52285494275445 tokens/s
2024-06-05 16:26:05,513 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:05,514 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[566/2067], cost time 1.3414s, every example cost time is 1.3414, generate speed: 10.4365 tokens/s, avg speed: 1.8135 tokens/s, remaining time: 0:24:55
pred is:
 ['Jacques Lefevre']
 label is:
 ['Jacques Lefevre']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:26:05,595 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:05,595 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 254, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:05,595 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:05,596 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:05,596 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:06,537 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:06,539 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428322315216064 s; generated tokens: 1 tokens; generate speed: 1.0606340837395136 tokens/s
2024-06-05 16:26:06,543 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:06,544 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[567/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.8122 tokens/s, remaining time: 0:24:54
pred is:
 ['']
 label is:
 ['24 August – 3 October 1572']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:06,625 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:06,625 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 174, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:06,625 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:06,625 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:06,626 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:07,566 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:07,568 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416966438293457 s; generated tokens: 1 tokens; generate speed: 1.0619130975486624 tokens/s
2024-06-05 16:26:07,572 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:07,572 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[568/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.8109 tokens/s, remaining time: 0:24:53
pred is:
 ['']
 label is:
 ['Louis XIV']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:07,654 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:07,654 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 367, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:07,654 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:07,654 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:07,655 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:08,598 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:08,600 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9452803134918213 s; generated tokens: 1 tokens; generate speed: 1.0578872591835184 tokens/s
2024-06-05 16:26:08,605 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:08,605 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[569/2067], cost time 0.9564s, every example cost time is 0.9564, generate speed: 1.0456 tokens/s, avg speed: 1.8096 tokens/s, remaining time: 0:24:52
pred is:
 ['']
 label is:
 ['Westchester']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:08,686 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:08,686 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 186, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:08,686 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:08,687 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:08,687 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:09,629 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:09,633 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9459278583526611 s; generated tokens: 1 tokens; generate speed: 1.0571630713377083 tokens/s
2024-06-05 16:26:09,638 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:09,638 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[570/2067], cost time 0.9571s, every example cost time is 0.9571, generate speed: 1.0448 tokens/s, avg speed: 1.8083 tokens/s, remaining time: 0:24:51
pred is:
 ['']
 label is:
 ['affiliated with other Protestant denominations']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.961965892582757, Em score: 2.1052631578947367, current_count: 570
2024-06-05 16:26:09,800 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:09,800 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 210, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:09,801 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:09,801 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:09,801 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:10,742 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:10,744 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422609806060791 s; generated tokens: 1 tokens; generate speed: 1.061277099001576 tokens/s
2024-06-05 16:26:10,748 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:10,748 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[571/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.8071 tokens/s, remaining time: 0:24:50
pred is:
 ['']
 label is:
 ['Pierre Bayle']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:10,829 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:10,829 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 225, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:10,830 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:10,830 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:10,830 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:11,771 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:11,773 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424741268157959 s; generated tokens: 1 tokens; generate speed: 1.0610370847829622 tokens/s
2024-06-05 16:26:11,777 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:11,778 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[572/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.8058 tokens/s, remaining time: 0:24:49
pred is:
 ['']
 label is:
 ['The French Protestant Church of London']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:11,859 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:11,860 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 350, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:11,860 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:11,860 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:11,861 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:12,804 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:12,806 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9448502063751221 s; generated tokens: 1 tokens; generate speed: 1.0583688221188603 tokens/s
2024-06-05 16:26:12,810 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:12,810 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[573/2067], cost time 0.9561s, every example cost time is 0.9561, generate speed: 1.0459 tokens/s, avg speed: 1.8045 tokens/s, remaining time: 0:24:48
pred is:
 ['']
 label is:
 ['Lutheran and Reformed']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:12,891 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:12,892 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 219, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:12,892 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:12,892 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:12,892 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:13,833 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:13,835 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422996044158936 s; generated tokens: 1 tokens; generate speed: 1.0612335984369572 tokens/s
2024-06-05 16:26:13,839 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:13,840 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[574/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.8033 tokens/s, remaining time: 0:24:47
pred is:
 ['']
 label is:
 ['Frederick William']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:13,921 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:13,922 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:13,922 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:13,922 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:13,922 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:14,863 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:14,865 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426679611206055 s; generated tokens: 1 tokens; generate speed: 1.0608189110524564 tokens/s
2024-06-05 16:26:14,870 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:14,870 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[575/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.8020 tokens/s, remaining time: 0:24:46
pred is:
 ['']
 label is:
 ['solar']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:14,951 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:14,951 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 200, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:14,951 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:14,952 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:14,952 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:15,892 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:15,894 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420335292816162 s; generated tokens: 1 tokens; generate speed: 1.061533341347827 tokens/s
2024-06-05 16:26:15,899 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:15,899 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[576/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.8008 tokens/s, remaining time: 0:24:44
pred is:
 ['']
 label is:
 ['atmospheric engine']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:15,986 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:15,986 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 197, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:15,987 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:15,987 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:15,987 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:16,928 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:16,930 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423508644104004 s; generated tokens: 1 tokens; generate speed: 1.0611758717127817 tokens/s
2024-06-05 16:26:16,934 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:16,934 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[577/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.7995 tokens/s, remaining time: 0:24:43
pred is:
 ['']
 label is:
 ['United Kingdom']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:17,015 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:17,015 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 153, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:17,016 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:17,016 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:17,016 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:17,956 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:17,958 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417171478271484 s; generated tokens: 1 tokens; generate speed: 1.061889976525679 tokens/s
2024-06-05 16:26:17,963 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:17,963 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[578/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.7983 tokens/s, remaining time: 0:24:42
pred is:
 ['']
 label is:
 ['water pump']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:18,044 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:18,044 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 295, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:18,044 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:18,045 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:18,045 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:18,987 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:18,988 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436018466949463 s; generated tokens: 1 tokens; generate speed: 1.0597690153983839 tokens/s
2024-06-05 16:26:18,993 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:18,993 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[579/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0477 tokens/s, avg speed: 1.7970 tokens/s, remaining time: 0:24:41
pred is:
 ['']
 label is:
 ['three']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:19,074 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:19,074 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 282, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:19,075 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:19,075 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:19,075 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:20,017 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:20,019 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.944171667098999 s; generated tokens: 1 tokens; generate speed: 1.0591294304271335 tokens/s
2024-06-05 16:26:20,024 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:20,024 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[580/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.7958 tokens/s, remaining time: 0:24:40
pred is:
 ['']
 label is:
 ['Corliss']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.9108975151244336, Em score: 2.0689655172413794, current_count: 580
2024-06-05 16:26:20,193 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:20,193 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 164, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:20,194 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:20,194 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:20,194 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:21,134 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:21,136 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941601037979126 s; generated tokens: 1 tokens; generate speed: 1.0620209193335326 tokens/s
2024-06-05 16:26:21,141 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:21,141 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[581/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7946 tokens/s, remaining time: 0:24:39
pred is:
 ['']
 label is:
 ['Lead fusible plugs']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:21,227 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:21,228 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 186, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:21,228 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:21,228 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:21,228 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:22,169 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:22,171 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421508312225342 s; generated tokens: 1 tokens; generate speed: 1.0614011757569652 tokens/s
2024-06-05 16:26:22,175 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:22,176 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[582/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.7933 tokens/s, remaining time: 0:24:38
pred is:
 ['']
 label is:
 ['James Watt']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:22,257 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:22,257 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:22,258 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:22,258 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:22,258 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:23,199 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:23,201 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430549144744873 s; generated tokens: 1 tokens; generate speed: 1.0603836368927095 tokens/s
2024-06-05 16:26:23,206 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:23,206 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[583/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.7921 tokens/s, remaining time: 0:24:37
pred is:
 ['']
 label is:
 ['first']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:23,287 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:23,287 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 182, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:23,288 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:23,288 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:23,288 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:24,229 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:24,231 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420931339263916 s; generated tokens: 1 tokens; generate speed: 1.061466179922433 tokens/s
2024-06-05 16:26:24,235 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:24,235 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[584/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.7909 tokens/s, remaining time: 0:24:36
pred is:
 ['']
 label is:
 ['compound']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:24,316 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:24,317 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:24,317 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:24,317 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:24,317 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:25,259 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:25,261 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94356369972229 s; generated tokens: 1 tokens; generate speed: 1.0598118603908993 tokens/s
2024-06-05 16:26:25,266 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:25,266 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[585/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0475 tokens/s, avg speed: 1.7897 tokens/s, remaining time: 0:24:34
pred is:
 ['']
 label is:
 ['steam turbines']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:25,347 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:25,347 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 148, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:25,347 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:25,348 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:25,348 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:26,287 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:26,289 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414117336273193 s; generated tokens: 1 tokens; generate speed: 1.062234476456902 tokens/s
2024-06-05 16:26:26,299 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:26,299 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[586/2067], cost time 0.9571s, every example cost time is 0.9571, generate speed: 1.0449 tokens/s, avg speed: 1.7884 tokens/s, remaining time: 0:24:33
pred is:
 ['']
 label is:
 ['burning combustible materials']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:26,381 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:26,381 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 173, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:26,381 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:26,382 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:26,382 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:27,322 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:27,324 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419207572937012 s; generated tokens: 1 tokens; generate speed: 1.061660434019068 tokens/s
2024-06-05 16:26:27,329 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:27,329 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[587/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7872 tokens/s, remaining time: 0:24:32
pred is:
 ['']
 label is:
 ['steam engine indicator']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:27,409 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:27,410 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 235, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:27,410 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:27,410 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:27,410 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:28,352 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:28,353 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427955150604248 s; generated tokens: 1 tokens; generate speed: 1.0606753893349916 tokens/s
2024-06-05 16:26:28,358 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:28,358 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[588/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.7860 tokens/s, remaining time: 0:24:31
pred is:
 ['']
 label is:
 ['90']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:28,438 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:28,439 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 173, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:28,439 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:28,439 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:28,439 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:29,380 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:29,382 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420120716094971 s; generated tokens: 1 tokens; generate speed: 1.0615575215415511 tokens/s
2024-06-05 16:26:29,386 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:29,386 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[589/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7848 tokens/s, remaining time: 0:24:30
pred is:
 ['']
 label is:
 ['counterflow']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:29,467 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:29,468 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 250, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:29,468 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:29,468 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:29,468 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:30,410 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:30,412 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436416625976562 s; generated tokens: 1 tokens; generate speed: 1.05972429963213 tokens/s
2024-06-05 16:26:30,417 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:30,417 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[590/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.7836 tokens/s, remaining time: 0:24:29
pred is:
 ['']
 label is:
 ['Quasiturbine']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.8615602691053756, Em score: 2.0338983050847457, current_count: 590
2024-06-05 16:26:30,588 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:30,589 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:30,589 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:30,589 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:30,589 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:31,530 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:31,532 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421069622039795 s; generated tokens: 1 tokens; generate speed: 1.0614505996862444 tokens/s
2024-06-05 16:26:31,536 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:31,537 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[591/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.7824 tokens/s, remaining time: 0:24:28
pred is:
 ['']
 label is:
 ['oscillating cylinder']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:31,623 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:31,623 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 167, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:31,624 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:31,624 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:31,624 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:32,564 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:32,566 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415445327758789 s; generated tokens: 1 tokens; generate speed: 1.0620846547234273 tokens/s
2024-06-05 16:26:32,571 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:32,571 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[592/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.7813 tokens/s, remaining time: 0:24:27
pred is:
 ['']
 label is:
 ['recycled continuously']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:32,652 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:32,652 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 186, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:32,652 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:32,652 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:32,653 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:33,593 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:33,595 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419398307800293 s; generated tokens: 1 tokens; generate speed: 1.0616389362915999 tokens/s
2024-06-05 16:26:33,599 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:33,600 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[593/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7801 tokens/s, remaining time: 0:24:26
pred is:
 ['']
 label is:
 ['working fluid']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:33,681 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:33,682 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 150, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:33,682 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:33,682 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:33,682 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:34,622 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:34,624 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414570331573486 s; generated tokens: 1 tokens; generate speed: 1.0621833655502224 tokens/s
2024-06-05 16:26:34,629 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:34,629 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[594/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7789 tokens/s, remaining time: 0:24:25
pred is:
 ['']
 label is:
 ['Steam engines']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:34,710 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:34,710 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 190, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:34,711 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:34,711 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:34,711 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:35,653 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:35,655 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437668323516846 s; generated tokens: 1 tokens; generate speed: 1.0595837506899806 tokens/s
2024-06-05 16:26:35,660 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:35,660 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[595/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0473 tokens/s, avg speed: 1.7777 tokens/s, remaining time: 0:24:24
pred is:
 ['']
 label is:
 ['Catch Me Who Can']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:35,741 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:35,742 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 226, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:35,742 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:35,742 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:35,742 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:36,683 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:36,685 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942723274230957 s; generated tokens: 1 tokens; generate speed: 1.0607566688281538 tokens/s
2024-06-05 16:26:36,690 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:36,690 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[596/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.7765 tokens/s, remaining time: 0:24:22
pred is:
 ['']
 label is:
 ['Arthur Woolf']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:36,772 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:36,772 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 242, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:36,772 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:36,772 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:36,773 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:37,714 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:37,716 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432373046875 s; generated tokens: 1 tokens; generate speed: 1.0601785945386308 tokens/s
2024-06-05 16:26:37,721 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:37,721 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[597/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0477 tokens/s, avg speed: 1.7754 tokens/s, remaining time: 0:24:21
pred is:
 ['']
 label is:
 ['90']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:37,813 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:37,813 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:37,813 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:37,814 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:37,814 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:38,755 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:38,756 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424717426300049 s; generated tokens: 1 tokens; generate speed: 1.0610397689053894 tokens/s
2024-06-05 16:26:38,761 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:38,761 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[598/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0485 tokens/s, avg speed: 1.7742 tokens/s, remaining time: 0:24:20
pred is:
 ['']
 label is:
 ['Rankine cycle']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:38,842 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:38,842 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 196, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:38,843 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:38,843 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:38,843 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:39,784 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:39,785 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942014217376709 s; generated tokens: 1 tokens; generate speed: 1.0615551034726078 tokens/s
2024-06-05 16:26:39,790 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:39,790 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[599/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.7730 tokens/s, remaining time: 0:24:19
pred is:
 ['']
 label is:
 ['duty']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:39,872 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:39,872 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 157, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:39,872 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:39,872 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:39,873 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:40,813 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:40,815 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942162036895752 s; generated tokens: 1 tokens; generate speed: 1.061388551904313 tokens/s
2024-06-05 16:26:40,820 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:40,820 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[600/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.7719 tokens/s, remaining time: 0:24:18
pred is:
 ['']
 label is:
 ['steam turbines']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.813867597953619, Em score: 2.0, current_count: 600
2024-06-05 16:26:40,985 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:40,986 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:40,986 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:40,986 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:40,986 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:41,928 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:41,930 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428999423980713 s; generated tokens: 1 tokens; generate speed: 1.0605579182205764 tokens/s
2024-06-05 16:26:41,934 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:41,935 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[601/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.7707 tokens/s, remaining time: 0:24:17
pred is:
 ['']
 label is:
 ['Thomas Savery']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:42,016 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:42,016 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 165, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:42,017 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:42,017 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:42,017 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:42,958 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:42,959 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419300556182861 s; generated tokens: 1 tokens; generate speed: 1.0616499537681665 tokens/s
2024-06-05 16:26:42,964 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:42,964 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[602/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7696 tokens/s, remaining time: 0:24:16
pred is:
 ['']
 label is:
 ['Richard Trevithick']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:43,047 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:43,047 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 175, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:43,048 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:43,048 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:43,048 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:43,988 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:43,990 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417610168457031 s; generated tokens: 1 tokens; generate speed: 1.0618405116718042 tokens/s
2024-06-05 16:26:43,995 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:43,995 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[603/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0489 tokens/s, avg speed: 1.7684 tokens/s, remaining time: 0:24:15
pred is:
 ['']
 label is:
 ['Energiprojekt AB']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:44,076 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:44,076 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 284, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:44,077 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:44,077 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:44,077 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:45,019 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:45,021 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437637329101562 s; generated tokens: 1 tokens; generate speed: 1.0595872304993492 tokens/s
2024-06-05 16:26:45,026 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:45,026 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[604/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0474 tokens/s, avg speed: 1.7673 tokens/s, remaining time: 0:24:14
pred is:
 ['']
 label is:
 ['surface condensers']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:45,107 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:45,107 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:45,108 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:45,108 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:45,108 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:46,050 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:46,052 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435851573944092 s; generated tokens: 1 tokens; generate speed: 1.0597877596563443 tokens/s
2024-06-05 16:26:46,057 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:46,057 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[605/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0477 tokens/s, avg speed: 1.7662 tokens/s, remaining time: 0:24:13
pred is:
 ['']
 label is:
 ['centrifugal governor']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:46,138 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:46,138 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 147, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:46,138 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:46,139 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:46,139 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:47,079 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:47,081 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417257308959961 s; generated tokens: 1 tokens; generate speed: 1.0618802982568603 tokens/s
2024-06-05 16:26:47,085 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:47,086 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[606/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.7650 tokens/s, remaining time: 0:24:11
pred is:
 ['']
 label is:
 ['1880']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:47,167 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:47,167 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 191, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:47,168 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:47,168 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:47,168 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:48,109 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:48,110 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94209885597229 s; generated tokens: 1 tokens; generate speed: 1.0614597328726754 tokens/s
2024-06-05 16:26:48,115 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:48,115 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[607/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7639 tokens/s, remaining time: 0:24:10
pred is:
 ['']
 label is:
 ['shortening the cutoff']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:48,197 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:48,197 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 182, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:48,197 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:48,197 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:48,198 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:49,138 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:49,140 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418542385101318 s; generated tokens: 1 tokens; generate speed: 1.0617354141569144 tokens/s
2024-06-05 16:26:49,144 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:49,145 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[608/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.7628 tokens/s, remaining time: 0:24:09
pred is:
 ['']
 label is:
 ['Jerónimo de Ayanz y Beaumont']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:49,226 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:49,226 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 353, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:49,227 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:49,227 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:49,227 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:50,170 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:50,172 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.944976806640625 s; generated tokens: 1 tokens; generate speed: 1.0582270305183272 tokens/s
2024-06-05 16:26:50,177 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:50,177 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[609/2067], cost time 0.9560s, every example cost time is 0.9560, generate speed: 1.0460 tokens/s, avg speed: 1.7616 tokens/s, remaining time: 0:24:08
pred is:
 ['']
 label is:
 ['rotating discs']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:50,257 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:50,257 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 170, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:50,258 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:50,258 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:50,258 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:51,198 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:51,201 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429135322570801 s; generated tokens: 1 tokens; generate speed: 1.0605426327971668 tokens/s
2024-06-05 16:26:51,206 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:51,206 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[610/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.7605 tokens/s, remaining time: 0:24:07
pred is:
 ['']
 label is:
 ['lower']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.7677386209379864, Em score: 1.9672131147540983, current_count: 610
2024-06-05 16:26:51,374 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:51,374 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 191, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:51,375 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:51,375 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:51,375 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:52,316 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:52,317 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420433044433594 s; generated tokens: 1 tokens; generate speed: 1.0615223262914506 tokens/s
2024-06-05 16:26:52,322 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:52,322 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[611/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0489 tokens/s, avg speed: 1.7594 tokens/s, remaining time: 0:24:06
pred is:
 ['']
 label is:
 ['Wankel']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:52,403 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:52,403 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:52,404 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:52,404 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:52,404 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:53,344 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:53,346 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419751167297363 s; generated tokens: 1 tokens; generate speed: 1.0615991677908745 tokens/s
2024-06-05 16:26:53,351 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:53,351 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[612/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7583 tokens/s, remaining time: 0:24:05
pred is:
 ['']
 label is:
 ['1775']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:53,432 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:53,432 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 211, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:53,433 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:53,433 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:53,433 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:54,374 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:54,376 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424986839294434 s; generated tokens: 1 tokens; generate speed: 1.0610094391122367 tokens/s
2024-06-05 16:26:54,380 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:54,381 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[613/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.7572 tokens/s, remaining time: 0:24:04
pred is:
 ['']
 label is:
 ['two']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:54,461 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:54,462 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 157, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:54,462 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:54,462 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:54,462 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:55,402 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:55,404 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417293071746826 s; generated tokens: 1 tokens; generate speed: 1.0618762656969203 tokens/s
2024-06-05 16:26:55,409 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:55,409 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[614/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7561 tokens/s, remaining time: 0:24:03
pred is:
 ['']
 label is:
 ['Corliss steam engine']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:55,490 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:55,490 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 212, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:55,491 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:55,491 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:55,491 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:56,432 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:56,434 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431374073028564 s; generated tokens: 1 tokens; generate speed: 1.06029088895939 tokens/s
2024-06-05 16:26:56,439 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:56,439 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[615/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.7550 tokens/s, remaining time: 0:24:02
pred is:
 ['']
 label is:
 ['thermodynamic']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:56,521 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:56,521 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 181, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:56,521 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:56,522 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:56,522 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:57,466 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:57,468 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9460740089416504 s; generated tokens: 1 tokens; generate speed: 1.0569997595840048 tokens/s
2024-06-05 16:26:57,473 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:57,473 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[616/2067], cost time 0.9569s, every example cost time is 0.9569, generate speed: 1.0450 tokens/s, avg speed: 1.7538 tokens/s, remaining time: 0:24:01
pred is:
 ['']
 label is:
 ['during the compression stage relatively little work is required to drive the pump']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:57,555 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:57,555 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 161, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:57,556 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:57,556 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:57,556 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:58,496 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:58,498 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419572353363037 s; generated tokens: 1 tokens; generate speed: 1.0616193203749569 tokens/s
2024-06-05 16:26:58,503 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:58,503 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[617/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7527 tokens/s, remaining time: 0:24:00
pred is:
 ['']
 label is:
 ['injector']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:58,592 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:58,592 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 170, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:58,593 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:58,593 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:58,593 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:26:59,534 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:59,537 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434700012207031 s; generated tokens: 1 tokens; generate speed: 1.05991711311028 tokens/s
2024-06-05 16:26:59,541 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:26:59,542 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[618/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.7516 tokens/s, remaining time: 0:23:58
pred is:
 ['']
 label is:
 ['feed water']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:26:59,624 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:26:59,624 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 235, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:26:59,624 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:26:59,625 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:26:59,625 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:00,567 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:00,570 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9453012943267822 s; generated tokens: 1 tokens; generate speed: 1.057863779518225 tokens/s
2024-06-05 16:27:00,575 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:00,575 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[619/2067], cost time 0.9572s, every example cost time is 0.9572, generate speed: 1.0447 tokens/s, avg speed: 1.7505 tokens/s, remaining time: 0:23:57
pred is:
 ['']
 label is:
 ['water']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:00,682 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:00,682 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 240, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:00,683 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:00,683 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:00,683 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:01,624 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:01,627 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434738159179688 s; generated tokens: 1 tokens; generate speed: 1.059912827604053 tokens/s
2024-06-05 16:27:01,631 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:01,631 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[620/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0474 tokens/s, avg speed: 1.7495 tokens/s, remaining time: 0:23:56
pred is:
 ['']
 label is:
 ['practical Carnot cycle']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.7230976754389866, Em score: 1.935483870967742, current_count: 620
2024-06-05 16:27:01,801 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:01,801 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:01,802 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:01,802 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:01,802 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:02,743 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:02,745 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427013397216797 s; generated tokens: 1 tokens; generate speed: 1.0607813502155805 tokens/s
2024-06-05 16:27:02,750 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:02,750 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[621/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.7484 tokens/s, remaining time: 0:23:55
pred is:
 ['']
 label is:
 ['8']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:02,831 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:02,831 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 249, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:02,831 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:02,832 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:02,832 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:03,773 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:03,775 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432268142700195 s; generated tokens: 1 tokens; generate speed: 1.0601903856750703 tokens/s
2024-06-05 16:27:03,780 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:03,780 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[622/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.7473 tokens/s, remaining time: 0:23:54
pred is:
 ['']
 label is:
 ['photosynthesis']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:03,861 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:03,862 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 172, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:03,862 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:03,862 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:03,862 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:04,803 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:04,805 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419960975646973 s; generated tokens: 1 tokens; generate speed: 1.0615755230677257 tokens/s
2024-06-05 16:27:04,809 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:04,810 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[623/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7462 tokens/s, remaining time: 0:23:53
pred is:
 ['']
 label is:
 ['Robert Boyle']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:04,890 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:04,890 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 245, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:04,891 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:04,891 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:04,891 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:05,833 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:05,835 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430782794952393 s; generated tokens: 1 tokens; generate speed: 1.0603573655998384 tokens/s
2024-06-05 16:27:05,839 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:05,839 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[624/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.7451 tokens/s, remaining time: 0:23:52
pred is:
 ['']
 label is:
 ['Joseph Priestley']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:05,921 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:05,921 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:05,922 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:05,922 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:05,922 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:06,863 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:06,902 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:06,932 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:06,961 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:06,990 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:07,019 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:07,048 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:07,077 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:07,106 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:07,135 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:07,423 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5011770725250244 s; generated tokens: 20 tokens; generate speed: 13.322878670375244 tokens/s
2024-06-05 16:27:07,428 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:07,428 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[625/2067], cost time 1.5124s, every example cost time is 1.5124, generate speed: 13.2240 tokens/s, avg speed: 1.7731 tokens/s, remaining time: 0:23:52
pred is:
 ['Leonardo da Vinci']
 label is:
 ['Leonardo da Vinci']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:27:07,510 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:07,510 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 161, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:07,511 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:07,511 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:07,511 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:08,450 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:08,452 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9407510757446289 s; generated tokens: 1 tokens; generate speed: 1.0629804480515466 tokens/s
2024-06-05 16:27:08,457 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:08,457 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[626/2067], cost time 0.9518s, every example cost time is 0.9518, generate speed: 1.0507 tokens/s, avg speed: 1.7720 tokens/s, remaining time: 0:23:51
pred is:
 ['']
 label is:
 ['heat or a spark']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:08,538 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:08,539 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 172, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:08,539 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:08,539 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:08,539 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:09,479 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:09,481 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413802623748779 s; generated tokens: 1 tokens; generate speed: 1.0622699879825805 tokens/s
2024-06-05 16:27:09,486 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:09,486 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[627/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.7709 tokens/s, remaining time: 0:23:50
pred is:
 ['']
 label is:
 ['pure O']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:09,567 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:09,567 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 200, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:09,568 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:09,568 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:09,568 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:10,508 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:10,510 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417181015014648 s; generated tokens: 1 tokens; generate speed: 1.0618889011537647 tokens/s
2024-06-05 16:27:10,515 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:10,515 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[628/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.7698 tokens/s, remaining time: 0:23:49
pred is:
 ['']
 label is:
 ['oxides of silicon']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:10,596 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:10,596 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 198, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:10,597 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:10,597 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:10,597 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:11,537 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:11,539 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417352676391602 s; generated tokens: 1 tokens; generate speed: 1.0618695448317486 tokens/s
2024-06-05 16:27:11,544 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:11,544 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[629/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.7687 tokens/s, remaining time: 0:23:48
pred is:
 ['']
 label is:
 ['monatomic']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:11,625 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:11,625 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 214, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:11,626 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:11,626 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:11,626 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:12,567 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:12,569 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423942565917969 s; generated tokens: 1 tokens; generate speed: 1.061127010277563 tokens/s
2024-06-05 16:27:12,573 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:12,573 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[630/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.7676 tokens/s, remaining time: 0:23:47
pred is:
 ['']
 label is:
 ['phlogiston']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.8386040615431294, Em score: 2.0634920634920637, current_count: 630
2024-06-05 16:27:12,743 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:12,743 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 245, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:12,744 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:12,744 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:12,744 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:13,686 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:13,687 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429402351379395 s; generated tokens: 1 tokens; generate speed: 1.0605125995643971 tokens/s
2024-06-05 16:27:13,692 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:13,692 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[631/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0481 tokens/s, avg speed: 1.7665 tokens/s, remaining time: 0:23:46
pred is:
 ['']
 label is:
 ['covalent double bond']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:13,773 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:13,773 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 247, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:13,774 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:13,774 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:13,774 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:14,716 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:14,718 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9440910816192627 s; generated tokens: 1 tokens; generate speed: 1.0592198353201736 tokens/s
2024-06-05 16:27:14,723 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:14,723 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[632/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.7654 tokens/s, remaining time: 0:23:45
pred is:
 ['']
 label is:
 ['1773']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:14,831 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:14,831 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 206, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:14,832 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:14,832 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:14,832 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:15,772 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:15,774 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419128894805908 s; generated tokens: 1 tokens; generate speed: 1.0616693020852923 tokens/s
2024-06-05 16:27:15,779 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:15,779 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[633/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7643 tokens/s, remaining time: 0:23:43
pred is:
 ['']
 label is:
 ['spin triplet state']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:15,859 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:15,860 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 231, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:15,860 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:15,860 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:15,860 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:16,801 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:16,803 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422893524169922 s; generated tokens: 1 tokens; generate speed: 1.0612451445354645 tokens/s
2024-06-05 16:27:16,808 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:16,808 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[634/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.7632 tokens/s, remaining time: 0:23:42
pred is:
 ['']
 label is:
 ['air']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:16,888 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:16,888 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 309, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:16,889 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:16,889 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:16,889 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:17,832 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:17,834 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9446496963500977 s; generated tokens: 1 tokens; generate speed: 1.0585934700066733 tokens/s
2024-06-05 16:27:17,839 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:17,839 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[635/2067], cost time 0.9555s, every example cost time is 0.9555, generate speed: 1.0466 tokens/s, avg speed: 1.7621 tokens/s, remaining time: 0:23:41
pred is:
 ['']
 label is:
 ['ozone']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:17,920 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:17,920 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 192, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:17,921 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:17,921 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:17,921 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:18,861 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:18,863 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415664672851562 s; generated tokens: 1 tokens; generate speed: 1.0620599126510173 tokens/s
2024-06-05 16:27:18,868 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:18,868 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[636/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.7611 tokens/s, remaining time: 0:23:40
pred is:
 ['']
 label is:
 ['dioxygen']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:18,948 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:18,949 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 176, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:18,949 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:18,949 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:18,950 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:19,889 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:19,891 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414417743682861 s; generated tokens: 1 tokens; generate speed: 1.0622005813062703 tokens/s
2024-06-05 16:27:19,896 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:19,896 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[637/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.7600 tokens/s, remaining time: 0:23:39
pred is:
 ['']
 label is:
 ['James Dewar']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:20,000 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:20,001 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 247, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:20,001 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:20,001 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:20,002 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:20,942 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:20,944 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425690174102783 s; generated tokens: 1 tokens; generate speed: 1.0609302677352095 tokens/s
2024-06-05 16:27:20,949 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:20,949 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[638/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.7589 tokens/s, remaining time: 0:23:38
pred is:
 ['']
 label is:
 ['Oxygen']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:21,030 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:21,031 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 248, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:21,031 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:21,031 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:21,032 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:21,973 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:21,974 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426589012145996 s; generated tokens: 1 tokens; generate speed: 1.060829106595734 tokens/s
2024-06-05 16:27:21,979 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:21,979 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[639/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.7579 tokens/s, remaining time: 0:23:37
pred is:
 ['']
 label is:
 ['most abundant']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:22,060 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:22,060 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 242, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:22,061 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:22,061 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:22,061 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:23,004 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:23,008 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9473221302032471 s; generated tokens: 1 tokens; generate speed: 1.0556071352259564 tokens/s
2024-06-05 16:27:23,013 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:23,014 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[640/2067], cost time 0.9587s, every example cost time is 0.9587, generate speed: 1.0431 tokens/s, avg speed: 1.7568 tokens/s, remaining time: 0:23:36
pred is:
 ['']
 label is:
 ['late 19th']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.794250873081518, Em score: 2.03125, current_count: 640
2024-06-05 16:27:23,185 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:23,185 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 182, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:23,185 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:23,186 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:23,186 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:24,125 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:24,127 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412329196929932 s; generated tokens: 1 tokens; generate speed: 1.062436278074693 tokens/s
2024-06-05 16:27:24,132 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:24,132 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[641/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.7557 tokens/s, remaining time: 0:23:35
pred is:
 ['']
 label is:
 ['Sun']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:24,238 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:24,238 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:24,238 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:24,238 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:24,239 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:25,179 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:25,181 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942267656326294 s; generated tokens: 1 tokens; generate speed: 1.0612695801305465 tokens/s
2024-06-05 16:27:25,186 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:25,186 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[642/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.7547 tokens/s, remaining time: 0:23:34
pred is:
 ['']
 label is:
 ['Singlet']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:25,266 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:25,266 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 229, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:25,267 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:25,267 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:25,267 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:26,208 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:26,209 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421629905700684 s; generated tokens: 1 tokens; generate speed: 1.06138747754774 tokens/s
2024-06-05 16:27:26,214 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:26,214 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[643/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7536 tokens/s, remaining time: 0:23:33
pred is:
 ['']
 label is:
 ['Paleoclimatologists']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:26,295 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:26,295 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 174, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:26,296 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:26,296 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:26,296 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:27,236 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:27,238 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941673994064331 s; generated tokens: 1 tokens; generate speed: 1.061938639384029 tokens/s
2024-06-05 16:27:27,242 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:27,243 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[644/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.7526 tokens/s, remaining time: 0:23:32
pred is:
 ['']
 label is:
 ['687 and 760 nm']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:27,324 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:27,324 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 147, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:27,325 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:27,325 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:27,325 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:28,265 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:28,267 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941230297088623 s; generated tokens: 1 tokens; generate speed: 1.0624392384022923 tokens/s
2024-06-05 16:27:28,271 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:28,271 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[645/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.7515 tokens/s, remaining time: 0:23:31
pred is:
 ['']
 label is:
 ['paramagnetic']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:28,352 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:28,352 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 190, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:28,353 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:28,353 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:28,353 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:29,293 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:29,294 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411585330963135 s; generated tokens: 1 tokens; generate speed: 1.0625202501326787 tokens/s
2024-06-05 16:27:29,299 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:29,299 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[646/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.7505 tokens/s, remaining time: 0:23:29
pred is:
 ['']
 label is:
 ['dangerous by-products']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:29,379 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:29,380 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 195, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:29,380 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:29,380 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:29,380 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:30,321 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:30,322 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418275356292725 s; generated tokens: 1 tokens; generate speed: 1.0617655166896987 tokens/s
2024-06-05 16:27:30,327 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:30,327 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[647/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.7494 tokens/s, remaining time: 0:23:28
pred is:
 ['']
 label is:
 ['90.20 K']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:30,408 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:30,408 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:30,408 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:30,409 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:30,409 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:31,349 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:31,351 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417715072631836 s; generated tokens: 1 tokens; generate speed: 1.0618286838025395 tokens/s
2024-06-05 16:27:31,355 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:31,356 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[648/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.7484 tokens/s, remaining time: 0:23:27
pred is:
 ['']
 label is:
 ['water']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:31,436 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:31,437 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:31,437 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:31,437 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:31,437 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:32,377 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:32,379 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414374828338623 s; generated tokens: 1 tokens; generate speed: 1.0622054233382083 tokens/s
2024-06-05 16:27:32,384 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:32,384 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[649/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.7474 tokens/s, remaining time: 0:23:26
pred is:
 ['']
 label is:
 ['3.5 billion years ago']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:32,465 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:32,465 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 169, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:32,466 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:32,466 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:32,466 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:33,406 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:33,408 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422004222869873 s; generated tokens: 1 tokens; generate speed: 1.061345310770204 tokens/s
2024-06-05 16:27:33,413 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:33,413 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[650/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7463 tokens/s, remaining time: 0:23:25
pred is:
 ['']
 label is:
 ['oxygen cycle']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.751262398111033, Em score: 2.0, current_count: 650
2024-06-05 16:27:33,585 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:33,585 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 215, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:33,586 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:33,586 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:33,586 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:34,527 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:34,529 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429712295532227 s; generated tokens: 1 tokens; generate speed: 1.0604777416950435 tokens/s
2024-06-05 16:27:34,534 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:34,534 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[651/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.7453 tokens/s, remaining time: 0:23:24
pred is:
 ['']
 label is:
 ['zeolite molecular sieves']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:34,615 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:34,615 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 261, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:34,616 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:34,616 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:34,616 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:35,558 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:35,559 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428815841674805 s; generated tokens: 1 tokens; generate speed: 1.060578567650096 tokens/s
2024-06-05 16:27:35,564 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:35,564 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[652/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.7443 tokens/s, remaining time: 0:23:23
pred is:
 ['']
 label is:
 ['water']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:35,646 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:35,646 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 179, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:35,647 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:35,647 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:35,647 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:36,587 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:36,589 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416244029998779 s; generated tokens: 1 tokens; generate speed: 1.0619945668508015 tokens/s
2024-06-05 16:27:36,594 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:36,594 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[653/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.7433 tokens/s, remaining time: 0:23:22
pred is:
 ['']
 label is:
 ['recreational']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:36,675 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:36,675 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 211, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:36,675 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:36,675 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:36,676 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:37,616 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:37,618 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418971538543701 s; generated tokens: 1 tokens; generate speed: 1.0616870386621993 tokens/s
2024-06-05 16:27:37,622 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:37,623 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[654/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.7422 tokens/s, remaining time: 0:23:21
pred is:
 ['']
 label is:
 ['Hyperbaric (high-pressure) medicine']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:37,704 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:37,704 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 170, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:37,705 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:37,705 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:37,705 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:38,645 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:38,648 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425630569458008 s; generated tokens: 1 tokens; generate speed: 1.0609369767157149 tokens/s
2024-06-05 16:27:38,653 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:38,653 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[655/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.7412 tokens/s, remaining time: 0:23:20
pred is:
 ['']
 label is:
 ['Oxygen therapy']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:38,734 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:38,734 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 173, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:38,734 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:38,734 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:38,735 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:39,674 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:39,676 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412386417388916 s; generated tokens: 1 tokens; generate speed: 1.0624298192353745 tokens/s
2024-06-05 16:27:39,681 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:39,681 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[656/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0504 tokens/s, avg speed: 1.7402 tokens/s, remaining time: 0:23:19
pred is:
 ['']
 label is:
 ['electronegativity']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:39,762 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:39,762 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:39,762 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:39,762 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:39,763 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:40,703 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:40,733 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:40,763 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:40,793 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:40,840 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:40,869 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:40,899 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:40,928 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:40,957 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:40,986 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:41,276 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5127182006835938 s; generated tokens: 20 tokens; generate speed: 13.221233135796243 tokens/s
2024-06-05 16:27:41,280 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:41,281 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[657/2067], cost time 1.5238s, every example cost time is 1.5238, generate speed: 13.1247 tokens/s, avg speed: 1.7668 tokens/s, remaining time: 0:23:19
pred is:
 ['A. The plane is flying at a high altitude.']
 label is:
 ['cabin depressurization']
The F1/Em of this example is:  {'F1': 9.090909090909092, 'Em': 0.0}
2024-06-05 16:27:41,368 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:41,368 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 212, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:41,369 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:41,369 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:41,369 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:42,310 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:42,312 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423284530639648 s; generated tokens: 1 tokens; generate speed: 1.0612011096009222 tokens/s
2024-06-05 16:27:42,316 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:42,317 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[658/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.7658 tokens/s, remaining time: 0:23:18
pred is:
 ['']
 label is:
 ['storage']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:42,397 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:42,397 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 301, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:42,398 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:42,398 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:42,398 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:43,340 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:43,342 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436030387878418 s; generated tokens: 1 tokens; generate speed: 1.0597676765481872 tokens/s
2024-06-05 16:27:43,347 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:43,347 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[659/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0477 tokens/s, avg speed: 1.7647 tokens/s, remaining time: 0:23:17
pred is:
 ['']
 label is:
 ['organic solvents']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:43,428 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:43,428 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 204, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:43,429 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:43,429 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:43,429 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:44,370 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:44,372 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942763090133667 s; generated tokens: 1 tokens; generate speed: 1.0607118696789644 tokens/s
2024-06-05 16:27:44,377 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:44,377 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[660/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.7637 tokens/s, remaining time: 0:23:16
pred is:
 ['']
 label is:
 ['biomolecules']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.7233507088834554, Em score: 1.9696969696969697, current_count: 660
2024-06-05 16:27:44,550 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:44,551 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:44,551 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:44,551 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:44,551 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:45,492 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:45,494 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421250820159912 s; generated tokens: 1 tokens; generate speed: 1.0614301848966445 tokens/s
2024-06-05 16:27:45,498 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:45,499 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[661/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.7626 tokens/s, remaining time: 0:23:15
pred is:
 ['']
 label is:
 ['Oxygen toxicity']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:45,585 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:45,585 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 165, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:45,586 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:45,586 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:45,586 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:46,527 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:46,528 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422125816345215 s; generated tokens: 1 tokens; generate speed: 1.0613316140028939 tokens/s
2024-06-05 16:27:46,533 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:46,533 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[662/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.7616 tokens/s, remaining time: 0:23:13
pred is:
 ['']
 label is:
 ['low total pressures']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:46,615 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:46,615 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 195, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:46,615 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:46,616 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:46,616 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:47,557 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:47,558 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424037933349609 s; generated tokens: 1 tokens; generate speed: 1.0611162721037217 tokens/s
2024-06-05 16:27:47,563 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:47,563 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[663/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.7606 tokens/s, remaining time: 0:23:12
pred is:
 ['']
 label is:
 ['at elevated partial pressures']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:47,645 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:47,645 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 185, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:47,646 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:47,646 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:47,646 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:48,586 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:48,588 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418556690216064 s; generated tokens: 1 tokens; generate speed: 1.0617338015693991 tokens/s
2024-06-05 16:27:48,593 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:48,593 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[664/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7595 tokens/s, remaining time: 0:23:11
pred is:
 ['']
 label is:
 ['October 1973']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:48,673 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:48,674 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 204, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:48,674 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:48,674 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:48,674 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:49,615 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:49,618 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429152011871338 s; generated tokens: 1 tokens; generate speed: 1.0605407556702833 tokens/s
2024-06-05 16:27:49,622 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:49,622 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[665/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.7585 tokens/s, remaining time: 0:23:10
pred is:
 ['']
 label is:
 ['to avoid being targeted by the boycott']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:49,703 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:49,703 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 248, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:49,704 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:49,704 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:49,704 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:50,645 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:50,647 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426641464233398 s; generated tokens: 1 tokens; generate speed: 1.0608232038888974 tokens/s
2024-06-05 16:27:50,652 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:50,652 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[666/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.7575 tokens/s, remaining time: 0:23:09
pred is:
 ['']
 label is:
 ['On August 15, 1971']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:50,733 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:50,733 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 181, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:50,734 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:50,734 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:50,734 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:51,675 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:51,677 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423692226409912 s; generated tokens: 1 tokens; generate speed: 1.0611551990179586 tokens/s
2024-06-05 16:27:51,681 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:51,682 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[667/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.7565 tokens/s, remaining time: 0:23:08
pred is:
 ['']
 label is:
 ['risen by less than two percent per year']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:51,763 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:51,763 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 238, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:51,763 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:51,764 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:51,764 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:52,705 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:52,707 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430022239685059 s; generated tokens: 1 tokens; generate speed: 1.0604428861170934 tokens/s
2024-06-05 16:27:52,712 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:52,712 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[668/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.7554 tokens/s, remaining time: 0:23:07
pred is:
 ['']
 label is:
 ['On October 6, 1973']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:52,793 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:52,793 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 268, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:52,793 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:52,794 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:52,794 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:53,735 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:53,737 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94329833984375 s; generated tokens: 1 tokens; generate speed: 1.060109996764801 tokens/s
2024-06-05 16:27:53,742 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:53,742 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[669/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.7544 tokens/s, remaining time: 0:23:06
pred is:
 ['']
 label is:
 ['In response to American aid to Israel']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:53,824 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:53,824 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 168, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:53,825 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:53,825 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:53,825 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:54,766 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:54,768 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943058967590332 s; generated tokens: 1 tokens; generate speed: 1.0603790795342962 tokens/s
2024-06-05 16:27:54,773 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:54,773 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[670/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0482 tokens/s, avg speed: 1.7534 tokens/s, remaining time: 0:23:05
pred is:
 ['']
 label is:
 ['over 100 billion dollars']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.6827036833777322, Em score: 1.9402985074626866, current_count: 670
2024-06-05 16:27:54,960 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:54,960 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:54,961 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:54,961 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:54,961 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:55,901 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:55,903 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941737174987793 s; generated tokens: 1 tokens; generate speed: 1.0618673941728618 tokens/s
2024-06-05 16:27:55,908 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:55,908 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[671/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7524 tokens/s, remaining time: 0:23:04
pred is:
 ['']
 label is:
 ['distribution and price disruptions']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:55,989 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:55,989 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 147, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:55,990 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:55,990 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:55,990 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:56,930 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:56,932 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416189193725586 s; generated tokens: 1 tokens; generate speed: 1.0620007514997079 tokens/s
2024-06-05 16:27:56,937 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:56,937 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[672/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7514 tokens/s, remaining time: 0:23:03
pred is:
 ['']
 label is:
 ['The embargo']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:57,018 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:57,019 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 171, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:57,019 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:57,019 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:57,019 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:57,960 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:57,961 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418275356292725 s; generated tokens: 1 tokens; generate speed: 1.0617655166896987 tokens/s
2024-06-05 16:27:57,966 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:57,966 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[673/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.7504 tokens/s, remaining time: 0:23:02
pred is:
 ['']
 label is:
 ['Netherlands']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:58,047 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:58,047 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 157, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:58,048 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:58,048 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:58,048 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:27:58,988 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:58,990 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418587684631348 s; generated tokens: 1 tokens; generate speed: 1.0617303076465874 tokens/s
2024-06-05 16:27:58,995 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:27:58,995 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[674/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0492 tokens/s, avg speed: 1.7494 tokens/s, remaining time: 0:23:01
pred is:
 ['']
 label is:
 ['UK']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:27:59,077 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:27:59,077 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:27:59,078 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:27:59,078 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:27:59,078 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:00,018 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:00,021 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424550533294678 s; generated tokens: 1 tokens; generate speed: 1.0610585581426295 tokens/s
2024-06-05 16:28:00,025 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:00,026 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[675/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.7484 tokens/s, remaining time: 0:23:00
pred is:
 ['']
 label is:
 ['Price controls']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:00,107 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:00,107 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 154, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:00,108 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:00,108 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:00,108 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:01,048 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:01,050 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416146278381348 s; generated tokens: 1 tokens; generate speed: 1.0620055917099684 tokens/s
2024-06-05 16:28:01,055 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:01,055 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[676/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7474 tokens/s, remaining time: 0:22:58
pred is:
 ['']
 label is:
 ['William E. Simon']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:01,136 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:01,136 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 167, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:01,136 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:01,136 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:01,137 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:02,077 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:02,079 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94195556640625 s; generated tokens: 1 tokens; generate speed: 1.061621201321843 tokens/s
2024-06-05 16:28:02,083 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:02,084 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[677/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.7464 tokens/s, remaining time: 0:22:57
pred is:
 ['']
 label is:
 ['55 mph']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:02,172 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:02,172 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 146, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:02,173 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:02,173 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:02,173 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:03,113 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:03,115 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414794445037842 s; generated tokens: 1 tokens; generate speed: 1.0621580809202473 tokens/s
2024-06-05 16:28:03,119 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:03,120 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[678/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7454 tokens/s, remaining time: 0:22:56
pred is:
 ['']
 label is:
 ['energy crisis']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:03,202 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:03,202 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 306, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:03,203 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:03,203 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:03,203 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:04,146 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:04,148 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9444215297698975 s; generated tokens: 1 tokens; generate speed: 1.058849219843224 tokens/s
2024-06-05 16:28:04,152 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:04,152 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[679/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0462 tokens/s, avg speed: 1.7444 tokens/s, remaining time: 0:22:55
pred is:
 ['']
 label is:
 ['U.S']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:04,241 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:04,241 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 196, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:04,241 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:04,242 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:04,242 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:05,183 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:05,185 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432582855224609 s; generated tokens: 1 tokens; generate speed: 1.06015501305256 tokens/s
2024-06-05 16:28:05,190 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:05,190 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[680/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0476 tokens/s, avg speed: 1.7434 tokens/s, remaining time: 0:22:54
pred is:
 ['']
 label is:
 ['Japan']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.6432521586221776, Em score: 1.911764705882353, current_count: 680
2024-06-05 16:28:05,368 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:05,368 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 387, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:05,369 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:05,369 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:05,369 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:06,313 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:06,315 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9455657005310059 s; generated tokens: 1 tokens; generate speed: 1.0575679716792024 tokens/s
2024-06-05 16:28:06,320 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:06,320 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[681/2067], cost time 0.9571s, every example cost time is 0.9571, generate speed: 1.0449 tokens/s, avg speed: 1.7424 tokens/s, remaining time: 0:22:53
pred is:
 ['']
 label is:
 ["USSR's invasion"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:06,408 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:06,409 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 159, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:06,409 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:06,409 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:06,410 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:07,350 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:07,352 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420030117034912 s; generated tokens: 1 tokens; generate speed: 1.0615677312874283 tokens/s
2024-06-05 16:28:07,356 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:07,357 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[682/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0489 tokens/s, avg speed: 1.7415 tokens/s, remaining time: 0:22:52
pred is:
 ['']
 label is:
 ['large cars']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:07,439 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:07,439 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 197, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:07,439 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:07,440 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:07,440 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:08,380 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:08,382 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421398639678955 s; generated tokens: 1 tokens; generate speed: 1.0614135313077848 tokens/s
2024-06-05 16:28:08,387 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:08,387 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[683/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.7405 tokens/s, remaining time: 0:22:51
pred is:
 ['']
 label is:
 ['A decade after the 1973']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:08,473 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:08,474 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 157, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:08,474 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:08,474 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:08,475 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:09,414 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:09,416 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415066242218018 s; generated tokens: 1 tokens; generate speed: 1.06212741819692 tokens/s
2024-06-05 16:28:09,421 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:09,421 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[684/2067], cost time 0.9576s, every example cost time is 0.9576, generate speed: 1.0443 tokens/s, avg speed: 1.7395 tokens/s, remaining time: 0:22:50
pred is:
 ['']
 label is:
 ['Toyota Hilux']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:09,502 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:09,503 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 303, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:09,503 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:09,503 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:09,503 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:10,446 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:10,448 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9446115493774414 s; generated tokens: 1 tokens; generate speed: 1.0586362199986472 tokens/s
2024-06-05 16:28:10,453 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:10,453 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[685/2067], cost time 0.9555s, every example cost time is 0.9555, generate speed: 1.0466 tokens/s, avg speed: 1.7385 tokens/s, remaining time: 0:22:49
pred is:
 ['']
 label is:
 ['An increase in imported cars']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:10,534 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:10,534 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 198, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:10,534 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:10,534 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:10,535 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:11,475 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:11,477 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420430660247803 s; generated tokens: 1 tokens; generate speed: 1.0615225949486424 tokens/s
2024-06-05 16:28:11,481 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:11,482 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[686/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7376 tokens/s, remaining time: 0:22:48
pred is:
 ['']
 label is:
 ['1979']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:11,562 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:11,562 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 181, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:11,563 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:11,563 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:11,563 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:12,503 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:12,505 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418885707855225 s; generated tokens: 1 tokens; generate speed: 1.0616967134084803 tokens/s
2024-06-05 16:28:12,510 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:12,510 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[687/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7366 tokens/s, remaining time: 0:22:47
pred is:
 ['']
 label is:
 ['1981']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:12,591 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:12,591 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:12,591 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:12,591 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:12,592 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:13,532 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:13,534 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424514770507812 s; generated tokens: 1 tokens; generate speed: 1.0610625844943293 tokens/s
2024-06-05 16:28:13,539 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:13,539 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[688/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.7356 tokens/s, remaining time: 0:22:46
pred is:
 ['']
 label is:
 ['Project Mercury']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:13,620 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:13,620 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 168, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:13,621 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:13,621 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:13,621 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:14,561 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:14,563 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414746761322021 s; generated tokens: 1 tokens; generate speed: 1.0621634605279384 tokens/s
2024-06-05 16:28:14,567 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:14,567 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[689/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.7347 tokens/s, remaining time: 0:22:45
pred is:
 ['']
 label is:
 ['1961 to 1972']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:14,648 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:14,648 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 189, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:14,649 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:14,649 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:14,649 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:15,590 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:15,592 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94307541847229 s; generated tokens: 1 tokens; generate speed: 1.0603605824229025 tokens/s
2024-06-05 16:28:15,597 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:15,597 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[690/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.7337 tokens/s, remaining time: 0:22:44
pred is:
 ['']
 label is:
 ['1967']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.604944156323305, Em score: 1.8840579710144927, current_count: 690
2024-06-05 16:28:15,775 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:15,775 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:15,776 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:15,776 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:15,776 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:16,716 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:16,718 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416227340698242 s; generated tokens: 1 tokens; generate speed: 1.0619964491276257 tokens/s
2024-06-05 16:28:16,722 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:16,723 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[691/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.7328 tokens/s, remaining time: 0:22:42
pred is:
 ['']
 label is:
 ['Apollo 8']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:16,803 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:16,804 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 195, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:16,804 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:16,804 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:16,804 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:17,745 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:17,747 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426522254943848 s; generated tokens: 1 tokens; generate speed: 1.0608366192267127 tokens/s
2024-06-05 16:28:17,752 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:17,752 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[692/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.7318 tokens/s, remaining time: 0:22:41
pred is:
 ['']
 label is:
 ['one']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:17,833 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:17,834 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 186, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:17,834 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:17,834 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:17,835 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:18,775 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:18,777 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422004222869873 s; generated tokens: 1 tokens; generate speed: 1.061345310770204 tokens/s
2024-06-05 16:28:18,782 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:18,782 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[693/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.7309 tokens/s, remaining time: 0:22:40
pred is:
 ['']
 label is:
 ['1960']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:18,862 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:18,862 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 257, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:18,863 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:18,863 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:18,863 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:19,805 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:19,806 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433484077453613 s; generated tokens: 1 tokens; generate speed: 1.0600537317808572 tokens/s
2024-06-05 16:28:19,811 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:19,811 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[694/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.7299 tokens/s, remaining time: 0:22:39
pred is:
 ['']
 label is:
 ['John F. Kennedy']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:19,892 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:19,892 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 156, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:19,893 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:19,893 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:19,893 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:20,833 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:20,835 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942002534866333 s; generated tokens: 1 tokens; generate speed: 1.0615682686479146 tokens/s
2024-06-05 16:28:20,840 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:20,840 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[695/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.7290 tokens/s, remaining time: 0:22:38
pred is:
 ['']
 label is:
 ['Yuri Gagarin']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:20,929 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:20,929 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 157, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:20,930 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:20,930 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:20,930 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:21,870 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:21,872 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417695999145508 s; generated tokens: 1 tokens; generate speed: 1.0618308343046245 tokens/s
2024-06-05 16:28:21,877 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:21,877 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[696/2067], cost time 0.9600s, every example cost time is 0.9600, generate speed: 1.0417 tokens/s, avg speed: 1.7280 tokens/s, remaining time: 0:22:37
pred is:
 ['']
 label is:
 ['April 20']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:21,958 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:21,958 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 187, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:21,958 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:21,958 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:21,959 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:22,899 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:22,901 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418771266937256 s; generated tokens: 1 tokens; generate speed: 1.0617096133444746 tokens/s
2024-06-05 16:28:22,905 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:22,906 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[697/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.7271 tokens/s, remaining time: 0:22:36
pred is:
 ['']
 label is:
 ['Robert R. Gilruth']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:22,986 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:22,986 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 244, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:22,987 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:22,987 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:22,987 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:23,929 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:23,934 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9463844299316406 s; generated tokens: 1 tokens; generate speed: 1.0566530559597564 tokens/s
2024-06-05 16:28:23,939 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:23,939 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[698/2067], cost time 0.9579s, every example cost time is 0.9579, generate speed: 1.0440 tokens/s, avg speed: 1.7261 tokens/s, remaining time: 0:22:35
pred is:
 ['']
 label is:
 ['Merritt Island']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:24,021 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:24,021 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 206, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:24,022 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:24,022 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:24,022 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:24,963 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:24,965 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421522617340088 s; generated tokens: 1 tokens; generate speed: 1.061399564184587 tokens/s
2024-06-05 16:28:24,969 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:24,970 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[699/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.7252 tokens/s, remaining time: 0:22:34
pred is:
 ['']
 label is:
 ['three']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:25,053 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:25,053 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 223, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:25,054 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:25,054 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:25,054 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:25,996 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:25,998 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434165954589844 s; generated tokens: 1 tokens; generate speed: 1.0599771138364247 tokens/s
2024-06-05 16:28:26,002 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:26,003 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[700/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.7243 tokens/s, remaining time: 0:22:33
pred is:
 ['']
 label is:
 ['Dr. George E. Mueller']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.5677306683758294, Em score: 1.8571428571428572, current_count: 700
2024-06-05 16:28:26,182 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:26,183 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 190, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:26,183 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:26,183 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:26,183 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:27,124 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:27,126 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422552585601807 s; generated tokens: 1 tokens; generate speed: 1.06128354383297 tokens/s
2024-06-05 16:28:27,131 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:27,131 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[701/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.7233 tokens/s, remaining time: 0:22:32
pred is:
 ['']
 label is:
 ['Air Force missile projects']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:27,212 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:27,212 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 220, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:27,213 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:27,213 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:27,213 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:28,154 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:28,156 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428458213806152 s; generated tokens: 1 tokens; generate speed: 1.0606187961205509 tokens/s
2024-06-05 16:28:28,161 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:28,161 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[702/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.7224 tokens/s, remaining time: 0:22:31
pred is:
 ['']
 label is:
 ['a rendezvous —let alone a docking']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:28,242 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:28,242 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 255, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:28,242 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:28,242 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:28,243 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:29,184 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:29,186 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433987140655518 s; generated tokens: 1 tokens; generate speed: 1.0599972048833166 tokens/s
2024-06-05 16:28:29,191 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:29,191 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[703/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.7215 tokens/s, remaining time: 0:22:30
pred is:
 ['']
 label is:
 ['Nicholas E. Golovin']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:29,272 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:29,272 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 188, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:29,272 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:29,272 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:29,273 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:30,213 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:30,215 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417662620544434 s; generated tokens: 1 tokens; generate speed: 1.0618345977042338 tokens/s
2024-06-05 16:28:30,219 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:30,219 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[704/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.7206 tokens/s, remaining time: 0:22:29
pred is:
 ['']
 label is:
 ['Jerome Wiesner']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:30,300 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:30,301 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:30,301 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:30,301 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:30,301 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:31,243 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:31,245 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431321620941162 s; generated tokens: 1 tokens; generate speed: 1.0602967857438086 tokens/s
2024-06-05 16:28:31,249 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:31,250 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[705/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0477 tokens/s, avg speed: 1.7197 tokens/s, remaining time: 0:22:28
pred is:
 ['']
 label is:
 ['Wiesner']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:31,330 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:31,330 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 187, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:31,331 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:31,331 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:31,331 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:32,271 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:32,273 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418652057647705 s; generated tokens: 1 tokens; generate speed: 1.0617230511111466 tokens/s
2024-06-05 16:28:32,278 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:32,278 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[706/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.7187 tokens/s, remaining time: 0:22:27
pred is:
 ['']
 label is:
 ['spacecraft to be used as a "lifeboat"']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:32,359 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:32,359 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 220, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:32,359 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:32,360 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:32,360 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:33,301 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:33,303 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427998065948486 s; generated tokens: 1 tokens; generate speed: 1.0606705612422045 tokens/s
2024-06-05 16:28:33,307 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:33,308 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[707/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.7178 tokens/s, remaining time: 0:22:25
pred is:
 ['']
 label is:
 ['cone-shaped']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:33,388 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:33,389 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 200, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:33,389 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:33,389 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:33,390 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:34,330 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:34,332 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423103332519531 s; generated tokens: 1 tokens; generate speed: 1.0612215155796472 tokens/s
2024-06-05 16:28:34,337 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:34,337 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[708/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.7169 tokens/s, remaining time: 0:22:24
pred is:
 ['']
 label is:
 ['three']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:34,418 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:34,418 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 215, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:34,418 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:34,419 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:34,419 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:35,359 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:35,361 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422318935394287 s; generated tokens: 1 tokens; generate speed: 1.0613098610402258 tokens/s
2024-06-05 16:28:35,366 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:35,366 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[709/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7160 tokens/s, remaining time: 0:22:23
pred is:
 ['']
 label is:
 ['Service Module (SM)']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:35,447 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:35,447 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 187, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:35,447 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:35,448 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:35,448 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:36,389 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:36,391 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432415962219238 s; generated tokens: 1 tokens; generate speed: 1.060173770967499 tokens/s
2024-06-05 16:28:36,396 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:36,396 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[710/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.7151 tokens/s, remaining time: 0:22:22
pred is:
 ['']
 label is:
 ['North American Aviation']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.5315654476944798, Em score: 1.8309859154929577, current_count: 710
2024-06-05 16:28:36,578 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:36,578 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 236, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:36,578 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:36,578 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:36,579 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:37,520 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:37,521 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426062107086182 s; generated tokens: 1 tokens; generate speed: 1.0608884056134482 tokens/s
2024-06-05 16:28:37,526 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:37,526 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[711/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0485 tokens/s, avg speed: 1.7142 tokens/s, remaining time: 0:22:21
pred is:
 ['']
 label is:
 ['two']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:37,607 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:37,608 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 214, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:37,608 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:37,608 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:37,608 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:38,549 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:38,551 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422605037689209 s; generated tokens: 1 tokens; generate speed: 1.0612776360678693 tokens/s
2024-06-05 16:28:38,555 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:38,556 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[712/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.7133 tokens/s, remaining time: 0:22:20
pred is:
 ['']
 label is:
 ['Wernher von Braun']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:38,637 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:38,638 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 169, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:38,638 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:38,638 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:38,638 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:39,578 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:39,580 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416937828063965 s; generated tokens: 1 tokens; generate speed: 1.0619163238179632 tokens/s
2024-06-05 16:28:39,585 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:39,585 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[713/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.7124 tokens/s, remaining time: 0:22:19
pred is:
 ['']
 label is:
 ['dummy upper stages filled with water']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:39,667 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:39,667 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 230, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:39,668 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:39,668 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:39,668 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:40,610 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:40,611 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430892467498779 s; generated tokens: 1 tokens; generate speed: 1.0603450346255678 tokens/s
2024-06-05 16:28:40,616 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:40,616 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[714/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.7115 tokens/s, remaining time: 0:22:18
pred is:
 ['']
 label is:
 ['Saturn IB']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:40,697 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:40,697 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 250, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:40,697 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:40,698 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:40,698 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:41,639 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:41,642 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436507225036621 s; generated tokens: 1 tokens; generate speed: 1.059714125314114 tokens/s
2024-06-05 16:28:41,646 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:41,646 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[715/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0477 tokens/s, avg speed: 1.7106 tokens/s, remaining time: 0:22:17
pred is:
 ['']
 label is:
 ['three-stage Saturn V']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:41,727 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:41,727 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 173, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:41,728 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:41,728 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:41,728 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:42,668 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:42,670 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417855739593506 s; generated tokens: 1 tokens; generate speed: 1.0618128241186693 tokens/s
2024-06-05 16:28:42,675 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:42,675 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[716/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.7097 tokens/s, remaining time: 0:22:16
pred is:
 ['']
 label is:
 ['Mercury and Gemini']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:42,758 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:42,758 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 223, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:42,758 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:42,758 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:42,759 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:43,700 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:43,701 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426088333129883 s; generated tokens: 1 tokens; generate speed: 1.0608854539218553 tokens/s
2024-06-05 16:28:43,706 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:43,706 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[717/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.7088 tokens/s, remaining time: 0:22:15
pred is:
 ['']
 label is:
 ['32']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:43,787 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:43,787 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 195, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:43,788 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:43,788 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:43,788 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:44,728 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:44,730 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419867992401123 s; generated tokens: 1 tokens; generate speed: 1.0615860018491619 tokens/s
2024-06-05 16:28:44,735 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:44,735 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[718/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.7080 tokens/s, remaining time: 0:22:14
pred is:
 ['']
 label is:
 ['1966']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:44,816 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:44,816 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 190, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:44,816 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:44,816 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:44,817 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:45,757 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:45,759 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418351650238037 s; generated tokens: 1 tokens; generate speed: 1.0617569157918691 tokens/s
2024-06-05 16:28:45,763 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:45,764 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[719/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.7071 tokens/s, remaining time: 0:22:13
pred is:
 ['']
 label is:
 ['unmanned']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:45,848 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:45,849 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 226, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:45,849 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:45,849 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:45,849 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:46,791 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:46,793 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436352252960205 s; generated tokens: 1 tokens; generate speed: 1.0597315288715485 tokens/s
2024-06-05 16:28:46,798 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:46,798 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[720/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.7062 tokens/s, remaining time: 0:22:12
pred is:
 ['']
 label is:
 ['Deke Slayton']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.4964048164765007, Em score: 1.8055555555555556, current_count: 720
2024-06-05 16:28:46,980 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:46,980 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 172, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:46,980 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:46,981 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:46,981 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:47,922 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:47,927 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9456541538238525 s; generated tokens: 1 tokens; generate speed: 1.0574690503461486 tokens/s
2024-06-05 16:28:47,932 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:47,932 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[721/2067], cost time 0.9574s, every example cost time is 0.9574, generate speed: 1.0445 tokens/s, avg speed: 1.7053 tokens/s, remaining time: 0:22:11
pred is:
 ['']
 label is:
 ['canceled']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:48,014 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:48,014 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 186, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:48,014 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:48,015 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:48,015 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:48,956 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:48,958 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428455829620361 s; generated tokens: 1 tokens; generate speed: 1.0606190643205942 tokens/s
2024-06-05 16:28:48,962 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:48,963 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[722/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.7044 tokens/s, remaining time: 0:22:10
pred is:
 ['']
 label is:
 ['Samuel Phillips']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:49,044 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:49,044 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 168, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:49,045 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:49,045 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:49,045 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:49,986 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:49,988 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425716400146484 s; generated tokens: 1 tokens; generate speed: 1.0609273158106678 tokens/s
2024-06-05 16:28:49,992 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:49,993 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[723/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.7035 tokens/s, remaining time: 0:22:09
pred is:
 ['']
 label is:
 ['altitude chamber']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:50,074 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:50,075 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 179, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:50,075 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:50,075 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:50,076 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:51,016 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:51,018 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421274662017822 s; generated tokens: 1 tokens; generate speed: 1.0614274987985786 tokens/s
2024-06-05 16:28:51,023 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:51,023 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[724/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.7027 tokens/s, remaining time: 0:22:08
pred is:
 ['']
 label is:
 ['strange odor in their spacesuits']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:51,103 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:51,104 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 142, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:51,104 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:51,104 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:51,104 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:52,044 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:52,047 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420228004455566 s; generated tokens: 1 tokens; generate speed: 1.0615454313069932 tokens/s
2024-06-05 16:28:52,051 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:52,051 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[725/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.7018 tokens/s, remaining time: 0:22:06
pred is:
 ['']
 label is:
 ['both houses of Congress']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:52,132 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:52,132 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 191, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:52,133 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:52,133 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:52,133 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:53,073 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:53,075 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942063570022583 s; generated tokens: 1 tokens; generate speed: 1.0614994909271656 tokens/s
2024-06-05 16:28:53,080 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:53,080 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[726/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.7009 tokens/s, remaining time: 0:22:05
pred is:
 ['']
 label is:
 ['nitrogen/oxygen mixture']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:53,161 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:53,161 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 250, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:53,162 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:53,162 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:53,162 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:54,106 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:54,108 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9458258152008057 s; generated tokens: 1 tokens; generate speed: 1.0572771264312475 tokens/s
2024-06-05 16:28:54,113 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:54,113 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[727/2067], cost time 0.9568s, every example cost time is 0.9568, generate speed: 1.0451 tokens/s, avg speed: 1.7001 tokens/s, remaining time: 0:22:04
pred is:
 ['']
 label is:
 ['sequence']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:54,194 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:54,194 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 354, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:54,194 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:54,195 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:54,195 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:55,138 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:55,140 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.944756031036377 s; generated tokens: 1 tokens; generate speed: 1.0584743226280562 tokens/s
2024-06-05 16:28:55,144 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:55,145 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[728/2067], cost time 0.9557s, every example cost time is 0.9557, generate speed: 1.0463 tokens/s, avg speed: 1.6992 tokens/s, remaining time: 0:22:03
pred is:
 ['']
 label is:
 ['AS-501']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:55,225 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:55,226 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 183, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:55,226 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:55,226 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:55,226 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:56,166 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:56,168 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418714046478271 s; generated tokens: 1 tokens; generate speed: 1.0617160634300258 tokens/s
2024-06-05 16:28:56,173 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:56,173 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[729/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.6983 tokens/s, remaining time: 0:22:02
pred is:
 ['']
 label is:
 ['Apollo 5']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:56,254 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:56,254 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 278, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:56,254 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:56,255 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:56,255 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:57,197 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:57,200 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445912837982178 s; generated tokens: 1 tokens; generate speed: 1.058658932336304 tokens/s
2024-06-05 16:28:57,204 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:57,204 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[730/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0463 tokens/s, avg speed: 1.6975 tokens/s, remaining time: 0:22:01
pred is:
 ['']
 label is:
 ['two Saturn IBs']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.462207490223398, Em score: 1.7808219178082192, current_count: 730
2024-06-05 16:28:57,413 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:57,413 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 185, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:57,413 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:57,413 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:57,414 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:58,354 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:58,356 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417517185211182 s; generated tokens: 1 tokens; generate speed: 1.0618509956853088 tokens/s
2024-06-05 16:28:58,360 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:58,360 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[731/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.6966 tokens/s, remaining time: 0:22:00
pred is:
 ['']
 label is:
 ['Gemini']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:58,441 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:58,442 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 182, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:58,442 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:58,442 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:58,442 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:28:59,383 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:59,385 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420769214630127 s; generated tokens: 1 tokens; generate speed: 1.0614844469887181 tokens/s
2024-06-05 16:28:59,389 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:28:59,389 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[732/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.6958 tokens/s, remaining time: 0:21:59
pred is:
 ['']
 label is:
 ['Apollo 12']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:28:59,471 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:28:59,471 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 216, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:28:59,471 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:28:59,472 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:28:59,472 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:00,413 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:00,414 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424972534179688 s; generated tokens: 1 tokens; generate speed: 1.0610110495001417 tokens/s
2024-06-05 16:29:00,419 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:00,419 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[733/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0485 tokens/s, avg speed: 1.6949 tokens/s, remaining time: 0:21:58
pred is:
 ['']
 label is:
 ['Lunar Roving Vehicle (LRV)']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:00,500 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:00,501 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:00,501 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:00,501 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:00,501 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:01,443 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:01,445 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433014392852783 s; generated tokens: 1 tokens; generate speed: 1.0601065135209389 tokens/s
2024-06-05 16:29:01,449 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:01,450 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[734/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.6941 tokens/s, remaining time: 0:21:57
pred is:
 ['']
 label is:
 ['liquid oxygen tank exploded']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:01,531 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:01,531 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 231, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:01,531 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:01,532 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:01,532 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:02,473 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:02,476 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434688091278076 s; generated tokens: 1 tokens; generate speed: 1.059918452338083 tokens/s
2024-06-05 16:29:02,480 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:02,480 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[735/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0474 tokens/s, avg speed: 1.6932 tokens/s, remaining time: 0:21:56
pred is:
 ['']
 label is:
 ['Apollo 20']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:02,561 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:02,562 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 258, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:02,562 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:02,562 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:02,562 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:03,504 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:03,506 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429326057434082 s; generated tokens: 1 tokens; generate speed: 1.060521180314472 tokens/s
2024-06-05 16:29:03,510 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:03,510 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[736/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0484 tokens/s, avg speed: 1.6924 tokens/s, remaining time: 0:21:55
pred is:
 ['']
 label is:
 ['extremely old']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:03,591 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:03,592 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 159, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:03,592 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:03,592 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:03,592 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:04,533 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:04,534 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418790340423584 s; generated tokens: 1 tokens; generate speed: 1.061707463333373 tokens/s
2024-06-05 16:29:04,539 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:04,539 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[737/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.6915 tokens/s, remaining time: 0:21:54
pred is:
 ['']
 label is:
 ['micrometeoroid impact craters']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:04,621 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:04,621 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 209, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:04,621 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:04,622 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:04,622 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:05,562 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:05,564 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423573017120361 s; generated tokens: 1 tokens; generate speed: 1.0611686227540669 tokens/s
2024-06-05 16:29:05,569 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:05,569 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[738/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.6907 tokens/s, remaining time: 0:21:53
pred is:
 ['']
 label is:
 ['$170 billion']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:05,649 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:05,650 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 228, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:05,650 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:05,650 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:05,650 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:06,591 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:06,593 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426627159118652 s; generated tokens: 1 tokens; generate speed: 1.0608248137115202 tokens/s
2024-06-05 16:29:06,598 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:06,598 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[739/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.6898 tokens/s, remaining time: 0:21:52
pred is:
 ['']
 label is:
 ['Apollo X']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:06,679 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:06,679 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 171, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:06,679 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:06,679 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:06,680 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:07,620 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:07,622 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425251483917236 s; generated tokens: 1 tokens; generate speed: 1.0609796478177251 tokens/s
2024-06-05 16:29:07,627 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:07,627 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[740/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.6890 tokens/s, remaining time: 0:21:51
pred is:
 ['']
 label is:
 ['1973']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.42893441603119, Em score: 1.7567567567567568, current_count: 740
2024-06-05 16:29:07,812 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:07,812 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 223, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:07,813 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:07,813 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:07,813 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:08,754 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:08,756 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426476955413818 s; generated tokens: 1 tokens; generate speed: 1.0608417171440487 tokens/s
2024-06-05 16:29:08,761 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:08,761 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[741/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.6882 tokens/s, remaining time: 0:21:50
pred is:
 ['']
 label is:
 ['Lunar Reconnaissance Orbiter']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:08,866 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:08,866 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:08,866 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:08,867 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:08,867 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:09,807 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:09,809 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422333240509033 s; generated tokens: 1 tokens; generate speed: 1.0613082497451298 tokens/s
2024-06-05 16:29:09,814 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:09,814 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[742/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.6873 tokens/s, remaining time: 0:21:49
pred is:
 ['']
 label is:
 ['Apollo 8']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:09,895 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:09,895 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 167, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:09,895 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:09,895 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:09,896 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:10,836 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:10,838 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420278072357178 s; generated tokens: 1 tokens; generate speed: 1.0615397892917786 tokens/s
2024-06-05 16:29:10,842 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:10,843 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[743/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0493 tokens/s, avg speed: 1.6865 tokens/s, remaining time: 0:21:48
pred is:
 ['']
 label is:
 ['special Apollo TV camera']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:10,924 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:10,924 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 147, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:10,925 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:10,925 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:10,925 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:11,865 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:11,867 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415459632873535 s; generated tokens: 1 tokens; generate speed: 1.0620830410748696 tokens/s
2024-06-05 16:29:11,871 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:11,872 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[744/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.6857 tokens/s, remaining time: 0:21:47
pred is:
 ['']
 label is:
 ['Nafzger']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:11,953 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:11,954 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 170, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:11,954 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:11,954 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:11,955 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:12,895 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:12,897 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427554607391357 s; generated tokens: 1 tokens; generate speed: 1.060720453653998 tokens/s
2024-06-05 16:29:12,902 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:12,902 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[745/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0483 tokens/s, avg speed: 1.6849 tokens/s, remaining time: 0:21:45
pred is:
 ['']
 label is:
 ['primary law, secondary law and supplementary law.']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:12,984 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:12,984 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 176, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:12,984 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:12,984 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:12,985 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:13,925 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:13,927 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941866397857666 s; generated tokens: 1 tokens; generate speed: 1.0617217073191723 tokens/s
2024-06-05 16:29:13,931 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:13,931 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[746/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.6840 tokens/s, remaining time: 0:21:44
pred is:
 ['']
 label is:
 ['courts of member states and the Court of Justice of the European Union']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:14,013 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:14,013 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 331, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:14,013 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:14,014 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:14,014 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:14,957 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:14,959 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94527268409729 s; generated tokens: 1 tokens; generate speed: 1.0578957975020435 tokens/s
2024-06-05 16:29:14,964 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:14,965 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[747/2067], cost time 0.9566s, every example cost time is 0.9566, generate speed: 1.0454 tokens/s, avg speed: 1.6832 tokens/s, remaining time: 0:21:43
pred is:
 ['']
 label is:
 ['Treaty on European Union (TEU) and the Treaty on the Functioning of the European Union (TFEU)']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:15,047 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:15,047 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 411, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:15,047 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:15,048 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:15,048 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:15,992 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:15,994 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9457848072052002 s; generated tokens: 1 tokens; generate speed: 1.0573229685883896 tokens/s
2024-06-05 16:29:15,998 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:15,999 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[748/2067], cost time 0.9569s, every example cost time is 0.9569, generate speed: 1.0451 tokens/s, avg speed: 1.6824 tokens/s, remaining time: 0:21:42
pred is:
 ['']
 label is:
 ['Treaty on European Union (TEU)']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:16,080 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:16,080 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 332, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:16,080 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:16,081 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:16,081 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:17,024 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:17,026 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.944683313369751 s; generated tokens: 1 tokens; generate speed: 1.0585557994381531 tokens/s
2024-06-05 16:29:17,030 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:17,031 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[749/2067], cost time 0.9557s, every example cost time is 0.9557, generate speed: 1.0464 tokens/s, avg speed: 1.6816 tokens/s, remaining time: 0:21:41
pred is:
 ['']
 label is:
 ['with common rules for coal and steel, and then atomic energy']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:17,112 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:17,113 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 163, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:17,113 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:17,113 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:17,113 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:18,054 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:18,057 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431209564208984 s; generated tokens: 1 tokens; generate speed: 1.0603093836393531 tokens/s
2024-06-05 16:29:18,061 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:18,062 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[750/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.6808 tokens/s, remaining time: 0:21:40
pred is:
 ['']
 label is:
 ['Following the Nice Treaty']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.396548623817441, Em score: 1.7333333333333334, current_count: 750
2024-06-05 16:29:18,251 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:18,251 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 403, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:18,251 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:18,252 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:18,252 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:19,196 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:19,197 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9455060958862305 s; generated tokens: 1 tokens; generate speed: 1.0576346406975747 tokens/s
2024-06-05 16:29:19,202 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:19,202 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[751/2067], cost time 0.9567s, every example cost time is 0.9567, generate speed: 1.0453 tokens/s, avg speed: 1.6799 tokens/s, remaining time: 0:21:39
pred is:
 ['']
 label is:
 ['The European Commission']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:19,283 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:19,283 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 326, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:19,284 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:19,284 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:19,284 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:20,227 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:20,229 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9444947242736816 s; generated tokens: 1 tokens; generate speed: 1.058767163330639 tokens/s
2024-06-05 16:29:20,234 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:20,234 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[752/2067], cost time 0.9555s, every example cost time is 0.9555, generate speed: 1.0465 tokens/s, avg speed: 1.6791 tokens/s, remaining time: 0:21:38
pred is:
 ['']
 label is:
 ['the Santer Commission']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:20,315 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:20,315 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 657, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:20,316 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:20,316 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:20,316 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:21,261 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:21,263 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9463322162628174 s; generated tokens: 1 tokens; generate speed: 1.0567113565562878 tokens/s
2024-06-05 16:29:21,267 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:21,268 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[753/2067], cost time 0.9577s, every example cost time is 0.9577, generate speed: 1.0442 tokens/s, avg speed: 1.6783 tokens/s, remaining time: 0:21:37
pred is:
 ['']
 label is:
 ['the European Parliament and the Council of the European Union']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:21,350 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:21,350 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 361, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:21,350 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:21,351 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:21,351 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:22,294 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:22,296 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.945293664932251 s; generated tokens: 1 tokens; generate speed: 1.0578723174577394 tokens/s
2024-06-05 16:29:22,301 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:22,301 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[754/2067], cost time 0.9565s, every example cost time is 0.9565, generate speed: 1.0454 tokens/s, avg speed: 1.6775 tokens/s, remaining time: 0:21:36
pred is:
 ['']
 label is:
 ['different ministers of the member states']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:22,383 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:22,383 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 400, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:22,384 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:22,384 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:22,384 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:23,328 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:23,330 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9459190368652344 s; generated tokens: 1 tokens; generate speed: 1.057172930268947 tokens/s
2024-06-05 16:29:23,335 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:23,335 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[755/2067], cost time 0.9575s, every example cost time is 0.9575, generate speed: 1.0444 tokens/s, avg speed: 1.6767 tokens/s, remaining time: 0:21:35
pred is:
 ['']
 label is:
 ['a majority']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:23,416 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:23,417 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 399, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:23,417 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:23,417 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:23,417 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:24,361 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:24,363 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9454951286315918 s; generated tokens: 1 tokens; generate speed: 1.0576469087125733 tokens/s
2024-06-05 16:29:24,368 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:24,368 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[756/2067], cost time 0.9566s, every example cost time is 0.9566, generate speed: 1.0454 tokens/s, avg speed: 1.6759 tokens/s, remaining time: 0:21:34
pred is:
 ['']
 label is:
 ['judicial branch']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:24,449 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:24,450 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 635, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:24,450 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:24,450 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:24,450 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:25,395 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:25,397 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9462411403656006 s; generated tokens: 1 tokens; generate speed: 1.0568130652336978 tokens/s
2024-06-05 16:29:25,402 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:25,402 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[757/2067], cost time 0.9572s, every example cost time is 0.9572, generate speed: 1.0447 tokens/s, avg speed: 1.6751 tokens/s, remaining time: 0:21:33
pred is:
 ['']
 label is:
 ['EU law']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:25,482 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:25,482 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 449, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:25,483 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:25,483 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:25,483 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:26,427 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:26,429 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9460752010345459 s; generated tokens: 1 tokens; generate speed: 1.0569984277216933 tokens/s
2024-06-05 16:29:26,434 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:26,434 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[758/2067], cost time 0.9571s, every example cost time is 0.9571, generate speed: 1.0448 tokens/s, avg speed: 1.6742 tokens/s, remaining time: 0:21:32
pred is:
 ['']
 label is:
 ['EU law']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:26,539 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:26,539 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 334, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:26,539 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:26,540 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:26,540 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:27,483 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:27,485 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9446992874145508 s; generated tokens: 1 tokens; generate speed: 1.0585379001785806 tokens/s
2024-06-05 16:29:27,489 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:27,490 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[759/2067], cost time 0.9559s, every example cost time is 0.9559, generate speed: 1.0461 tokens/s, avg speed: 1.6734 tokens/s, remaining time: 0:21:31
pred is:
 ['']
 label is:
 ['administrative law']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:27,571 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:27,572 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 522, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:27,572 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:27,572 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:27,572 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:28,517 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:28,519 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9468226432800293 s; generated tokens: 1 tokens; generate speed: 1.0561640103322318 tokens/s
2024-06-05 16:29:28,524 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:28,524 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[760/2067], cost time 0.9581s, every example cost time is 0.9581, generate speed: 1.0437 tokens/s, avg speed: 1.6726 tokens/s, remaining time: 0:21:30
pred is:
 ['']
 label is:
 ['Van Gend en Loos v Nederlandse Administratie der Belastingen']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.365015089293527, Em score: 1.7105263157894737, current_count: 760
2024-06-05 16:29:28,715 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:28,715 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 286, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:28,715 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:28,716 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:28,716 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:29,658 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:29,660 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943810224533081 s; generated tokens: 1 tokens; generate speed: 1.0595350357586102 tokens/s
2024-06-05 16:29:29,664 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:29,665 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[761/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.6718 tokens/s, remaining time: 0:21:29
pred is:
 ['']
 label is:
 ['Directives']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:29,745 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:29,745 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 568, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:29,746 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:29,746 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:29,746 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:30,691 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:30,693 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9462742805480957 s; generated tokens: 1 tokens; generate speed: 1.0567760537893787 tokens/s
2024-06-05 16:29:30,697 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:30,698 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[762/2067], cost time 0.9573s, every example cost time is 0.9573, generate speed: 1.0446 tokens/s, avg speed: 1.6711 tokens/s, remaining time: 0:21:28
pred is:
 ['']
 label is:
 ['the member state cannot enforce conflicting laws, and a citizen may rely on the Directive in such an action']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:30,779 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:30,780 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 359, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:30,780 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:30,780 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:30,780 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:31,724 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:31,726 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9450502395629883 s; generated tokens: 1 tokens; generate speed: 1.0581448034576677 tokens/s
2024-06-05 16:29:31,730 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:31,731 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[763/2067], cost time 0.9561s, every example cost time is 0.9561, generate speed: 1.0459 tokens/s, avg speed: 1.6703 tokens/s, remaining time: 0:21:27
pred is:
 ['']
 label is:
 ['national courts']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:31,836 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:31,837 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 174, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:31,837 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:31,837 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:31,838 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:32,778 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:32,780 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418973922729492 s; generated tokens: 1 tokens; generate speed: 1.0616867699217638 tokens/s
2024-06-05 16:29:32,784 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:32,785 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[764/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.6695 tokens/s, remaining time: 0:21:26
pred is:
 ['']
 label is:
 ['the European Court of Justice']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:32,867 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:32,867 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:32,868 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:32,868 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:32,868 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:33,810 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:33,813 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439616203308105 s; generated tokens: 1 tokens; generate speed: 1.0593651039006764 tokens/s
2024-06-05 16:29:33,817 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:33,817 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[765/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0462 tokens/s, avg speed: 1.6687 tokens/s, remaining time: 0:21:25
pred is:
 ['']
 label is:
 ['since the 1950s']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:33,899 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:33,899 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 296, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:33,899 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:33,899 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:33,900 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:34,842 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:34,844 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437379837036133 s; generated tokens: 1 tokens; generate speed: 1.059616140568584 tokens/s
2024-06-05 16:29:34,848 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:34,848 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[766/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0475 tokens/s, avg speed: 1.6679 tokens/s, remaining time: 0:21:24
pred is:
 ['']
 label is:
 ['since the 1960s']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:34,930 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:34,930 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 189, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:34,930 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:34,931 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:34,931 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:35,871 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:35,873 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421911239624023 s; generated tokens: 1 tokens; generate speed: 1.0613557850072726 tokens/s
2024-06-05 16:29:35,878 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:35,878 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[767/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.6671 tokens/s, remaining time: 0:21:23
pred is:
 ['']
 label is:
 ['from the constitutional traditions common to the member states']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:35,959 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:35,959 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 272, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:35,960 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:35,960 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:35,960 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:36,902 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:36,904 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436256885528564 s; generated tokens: 1 tokens; generate speed: 1.059742239037175 tokens/s
2024-06-05 16:29:36,908 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:36,909 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[768/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0475 tokens/s, avg speed: 1.6663 tokens/s, remaining time: 0:21:21
pred is:
 ['']
 label is:
 ['None']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:36,989 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:36,990 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 217, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:36,990 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:36,990 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:36,990 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:37,931 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:37,933 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423954486846924 s; generated tokens: 1 tokens; generate speed: 1.0611256679939474 tokens/s
2024-06-05 16:29:37,938 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:37,938 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[769/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.6656 tokens/s, remaining time: 0:21:20
pred is:
 ['']
 label is:
 ['2007']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:38,043 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:38,043 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 207, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:38,044 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:38,044 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:38,044 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:38,986 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:38,988 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438409805297852 s; generated tokens: 1 tokens; generate speed: 1.059500509756095 tokens/s
2024-06-05 16:29:38,993 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:38,993 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[770/2067], cost time 0.9552s, every example cost time is 0.9552, generate speed: 1.0469 tokens/s, avg speed: 1.6648 tokens/s, remaining time: 0:21:19
pred is:
 ['']
 label is:
 ['1997 Treaty of Amsterdam']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.33430060761439, Em score: 1.6883116883116882, current_count: 770
2024-06-05 16:29:39,186 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:39,186 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 228, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:39,187 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:39,187 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:39,187 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:40,128 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:40,130 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424540996551514 s; generated tokens: 1 tokens; generate speed: 1.0610596318334282 tokens/s
2024-06-05 16:29:40,134 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:40,134 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[771/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.6640 tokens/s, remaining time: 0:21:18
pred is:
 ['']
 label is:
 ['11 of the then 12 member states']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:40,215 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:40,215 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 210, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:40,216 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:40,216 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:40,216 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:41,157 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:41,159 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422657489776611 s; generated tokens: 1 tokens; generate speed: 1.0612717283685407 tokens/s
2024-06-05 16:29:41,163 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:41,164 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[772/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.6632 tokens/s, remaining time: 0:21:17
pred is:
 ['']
 label is:
 ['the election of the UK Labour Party to government']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:41,245 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:41,245 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 346, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:41,245 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:41,246 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:41,246 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:42,189 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:42,191 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.944751501083374 s; generated tokens: 1 tokens; generate speed: 1.0584793978662865 tokens/s
2024-06-05 16:29:42,195 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:42,196 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[773/2067], cost time 0.9557s, every example cost time is 0.9557, generate speed: 1.0464 tokens/s, avg speed: 1.6625 tokens/s, remaining time: 0:21:16
pred is:
 ['']
 label is:
 ['France, Italy, Belgium, the Netherlands, Luxembourg and Germany']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:42,277 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:42,277 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 312, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:42,278 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:42,278 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:42,278 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:43,221 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:43,222 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9441492557525635 s; generated tokens: 1 tokens; generate speed: 1.0591545710671761 tokens/s
2024-06-05 16:29:43,227 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:43,227 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[774/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.6617 tokens/s, remaining time: 0:21:15
pred is:
 ['']
 label is:
 ['Article 101(1)']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:43,326 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:43,326 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 496, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:43,327 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:43,327 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:43,327 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:44,272 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:44,274 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9470083713531494 s; generated tokens: 1 tokens; generate speed: 1.0559568745639836 tokens/s
2024-06-05 16:29:44,279 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:44,279 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[775/2067], cost time 0.9582s, every example cost time is 0.9582, generate speed: 1.0437 tokens/s, avg speed: 1.6609 tokens/s, remaining time: 0:21:14
pred is:
 ['']
 label is:
 ['2007']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:44,361 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:44,361 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 666, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:44,362 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:44,362 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:44,362 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:45,306 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:45,308 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9459373950958252 s; generated tokens: 1 tokens; generate speed: 1.057152413240517 tokens/s
2024-06-05 16:29:45,313 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:45,313 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[776/2067], cost time 0.9568s, every example cost time is 0.9568, generate speed: 1.0452 tokens/s, avg speed: 1.6602 tokens/s, remaining time: 0:21:13
pred is:
 ['']
 label is:
 ['a customs union, and the principle of non-discrimination']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:45,394 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:45,394 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 685, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:45,395 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:45,395 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:45,395 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:46,339 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:46,341 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9459266662597656 s; generated tokens: 1 tokens; generate speed: 1.057164403614968 tokens/s
2024-06-05 16:29:46,346 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:46,346 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[777/2067], cost time 0.9568s, every example cost time is 0.9568, generate speed: 1.0452 tokens/s, avg speed: 1.6594 tokens/s, remaining time: 0:21:12
pred is:
 ['']
 label is:
 ['25']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:46,426 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:46,427 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 539, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:46,427 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:46,427 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:46,427 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:47,372 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:47,373 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9458944797515869 s; generated tokens: 1 tokens; generate speed: 1.057200376370335 tokens/s
2024-06-05 16:29:47,378 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:47,378 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[778/2067], cost time 0.9567s, every example cost time is 0.9567, generate speed: 1.0453 tokens/s, avg speed: 1.6586 tokens/s, remaining time: 0:21:11
pred is:
 ['']
 label is:
 ['Keck and Mithouard']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:47,459 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:47,459 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 484, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:47,460 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:47,460 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:47,460 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:48,405 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:48,406 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.945906400680542 s; generated tokens: 1 tokens; generate speed: 1.0571870528421625 tokens/s
2024-06-05 16:29:48,411 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:48,411 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[779/2067], cost time 0.9568s, every example cost time is 0.9568, generate speed: 1.0452 tokens/s, avg speed: 1.6579 tokens/s, remaining time: 0:21:10
pred is:
 ['']
 label is:
 ['to enable people to pursue their life goals in any country through free movement']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:48,500 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:48,501 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 748, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:48,501 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:48,502 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:48,502 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:49,448 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:49,450 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9485077857971191 s; generated tokens: 1 tokens; generate speed: 1.0542876030897386 tokens/s
2024-06-05 16:29:49,455 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:49,455 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[780/2067], cost time 0.9606s, every example cost time is 0.9606, generate speed: 1.0410 tokens/s, avg speed: 1.6571 tokens/s, remaining time: 0:21:09
pred is:
 ['']
 label is:
 ['articles 1 to 7']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.3043736767475393, Em score: 1.6666666666666667, current_count: 780
2024-06-05 16:29:49,651 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:49,651 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 181, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:49,652 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:49,652 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:49,652 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:50,592 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:50,594 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418506622314453 s; generated tokens: 1 tokens; generate speed: 1.0617394456471332 tokens/s
2024-06-05 16:29:50,599 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:50,599 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[781/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.6563 tokens/s, remaining time: 0:21:08
pred is:
 ['']
 label is:
 ['Citizenship of the EU']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:50,679 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:50,679 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 495, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:50,680 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:50,680 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:50,680 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:51,625 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:51,627 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9462790489196777 s; generated tokens: 1 tokens; generate speed: 1.0567707286150454 tokens/s
2024-06-05 16:29:51,631 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:51,631 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[782/2067], cost time 0.9571s, every example cost time is 0.9571, generate speed: 1.0448 tokens/s, avg speed: 1.6556 tokens/s, remaining time: 0:21:07
pred is:
 ['']
 label is:
 ['the Treaty on the Functioning of the European Union']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:51,719 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:51,719 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 296, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:51,720 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:51,720 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:51,720 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:52,662 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:52,664 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438660144805908 s; generated tokens: 1 tokens; generate speed: 1.059472408856992 tokens/s
2024-06-05 16:29:52,669 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:52,669 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[783/2067], cost time 0.9551s, every example cost time is 0.9551, generate speed: 1.0470 tokens/s, avg speed: 1.6548 tokens/s, remaining time: 0:21:06
pred is:
 ['']
 label is:
 ['2006']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:52,750 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:52,750 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 835, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:52,750 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:52,750 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:52,751 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:53,695 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:53,697 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.946197509765625 s; generated tokens: 1 tokens; generate speed: 1.056861796484438 tokens/s
2024-06-05 16:29:53,702 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:53,702 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[784/2067], cost time 0.9572s, every example cost time is 0.9572, generate speed: 1.0447 tokens/s, avg speed: 1.6541 tokens/s, remaining time: 0:21:05
pred is:
 ['']
 label is:
 ['to people who give services "for remuneration"']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:53,783 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:53,784 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 588, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:53,784 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:53,784 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:53,784 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:54,729 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:54,731 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9469127655029297 s; generated tokens: 1 tokens; generate speed: 1.056063490145129 tokens/s
2024-06-05 16:29:54,736 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:54,736 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[785/2067], cost time 0.9579s, every example cost time is 0.9579, generate speed: 1.0439 tokens/s, avg speed: 1.6533 tokens/s, remaining time: 0:21:04
pred is:
 ['']
 label is:
 ['the Daily Mail']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:54,817 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:54,817 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 303, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:54,817 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:54,818 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:54,818 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:55,760 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:55,762 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943734884262085 s; generated tokens: 1 tokens; generate speed: 1.0596196205907014 tokens/s
2024-06-05 16:29:55,766 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:55,767 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[786/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0473 tokens/s, avg speed: 1.6526 tokens/s, remaining time: 0:21:03
pred is:
 ['']
 label is:
 ['also known in English as Amazonia or the Amazon Jungle,']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:55,848 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:55,848 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 202, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:55,848 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:55,849 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:55,849 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:56,789 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:56,791 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422972202301025 s; generated tokens: 1 tokens; generate speed: 1.061236283553725 tokens/s
2024-06-05 16:29:56,796 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:56,796 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[787/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.6518 tokens/s, remaining time: 0:21:02
pred is:
 ['']
 label is:
 ['the wetter climate may have allowed the tropical rainforest to spread out across the continent.']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:56,878 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:56,878 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 164, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:56,879 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:56,879 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:56,879 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:57,819 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:57,821 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941950798034668 s; generated tokens: 1 tokens; generate speed: 1.0616265754925296 tokens/s
2024-06-05 16:29:57,826 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:57,826 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[788/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.6511 tokens/s, remaining time: 0:21:01
pred is:
 ['']
 label is:
 ['During the mid-Eocene, it is believed that the drainage basin of the Amazon was split along the middle of the continent by the Purus Arch.']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:57,908 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:57,909 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 241, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:57,909 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:57,909 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:57,909 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:58,851 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:58,852 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429352283477783 s; generated tokens: 1 tokens; generate speed: 1.060518230665972 tokens/s
2024-06-05 16:29:58,857 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:58,857 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[789/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0485 tokens/s, avg speed: 1.6504 tokens/s, remaining time: 0:21:00
pred is:
 ['']
 label is:
 ['Last Glacial Maximum']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:29:58,944 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:29:58,944 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 192, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:29:58,945 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:58,945 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:29:58,945 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:29:59,886 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:29:59,889 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943425178527832 s; generated tokens: 1 tokens; generate speed: 1.0599674704044364 tokens/s
2024-06-05 16:29:59,893 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:29:59,894 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[790/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0475 tokens/s, avg speed: 1.6496 tokens/s, remaining time: 0:20:59
pred is:
 ['']
 label is:
 ['CALIPSO']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.275204389700102, Em score: 1.6455696202531647, current_count: 790
2024-06-05 16:30:00,093 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:00,093 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 253, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:00,094 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:00,094 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:00,094 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:01,035 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:01,037 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430243968963623 s; generated tokens: 1 tokens; generate speed: 1.060417952378701 tokens/s
2024-06-05 16:30:01,042 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:01,042 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[791/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.6489 tokens/s, remaining time: 0:20:58
pred is:
 ['']
 label is:
 ['Man and Culture in a Counterfeit Paradise']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:01,123 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:01,123 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 260, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:01,123 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:01,124 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:01,124 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:02,066 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:02,067 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434447288513184 s; generated tokens: 1 tokens; generate speed: 1.0599455054643634 tokens/s
2024-06-05 16:30:02,072 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:02,072 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[792/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.6481 tokens/s, remaining time: 0:20:57
pred is:
 ['']
 label is:
 ['Francisco de Orellana']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:02,159 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:02,159 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:02,160 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:02,160 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:02,160 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:03,101 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:03,103 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421231746673584 s; generated tokens: 1 tokens; generate speed: 1.0614323337848859 tokens/s
2024-06-05 16:30:03,107 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:03,107 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[793/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.6474 tokens/s, remaining time: 0:20:56
pred is:
 ['']
 label is:
 ['black earth']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:03,189 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:03,189 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:03,189 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:03,190 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:03,190 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:04,130 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:04,132 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424622058868408 s; generated tokens: 1 tokens; generate speed: 1.0610505055309005 tokens/s
2024-06-05 16:30:04,137 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:04,137 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[794/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.6467 tokens/s, remaining time: 0:20:55
pred is:
 ['']
 label is:
 ['2.5 million']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:04,218 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:04,218 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 193, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:04,218 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:04,218 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:04,219 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:05,159 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:05,161 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425420761108398 s; generated tokens: 1 tokens; generate speed: 1.0609605930021138 tokens/s
2024-06-05 16:30:05,166 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:05,166 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[795/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.6460 tokens/s, remaining time: 0:20:53
pred is:
 ['']
 label is:
 ['62 acres']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:05,247 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:05,247 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 176, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:05,248 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:05,248 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:05,248 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:06,188 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:06,190 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415411949157715 s; generated tokens: 1 tokens; generate speed: 1.0620884199224636 tokens/s
2024-06-05 16:30:06,195 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:06,195 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[796/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.6452 tokens/s, remaining time: 0:20:52
pred is:
 ['']
 label is:
 ['electric eels']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:06,277 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:06,277 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 218, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:06,278 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:06,278 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:06,278 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:07,219 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:07,221 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426095485687256 s; generated tokens: 1 tokens; generate speed: 1.0608846489179078 tokens/s
2024-06-05 16:30:07,225 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:07,226 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[797/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.6445 tokens/s, remaining time: 0:20:51
pred is:
 ['']
 label is:
 ['Deforestation']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:07,306 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:07,306 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 226, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:07,307 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:07,307 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:07,307 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:08,248 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:08,250 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429299831390381 s; generated tokens: 1 tokens; generate speed: 1.0605241299793802 tokens/s
2024-06-05 16:30:08,255 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:08,255 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[798/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.6438 tokens/s, remaining time: 0:20:50
pred is:
 ['']
 label is:
 ['415,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:08,336 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:08,336 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 185, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:08,337 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:08,337 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:08,337 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:09,277 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:09,279 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416947364807129 s; generated tokens: 1 tokens; generate speed: 1.0619152483926848 tokens/s
2024-06-05 16:30:09,283 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:09,284 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[799/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.6431 tokens/s, remaining time: 0:20:49
pred is:
 ['']
 label is:
 ['soy farmers']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:09,376 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:09,376 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 167, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:09,376 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:09,377 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:09,377 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:10,317 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:10,319 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423222541809082 s; generated tokens: 1 tokens; generate speed: 1.0612080905053303 tokens/s
2024-06-05 16:30:10,324 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:10,324 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[800/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.6423 tokens/s, remaining time: 0:20:48
pred is:
 ['']
 label is:
 ['loss of biodiversity']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.2467643348288506, Em score: 1.625, current_count: 800
2024-06-05 16:30:10,525 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:10,525 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 156, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:10,525 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:10,526 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:10,526 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:11,466 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:11,468 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416511058807373 s; generated tokens: 1 tokens; generate speed: 1.0619644513290178 tokens/s
2024-06-05 16:30:11,472 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:11,472 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[801/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.6416 tokens/s, remaining time: 0:20:47
pred is:
 ['']
 label is:
 ['reduced rainfall and increased temperatures']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:11,555 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:11,555 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 149, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:11,555 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:11,556 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:11,556 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:12,496 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:12,498 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415431022644043 s; generated tokens: 1 tokens; generate speed: 1.0620862683768881 tokens/s
2024-06-05 16:30:12,502 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:12,502 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[802/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.6409 tokens/s, remaining time: 0:20:46
pred is:
 ['']
 label is:
 ['indigenous territories']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:12,584 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:12,584 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 151, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:12,584 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:12,584 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:12,585 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:13,525 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:13,526 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941659688949585 s; generated tokens: 1 tokens; generate speed: 1.0619547717026023 tokens/s
2024-06-05 16:30:13,531 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:13,531 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[803/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0499 tokens/s, avg speed: 1.6402 tokens/s, remaining time: 0:20:45
pred is:
 ['']
 label is:
 ['remote sensing']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:13,614 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:13,615 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 187, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:13,615 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:13,615 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:13,616 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:14,558 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:14,560 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9442658424377441 s; generated tokens: 1 tokens; generate speed: 1.0590237992919145 tokens/s
2024-06-05 16:30:14,565 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:14,565 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[804/2067], cost time 0.9559s, every example cost time is 0.9559, generate speed: 1.0461 tokens/s, avg speed: 1.6395 tokens/s, remaining time: 0:20:44
pred is:
 ['']
 label is:
 ['tree growth']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:14,646 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:14,646 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 206, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:14,646 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:14,647 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:14,647 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:15,588 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:15,590 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943457841873169 s; generated tokens: 1 tokens; generate speed: 1.0599307733926622 tokens/s
2024-06-05 16:30:15,595 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:15,595 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[805/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0475 tokens/s, avg speed: 1.6388 tokens/s, remaining time: 0:20:43
pred is:
 ['']
 label is:
 ['2005']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:15,676 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:15,676 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 214, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:15,676 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:15,677 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:15,677 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:16,618 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:16,620 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424879550933838 s; generated tokens: 1 tokens; generate speed: 1.061021517140681 tokens/s
2024-06-05 16:30:16,624 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:16,624 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[806/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.6381 tokens/s, remaining time: 0:20:42
pred is:
 ['']
 label is:
 ['2010']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:16,710 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:16,711 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 320, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:16,711 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:16,711 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:16,711 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:17,654 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:17,656 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445233345031738 s; generated tokens: 1 tokens; generate speed: 1.0587350925808596 tokens/s
2024-06-05 16:30:17,661 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:17,661 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[807/2067], cost time 0.9557s, every example cost time is 0.9557, generate speed: 1.0463 tokens/s, avg speed: 1.6374 tokens/s, remaining time: 0:20:41
pred is:
 ['']
 label is:
 ['comb jellies']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:17,742 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:17,742 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 299, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:17,743 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:17,743 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:17,743 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:18,685 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:18,687 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439249038696289 s; generated tokens: 1 tokens; generate speed: 1.0594063107144336 tokens/s
2024-06-05 16:30:18,692 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:18,692 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[808/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.6367 tokens/s, remaining time: 0:20:40
pred is:
 ['']
 label is:
 ['ten times their own weight']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:18,773 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:18,773 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 288, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:18,774 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:18,774 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:18,774 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:19,716 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:19,718 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438064098358154 s; generated tokens: 1 tokens; generate speed: 1.059539318210352 tokens/s
2024-06-05 16:30:19,723 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:19,723 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[809/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0474 tokens/s, avg speed: 1.6359 tokens/s, remaining time: 0:20:39
pred is:
 ['']
 label is:
 ['Most species are hermaphrodites']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:19,803 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:19,804 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 241, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:19,804 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:19,804 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:19,804 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:20,746 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:20,749 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9442098140716553 s; generated tokens: 1 tokens; generate speed: 1.059086640592904 tokens/s
2024-06-05 16:30:20,754 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:20,754 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[810/2067], cost time 0.9551s, every example cost time is 0.9551, generate speed: 1.0470 tokens/s, avg speed: 1.6352 tokens/s, remaining time: 0:20:38
pred is:
 ['']
 label is:
 ['the Black Sea']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.2190265035346672, Em score: 1.6049382716049383, current_count: 810
2024-06-05 16:30:20,956 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:20,957 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 281, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:20,957 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:20,957 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:20,957 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:21,900 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:21,901 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437994956970215 s; generated tokens: 1 tokens; generate speed: 1.0595470802423697 tokens/s
2024-06-05 16:30:21,906 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:21,906 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[811/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.6345 tokens/s, remaining time: 0:20:37
pred is:
 ['']
 label is:
 ['66 million years ago']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:21,987 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:21,988 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:21,988 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:21,988 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:21,988 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:22,928 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:22,930 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418511390686035 s; generated tokens: 1 tokens; generate speed: 1.061738908113335 tokens/s
2024-06-05 16:30:22,935 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:22,935 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[812/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.6338 tokens/s, remaining time: 0:20:36
pred is:
 ['']
 label is:
 ['cnidarians']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:23,017 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:23,017 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 189, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:23,018 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:23,018 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:23,018 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:23,959 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:23,960 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422674179077148 s; generated tokens: 1 tokens; generate speed: 1.0612698486598202 tokens/s
2024-06-05 16:30:23,965 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:23,965 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[813/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.6331 tokens/s, remaining time: 0:20:35
pred is:
 ['']
 label is:
 ['mesoglea']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:24,046 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:24,046 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 202, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:24,047 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:24,047 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:24,047 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:24,988 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:24,990 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942659854888916 s; generated tokens: 1 tokens; generate speed: 1.0608280333714233 tokens/s
2024-06-05 16:30:24,995 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:24,995 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[814/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.6324 tokens/s, remaining time: 0:20:34
pred is:
 ['']
 label is:
 ['cilia']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:25,075 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:25,075 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 185, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:25,075 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:25,076 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:25,076 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:26,016 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:26,019 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425802230834961 s; generated tokens: 1 tokens; generate speed: 1.0609176550815638 tokens/s
2024-06-05 16:30:26,023 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:26,024 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[815/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.6318 tokens/s, remaining time: 0:20:33
pred is:
 ['']
 label is:
 ['Pleurobrachia']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:26,104 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:26,104 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 315, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:26,104 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:26,105 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:26,105 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:27,047 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:27,049 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9443244934082031 s; generated tokens: 1 tokens; generate speed: 1.0589580244719228 tokens/s
2024-06-05 16:30:27,054 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:27,054 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[816/2067], cost time 0.9551s, every example cost time is 0.9551, generate speed: 1.0470 tokens/s, avg speed: 1.6311 tokens/s, remaining time: 0:20:32
pred is:
 ['']
 label is:
 ['epithelium']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:27,135 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:27,135 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 315, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:27,136 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:27,136 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:27,136 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:28,079 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:28,081 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9442384243011475 s; generated tokens: 1 tokens; generate speed: 1.0590545504861475 tokens/s
2024-06-05 16:30:28,085 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:28,085 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[817/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.6304 tokens/s, remaining time: 0:20:31
pred is:
 ['']
 label is:
 ['swimming-plates']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:28,166 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:28,166 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 171, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:28,167 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:28,167 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:28,167 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:29,107 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:29,109 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418389797210693 s; generated tokens: 1 tokens; generate speed: 1.0617526153952084 tokens/s
2024-06-05 16:30:29,114 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:29,114 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[818/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.6297 tokens/s, remaining time: 0:20:30
pred is:
 ['']
 label is:
 ['osmotic pressure']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:29,195 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:29,195 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 208, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:29,195 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:29,196 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:29,196 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:30,137 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:30,138 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423391819000244 s; generated tokens: 1 tokens; generate speed: 1.061189027483411 tokens/s
2024-06-05 16:30:30,143 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:30,143 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[819/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.6290 tokens/s, remaining time: 0:20:29
pred is:
 ['']
 label is:
 ['aboral organ']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:30,225 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:30,225 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 174, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:30,225 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:30,225 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:30,226 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:31,166 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:31,168 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942570686340332 s; generated tokens: 1 tokens; generate speed: 1.0609283892358732 tokens/s
2024-06-05 16:30:31,173 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:31,173 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[820/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.6283 tokens/s, remaining time: 0:20:28
pred is:
 ['']
 label is:
 ['sea gooseberry']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.191965204711074, Em score: 1.5853658536585367, current_count: 820
2024-06-05 16:30:31,378 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:31,378 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 487, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:31,378 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:31,379 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:31,379 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:32,323 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:32,325 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9460976123809814 s; generated tokens: 1 tokens; generate speed: 1.0569733893349187 tokens/s
2024-06-05 16:30:32,330 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:32,330 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[821/2067], cost time 0.9574s, every example cost time is 0.9574, generate speed: 1.0445 tokens/s, avg speed: 1.6276 tokens/s, remaining time: 0:20:27
pred is:
 ['']
 label is:
 ['tentilla']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:32,411 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:32,411 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 165, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:32,411 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:32,411 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:32,412 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:33,352 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:33,354 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420192241668701 s; generated tokens: 1 tokens; generate speed: 1.0615494613545797 tokens/s
2024-06-05 16:30:33,359 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:33,359 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[822/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.6269 tokens/s, remaining time: 0:20:26
pred is:
 ['']
 label is:
 ['eight rows']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:33,440 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:33,440 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 181, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:33,440 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:33,441 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:33,441 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:34,381 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:34,383 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942328691482544 s; generated tokens: 1 tokens; generate speed: 1.0612008411064329 tokens/s
2024-06-05 16:30:34,388 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:34,388 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[823/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.6263 tokens/s, remaining time: 0:20:25
pred is:
 ['']
 label is:
 ['lobes']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:34,470 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:34,470 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 272, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:34,470 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:34,471 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:34,471 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:35,413 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:35,415 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943917989730835 s; generated tokens: 1 tokens; generate speed: 1.059414070797779 tokens/s
2024-06-05 16:30:35,420 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:35,420 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[824/2067], cost time 0.9554s, every example cost time is 0.9554, generate speed: 1.0467 tokens/s, avg speed: 1.6256 tokens/s, remaining time: 0:20:24
pred is:
 ['']
 label is:
 ['by clapping their lobes']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:35,502 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:35,502 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 216, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:35,502 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:35,503 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:35,503 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:36,444 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:36,446 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433841705322266 s; generated tokens: 1 tokens; generate speed: 1.0600135461631 tokens/s
2024-06-05 16:30:36,451 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:36,451 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[825/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0473 tokens/s, avg speed: 1.6249 tokens/s, remaining time: 0:20:22
pred is:
 ['']
 label is:
 ['Nuda']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:36,533 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:36,533 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 247, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:36,533 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:36,534 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:36,534 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:37,475 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:37,477 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431660175323486 s; generated tokens: 1 tokens; generate speed: 1.0602587258352978 tokens/s
2024-06-05 16:30:37,482 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:37,482 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[826/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.6242 tokens/s, remaining time: 0:20:21
pred is:
 ['']
 label is:
 ['The Cestida']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:37,574 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:37,574 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 185, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:37,575 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:37,575 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:37,575 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:38,516 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:38,517 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423933029174805 s; generated tokens: 1 tokens; generate speed: 1.0611280841069006 tokens/s
2024-06-05 16:30:38,522 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:38,522 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[827/2067], cost time 0.9641s, every example cost time is 0.9641, generate speed: 1.0372 tokens/s, avg speed: 1.6235 tokens/s, remaining time: 0:20:20
pred is:
 ['']
 label is:
 ['a pair of tentilla-bearing tentacles']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:38,603 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:38,603 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:38,604 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:38,604 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:38,604 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:39,545 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:39,546 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423196315765381 s; generated tokens: 1 tokens; generate speed: 1.0612110439925362 tokens/s
2024-06-05 16:30:39,551 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:39,551 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[828/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.6229 tokens/s, remaining time: 0:20:19
pred is:
 ['']
 label is:
 ['via pores in the epidermis']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:39,632 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:39,633 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 188, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:39,633 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:39,633 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:39,633 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:40,573 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:40,575 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417483806610107 s; generated tokens: 1 tokens; generate speed: 1.0618547592278338 tokens/s
2024-06-05 16:30:40,580 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:40,580 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[829/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.6222 tokens/s, remaining time: 0:20:18
pred is:
 ['']
 label is:
 ['tentacles and tentacle sheaths']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:40,661 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:40,661 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 199, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:40,662 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:40,662 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:40,662 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:41,603 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:41,607 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9440982341766357 s; generated tokens: 1 tokens; generate speed: 1.059211810593118 tokens/s
2024-06-05 16:30:41,611 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:41,611 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[830/2067], cost time 0.9553s, every example cost time is 0.9553, generate speed: 1.0468 tokens/s, avg speed: 1.6215 tokens/s, remaining time: 0:20:17
pred is:
 ['']
 label is:
 ['they produce secretions (ink) that luminesce']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.1655559853772055, Em score: 1.5662650602409638, current_count: 830
2024-06-05 16:30:41,820 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:41,821 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 427, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:41,821 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:41,821 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:41,821 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:42,766 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:42,767 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9457552433013916 s; generated tokens: 1 tokens; generate speed: 1.0573560200515026 tokens/s
2024-06-05 16:30:42,772 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:42,772 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[831/2067], cost time 0.9570s, every example cost time is 0.9570, generate speed: 1.0449 tokens/s, avg speed: 1.6208 tokens/s, remaining time: 0:20:16
pred is:
 ['']
 label is:
 ['Almost all ctenophores are predators']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:42,853 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:42,853 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 331, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:42,853 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:42,854 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:42,854 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:43,797 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:43,799 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.944589376449585 s; generated tokens: 1 tokens; generate speed: 1.0586610700182615 tokens/s
2024-06-05 16:30:43,803 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:43,804 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[832/2067], cost time 0.9556s, every example cost time is 0.9556, generate speed: 1.0465 tokens/s, avg speed: 1.6202 tokens/s, remaining time: 0:20:15
pred is:
 ['']
 label is:
 ['their low ratio of organic matter to salt and water']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:43,884 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:43,884 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 319, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:43,885 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:43,885 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:43,885 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:44,828 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:44,830 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9444503784179688 s; generated tokens: 1 tokens; generate speed: 1.0588168768327262 tokens/s
2024-06-05 16:30:44,835 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:44,835 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[833/2067], cost time 0.9554s, every example cost time is 0.9554, generate speed: 1.0467 tokens/s, avg speed: 1.6195 tokens/s, remaining time: 0:20:14
pred is:
 ['']
 label is:
 ['ctenophore Mnemiopsis leidyi']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:44,917 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:44,917 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 312, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:44,917 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:44,917 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:44,918 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:45,861 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:45,863 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.944868803024292 s; generated tokens: 1 tokens; generate speed: 1.0583479915933796 tokens/s
2024-06-05 16:30:45,867 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:45,868 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[834/2067], cost time 0.9561s, every example cost time is 0.9561, generate speed: 1.0459 tokens/s, avg speed: 1.6188 tokens/s, remaining time: 0:20:13
pred is:
 ['']
 label is:
 ['Because of their soft, gelatinous bodies']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:45,949 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:45,949 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:45,950 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:45,950 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:45,950 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:46,890 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:46,893 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424493312835693 s; generated tokens: 1 tokens; generate speed: 1.0610650003200166 tokens/s
2024-06-05 16:30:46,897 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:46,898 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[835/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.6182 tokens/s, remaining time: 0:20:12
pred is:
 ['']
 label is:
 ['515 million years']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:46,979 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:46,979 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 383, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:46,980 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:46,980 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:46,980 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:47,923 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:47,925 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9452188014984131 s; generated tokens: 1 tokens; generate speed: 1.0579561033008915 tokens/s
2024-06-05 16:30:47,930 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:47,930 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[836/2067], cost time 0.9561s, every example cost time is 0.9561, generate speed: 1.0460 tokens/s, avg speed: 1.6175 tokens/s, remaining time: 0:20:11
pred is:
 ['']
 label is:
 ['all other animals']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:48,011 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:48,011 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 398, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:48,011 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:48,012 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:48,012 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:48,956 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:48,958 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9456958770751953 s; generated tokens: 1 tokens; generate speed: 1.057422395762953 tokens/s
2024-06-05 16:30:48,962 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:48,963 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[837/2067], cost time 0.9568s, every example cost time is 0.9568, generate speed: 1.0452 tokens/s, avg speed: 1.6168 tokens/s, remaining time: 0:20:10
pred is:
 ['']
 label is:
 ['beroids']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:49,043 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:49,043 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 225, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:49,044 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:49,044 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:49,044 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:49,985 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:49,987 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942819356918335 s; generated tokens: 1 tokens; generate speed: 1.0606485671534827 tokens/s
2024-06-05 16:30:49,992 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:49,992 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[838/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.6162 tokens/s, remaining time: 0:20:09
pred is:
 ['']
 label is:
 ['Fresno']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:50,073 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:50,074 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 161, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:50,074 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:50,074 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:50,074 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:51,014 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:51,016 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414992332458496 s; generated tokens: 1 tokens; generate speed: 1.062135756130642 tokens/s
2024-06-05 16:30:51,021 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:51,021 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[839/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.6155 tokens/s, remaining time: 0:20:08
pred is:
 ['']
 label is:
 ['1872']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:51,101 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:51,101 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 189, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:51,102 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:51,102 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:51,102 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:52,043 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:52,045 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428806304931641 s; generated tokens: 1 tokens; generate speed: 1.0605796403697043 tokens/s
2024-06-05 16:30:52,050 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:52,050 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[840/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.6149 tokens/s, remaining time: 0:20:07
pred is:
 ['']
 label is:
 ['2.7%']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.139775556979858, Em score: 1.5476190476190477, current_count: 840
2024-06-05 16:30:52,258 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:52,258 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 159, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:52,258 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:52,259 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:52,259 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:53,199 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:53,201 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941683292388916 s; generated tokens: 1 tokens; generate speed: 1.06192815363979 tokens/s
2024-06-05 16:30:53,205 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:53,205 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[841/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.6142 tokens/s, remaining time: 0:20:06
pred is:
 ['']
 label is:
 ['BankAmericard']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:53,287 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:53,287 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 170, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:53,288 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:53,288 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:53,288 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:54,229 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:54,231 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421796798706055 s; generated tokens: 1 tokens; generate speed: 1.0613686766597803 tokens/s
2024-06-05 16:30:54,235 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:54,235 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[842/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.6136 tokens/s, remaining time: 0:20:05
pred is:
 ['']
 label is:
 ['Bill Aken']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:54,324 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:54,325 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:54,325 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:54,325 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:54,325 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:55,266 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:55,268 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427239894866943 s; generated tokens: 1 tokens; generate speed: 1.0607558640196395 tokens/s
2024-06-05 16:30:55,273 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:55,273 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[843/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0477 tokens/s, avg speed: 1.6129 tokens/s, remaining time: 0:20:04
pred is:
 ['']
 label is:
 ['three']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:55,355 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:55,355 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 158, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:55,355 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:55,356 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:55,356 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:56,296 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:56,298 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419131278991699 s; generated tokens: 1 tokens; generate speed: 1.0616690333538361 tokens/s
2024-06-05 16:30:56,302 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:56,303 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[844/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.6123 tokens/s, remaining time: 0:20:03
pred is:
 ['']
 label is:
 ['Between the 1880s and World War II']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:56,384 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:56,384 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 207, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:56,384 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:56,385 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:56,385 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:57,326 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:57,328 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427807331085205 s; generated tokens: 1 tokens; generate speed: 1.0606920197688143 tokens/s
2024-06-05 16:30:57,332 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:57,333 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[845/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.6116 tokens/s, remaining time: 0:20:02
pred is:
 ['']
 label is:
 ['1964']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:57,414 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:57,415 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 172, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:57,415 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:57,415 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:57,416 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:58,356 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:58,358 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418308734893799 s; generated tokens: 1 tokens; generate speed: 1.0617617537797523 tokens/s
2024-06-05 16:30:58,362 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:58,363 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[846/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0492 tokens/s, avg speed: 1.6110 tokens/s, remaining time: 0:20:01
pred is:
 ['']
 label is:
 ["Fresno's far southeast side"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:58,444 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:58,444 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 251, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:58,445 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:58,445 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:58,445 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:30:59,387 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:59,388 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431099891662598 s; generated tokens: 1 tokens; generate speed: 1.0603217137844472 tokens/s
2024-06-05 16:30:59,393 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:30:59,393 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[847/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.6103 tokens/s, remaining time: 0:20:00
pred is:
 ['']
 label is:
 ['Tower Theatre']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:30:59,473 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:30:59,474 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 218, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:30:59,474 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:30:59,474 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:30:59,474 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:00,415 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:00,417 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422399997711182 s; generated tokens: 1 tokens; generate speed: 1.0613007304327056 tokens/s
2024-06-05 16:31:00,421 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:00,422 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[848/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.6097 tokens/s, remaining time: 0:19:59
pred is:
 ['']
 label is:
 ['late 1970s']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:00,502 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:00,502 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 154, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:00,503 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:00,503 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:00,503 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:01,443 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:01,445 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418613910675049 s; generated tokens: 1 tokens; generate speed: 1.061727351268323 tokens/s
2024-06-05 16:31:01,450 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:01,450 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[849/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.6091 tokens/s, remaining time: 0:19:58
pred is:
 ['']
 label is:
 ['live theater']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:01,532 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:01,532 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 146, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:01,533 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:01,533 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:01,533 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:02,473 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:02,476 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425113201141357 s; generated tokens: 1 tokens; generate speed: 1.0609952142313819 tokens/s
2024-06-05 16:31:02,480 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:02,481 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[850/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.6084 tokens/s, remaining time: 0:19:57
pred is:
 ['']
 label is:
 ['early twentieth century homes']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.114601726897742, Em score: 1.5294117647058822, current_count: 850
2024-06-05 16:31:02,691 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:02,691 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 364, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:02,692 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:02,692 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:02,692 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:03,635 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:03,637 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.945213794708252 s; generated tokens: 1 tokens; generate speed: 1.0579617072861893 tokens/s
2024-06-05 16:31:03,642 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:03,643 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[851/2067], cost time 0.9567s, every example cost time is 0.9567, generate speed: 1.0452 tokens/s, avg speed: 1.6078 tokens/s, remaining time: 0:19:56
pred is:
 ['']
 label is:
 ['Huntington Boulevard']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:03,725 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:03,725 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 168, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:03,725 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:03,726 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:03,726 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:04,666 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:04,668 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421064853668213 s; generated tokens: 1 tokens; generate speed: 1.0614511369281543 tokens/s
2024-06-05 16:31:04,673 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:04,673 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[852/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.6071 tokens/s, remaining time: 0:19:55
pred is:
 ['']
 label is:
 ['"Southwest Fresno"']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:04,755 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:04,756 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 228, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:04,756 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:04,756 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:04,756 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:05,698 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:05,699 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428796768188477 s; generated tokens: 1 tokens; generate speed: 1.0605807130914824 tokens/s
2024-06-05 16:31:05,704 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:05,704 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[853/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.6065 tokens/s, remaining time: 0:19:54
pred is:
 ['']
 label is:
 ['M. Theo Kearney']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:05,789 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:05,790 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 325, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:05,790 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:05,790 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:05,791 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:06,733 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:06,735 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445657730102539 s; generated tokens: 1 tokens; generate speed: 1.0586875245469478 tokens/s
2024-06-05 16:31:06,740 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:06,740 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[854/2067], cost time 0.9561s, every example cost time is 0.9561, generate speed: 1.0459 tokens/s, avg speed: 1.6059 tokens/s, remaining time: 0:19:53
pred is:
 ['']
 label is:
 ['between the 1960s and 1990s']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:06,822 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:06,822 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 452, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:06,822 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:06,822 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:06,823 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:07,767 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:07,769 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9466748237609863 s; generated tokens: 1 tokens; generate speed: 1.0563289261535036 tokens/s
2024-06-05 16:31:07,774 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:07,774 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[855/2067], cost time 0.9579s, every example cost time is 0.9579, generate speed: 1.0439 tokens/s, avg speed: 1.6052 tokens/s, remaining time: 0:19:52
pred is:
 ['']
 label is:
 ['Ralph Woodward']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:07,856 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:07,856 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 149, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:07,856 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:07,856 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:07,857 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:08,796 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:08,798 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413497447967529 s; generated tokens: 1 tokens; generate speed: 1.0623044256690273 tokens/s
2024-06-05 16:31:08,804 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:08,804 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[856/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.6046 tokens/s, remaining time: 0:19:51
pred is:
 ['']
 label is:
 ['1946']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:08,885 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:08,886 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 416, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:08,886 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:08,886 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:08,887 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:09,831 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:09,833 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9464504718780518 s; generated tokens: 1 tokens; generate speed: 1.0565793242362587 tokens/s
2024-06-05 16:31:09,838 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:09,838 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[857/2067], cost time 0.9580s, every example cost time is 0.9580, generate speed: 1.0438 tokens/s, avg speed: 1.6040 tokens/s, remaining time: 0:19:50
pred is:
 ['']
 label is:
 ['hot and dry']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:09,919 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:09,920 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 331, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:09,920 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:09,920 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:09,921 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:10,863 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:10,865 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445586204528809 s; generated tokens: 1 tokens; generate speed: 1.0586955413318202 tokens/s
2024-06-05 16:31:10,870 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:10,870 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[858/2067], cost time 0.9560s, every example cost time is 0.9560, generate speed: 1.0460 tokens/s, avg speed: 1.6033 tokens/s, remaining time: 0:19:49
pred is:
 ['']
 label is:
 ['115 °F']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:10,951 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:10,952 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 338, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:10,952 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:10,952 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:10,952 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:11,895 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:11,931 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:11,960 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:11,990 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:12,019 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:12,048 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:12,077 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:12,106 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:12,136 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:12,165 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:12,456 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5035037994384766 s; generated tokens: 20 tokens; generate speed: 13.302261030181322 tokens/s
2024-06-05 16:31:12,461 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:12,461 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[859/2067], cost time 1.5149s, every example cost time is 1.5149, generate speed: 13.2026 tokens/s, avg speed: 1.6241 tokens/s, remaining time: 0:19:48
pred is:
 ['494,665']
 label is:
 ['494,665']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:31:12,543 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:12,543 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 248, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:12,544 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:12,544 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:12,544 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:13,486 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:13,488 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431653022766113 s; generated tokens: 1 tokens; generate speed: 1.0602595298896187 tokens/s
2024-06-05 16:31:13,492 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:13,493 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[860/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0475 tokens/s, avg speed: 1.6235 tokens/s, remaining time: 0:19:47
pred is:
 ['']
 label is:
 ['68,511']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 2.206292404491954, Em score: 1.627906976744186, current_count: 860
2024-06-05 16:31:13,706 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:13,706 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 236, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:13,707 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:13,707 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:13,707 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:14,648 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:14,679 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:14,709 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:14,739 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:14,769 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:14,799 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:14,830 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:14,859 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:14,889 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:14,919 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:15,218 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5103394985198975 s; generated tokens: 20 tokens; generate speed: 13.242055855388541 tokens/s
2024-06-05 16:31:15,222 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:15,223 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[861/2067], cost time 1.5222s, every example cost time is 1.5222, generate speed: 13.1386 tokens/s, avg speed: 1.6441 tokens/s, remaining time: 0:19:47
pred is:
 ['427,652']
 label is:
 ['427,652']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:31:15,305 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:15,305 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 204, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:15,305 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:15,306 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:15,306 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:16,247 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:16,249 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429481029510498 s; generated tokens: 1 tokens; generate speed: 1.0605037508113124 tokens/s
2024-06-05 16:31:16,254 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:16,254 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[862/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.6435 tokens/s, remaining time: 0:19:46
pred is:
 ['']
 label is:
 ['To avoid interference with existing VHF television stations']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:16,336 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:16,336 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 169, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:16,337 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:16,337 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:16,337 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:17,277 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:17,279 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941840648651123 s; generated tokens: 1 tokens; generate speed: 1.0617507339826233 tokens/s
2024-06-05 16:31:17,284 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:17,284 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[863/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.6428 tokens/s, remaining time: 0:19:45
pred is:
 ['']
 label is:
 ['State Route 99']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:17,366 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:17,366 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 200, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:17,366 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:17,367 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:17,367 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:18,307 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:18,309 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421510696411133 s; generated tokens: 1 tokens; generate speed: 1.0614009071612291 tokens/s
2024-06-05 16:31:18,314 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:18,314 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[864/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.6421 tokens/s, remaining time: 0:19:44
pred is:
 ['']
 label is:
 ['Fresno']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:18,395 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:18,395 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 155, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:18,395 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:18,395 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:18,396 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:19,336 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:19,338 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420039653778076 s; generated tokens: 1 tokens; generate speed: 1.061566656568088 tokens/s
2024-06-05 16:31:19,342 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:19,343 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[865/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.6415 tokens/s, remaining time: 0:19:43
pred is:
 ['']
 label is:
 ['Amtrak San Joaquins']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:19,424 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:19,424 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 220, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:19,425 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:19,425 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:19,425 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:20,367 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:20,398 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:20,427 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:20,457 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:20,488 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:20,518 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:20,548 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:20,578 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:20,608 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:20,638 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:20,950 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.524552822113037 s; generated tokens: 20 tokens; generate speed: 13.118600884080822 tokens/s
2024-06-05 16:31:20,955 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:20,955 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[866/2067], cost time 1.5361s, every example cost time is 1.5361, generate speed: 13.0196 tokens/s, avg speed: 1.6620 tokens/s, remaining time: 0:19:43
pred is:
 ['Distributed Adaptive Message Block Switching']
 label is:
 ['Paul Baran developed the concept Distributed Adaptive Message Block Switching']
The F1/Em of this example is:  {'F1': 64.28571428571429, 'Em': 0.0}
2024-06-05 16:31:21,038 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:21,038 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 144, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:21,039 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:21,039 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:21,039 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:21,979 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:21,981 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418535232543945 s; generated tokens: 1 tokens; generate speed: 1.061736220452509 tokens/s
2024-06-05 16:31:21,986 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:21,986 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[867/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0489 tokens/s, avg speed: 1.6613 tokens/s, remaining time: 0:19:42
pred is:
 ['']
 label is:
 ['circuit switching']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:22,068 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:22,068 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 148, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:22,068 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:22,069 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:22,069 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:23,008 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:23,039 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:23,069 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:23,098 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:23,128 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:23,158 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:23,187 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:23,217 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:23,246 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:23,276 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:23,399 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.3298282623291016 s; generated tokens: 14 tokens; generate speed: 10.527675186779362 tokens/s
2024-06-05 16:31:23,404 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:23,404 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[868/2067], cost time 1.3412s, every example cost time is 1.3412, generate speed: 10.4386 tokens/s, avg speed: 1.6750 tokens/s, remaining time: 0:19:41
pred is:
 ['With or without intermediate forwarding nodes (packet switches or routers).']
 label is:
 ['with or without intermediate forwarding nodes']
The F1/Em of this example is:  {'F1': 66.66666666666666, 'Em': 0.0}
2024-06-05 16:31:23,487 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:23,487 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 188, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:23,488 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:23,488 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:23,488 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:24,429 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:24,460 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:24,489 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:24,541 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:24,571 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:24,600 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:24,630 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:24,659 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:24,689 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:24,718 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:25,023 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.534726858139038 s; generated tokens: 20 tokens; generate speed: 13.031634843643367 tokens/s
2024-06-05 16:31:25,028 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:25,028 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[869/2067], cost time 1.5460s, every example cost time is 1.5460, generate speed: 12.9362 tokens/s, avg speed: 1.6953 tokens/s, remaining time: 0:19:41
pred is:
 ['A concept of distributed adaptive message block switching']
 label is:
 ['the concept of distributed adaptive message block switching']
The F1/Em of this example is:  {'F1': 93.33333333333333, 'Em': 0.0}
2024-06-05 16:31:25,110 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:25,110 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 171, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:25,111 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:25,111 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:25,111 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:26,051 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:26,082 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:26,111 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:26,141 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:26,170 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:26,199 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:26,228 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:26,257 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:26,286 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:26,315 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:26,606 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.494234323501587 s; generated tokens: 20 tokens; generate speed: 13.384781546934368 tokens/s
2024-06-05 16:31:26,610 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:26,611 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[870/2067], cost time 1.5055s, every example cost time is 1.5055, generate speed: 13.2848 tokens/s, avg speed: 1.7157 tokens/s, remaining time: 0:19:41
pred is:
 ['1. Packet Switching']
 label is:
 ['independently developed the same message routing methodology as developed by Baran']
The F1/Em of this example is:  {'F1': 7.4074074074074066, 'Em': 0.0}
F1 score: 2.5621891833979333, Em score: 1.7241379310344827, current_count: 870
2024-06-05 16:31:26,853 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:26,854 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 273, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:26,854 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:26,854 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:26,855 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:27,796 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:27,827 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:27,856 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:27,886 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:27,915 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:27,944 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:27,974 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:28,003 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:28,032 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:28,061 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:28,352 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4975879192352295 s; generated tokens: 20 tokens; generate speed: 13.354808584602742 tokens/s
2024-06-05 16:31:28,357 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:28,357 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[871/2067], cost time 1.5089s, every example cost time is 1.5089, generate speed: 13.2548 tokens/s, avg speed: 1.7359 tokens/s, remaining time: 0:19:40
pred is:
 ['Complete addressing information']
 label is:
 ['each packet includes complete addressing information']
The F1/Em of this example is:  {'F1': 62.5, 'Em': 0.0}
2024-06-05 16:31:28,439 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:28,439 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 215, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:28,440 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:28,440 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:28,440 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:29,381 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:29,411 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:29,440 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:29,470 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:29,499 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:29,528 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:29,557 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:29,586 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:29,615 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:29,644 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:29,947 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5068552494049072 s; generated tokens: 20 tokens; generate speed: 13.272675001728581 tokens/s
2024-06-05 16:31:29,952 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:29,952 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[872/2067], cost time 1.5179s, every example cost time is 1.5179, generate speed: 13.1759 tokens/s, avg speed: 1.7561 tokens/s, remaining time: 0:19:40
pred is:
 ['Yes']
 label is:
 ['The packet header can be small, as it only needs to contain this code and any information, such as length, timestamp, or sequence number']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:30,035 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:30,036 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 765, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:30,036 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:30,036 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:30,036 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:30,982 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:30,984 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9469246864318848 s; generated tokens: 1 tokens; generate speed: 1.056050195256931 tokens/s
2024-06-05 16:31:30,988 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:30,988 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[873/2067], cost time 0.9581s, every example cost time is 0.9581, generate speed: 1.0437 tokens/s, avg speed: 1.7553 tokens/s, remaining time: 0:19:39
pred is:
 ['']
 label is:
 ['connection-oriented operations. But X.25 does it at the network layer of the OSI Model. Frame Relay does it at level two, the data link layer']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:31,095 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:31,096 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 190, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:31,096 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:31,096 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:31,096 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:32,037 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:32,039 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419858455657959 s; generated tokens: 1 tokens; generate speed: 1.0615870766076727 tokens/s
2024-06-05 16:31:32,043 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:32,043 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[874/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0490 tokens/s, avg speed: 1.7545 tokens/s, remaining time: 0:19:38
pred is:
 ['']
 label is:
 ['1969']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:32,124 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:32,124 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 141, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:32,125 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:32,125 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:32,125 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:33,065 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:33,096 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:33,125 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:33,155 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:33,184 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:33,213 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:33,243 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:33,272 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:33,301 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:33,331 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:33,626 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5009255409240723 s; generated tokens: 20 tokens; generate speed: 13.325111376069085 tokens/s
2024-06-05 16:31:33,631 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:33,631 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[875/2067], cost time 1.5122s, every example cost time is 1.5122, generate speed: 13.2261 tokens/s, avg speed: 1.7745 tokens/s, remaining time: 0:19:38
pred is:
 ['A proprietary suite of networking protocols developed by Apple Inc. in 1985 for Apple Macintosh']
 label is:
 ['a proprietary suite of networking protocols developed by Apple Inc. in 1985']
The F1/Em of this example is:  {'F1': 88.8888888888889, 'Em': 0.0}
2024-06-05 16:31:33,714 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:33,715 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 140, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:33,715 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:33,715 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:33,716 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:34,655 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:34,658 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418191909790039 s; generated tokens: 1 tokens; generate speed: 1.0617749240812542 tokens/s
2024-06-05 16:31:34,662 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:34,663 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[876/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.7737 tokens/s, remaining time: 0:19:37
pred is:
 ['']
 label is:
 ['CYCLADES packet switching network']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:34,744 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:34,744 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 171, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:34,744 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:34,745 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:34,745 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:35,685 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:35,715 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:35,744 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:35,774 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:35,803 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:35,832 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:35,861 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:35,890 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:35,919 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:35,948 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:36,267 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5218665599822998 s; generated tokens: 20 tokens; generate speed: 13.141756659816885 tokens/s
2024-06-05 16:31:36,272 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:36,272 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[877/2067], cost time 1.5331s, every example cost time is 1.5331, generate speed: 13.0454 tokens/s, avg speed: 1.7937 tokens/s, remaining time: 0:19:37
pred is:
 ['DECnet is a suite of network protocols created by Digital Equipment Corporation, originally released in 197']
 label is:
 ['a suite of network protocols created by Digital Equipment Corporation']
The F1/Em of this example is:  {'F1': 74.50980392156863, 'Em': 0.0}
2024-06-05 16:31:36,355 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:36,355 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 192, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:36,356 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:36,356 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:36,356 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:37,297 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:37,298 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419817924499512 s; generated tokens: 1 tokens; generate speed: 1.0615916443556221 tokens/s
2024-06-05 16:31:37,303 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:37,303 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[878/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.7929 tokens/s, remaining time: 0:19:36
pred is:
 ['']
 label is:
 ["a data network based on this voice-phone network was designed to connect GE's four computer sales and service centers"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:37,385 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:37,385 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 313, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:37,386 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:37,386 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:37,386 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:38,328 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:38,359 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:38,388 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:38,418 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:38,447 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:38,477 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:38,506 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:38,536 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:38,565 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:38,595 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:38,887 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5006165504455566 s; generated tokens: 20 tokens; generate speed: 13.327855136651456 tokens/s
2024-06-05 16:31:38,891 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:38,892 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[879/2067], cost time 1.5116s, every example cost time is 1.5116, generate speed: 13.2311 tokens/s, avg speed: 1.8127 tokens/s, remaining time: 0:19:35
pred is:
 ["to explore computer networking between three of Michigan's public universities as a means to help the state's"]
 label is:
 ["as a means to help the state's educational and economic development"]
The F1/Em of this example is:  {'F1': 50.0, 'Em': 0.0}
2024-06-05 16:31:39,004 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:39,004 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 199, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:39,005 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:39,005 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:39,005 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:39,946 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:39,977 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:40,006 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:40,035 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:40,064 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:40,093 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:40,123 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:40,152 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:40,181 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:40,210 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:40,499 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4934253692626953 s; generated tokens: 20 tokens; generate speed: 13.392031775832232 tokens/s
2024-06-05 16:31:40,503 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:40,504 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[880/2067], cost time 1.5048s, every example cost time is 1.5048, generate speed: 13.2912 tokens/s, avg speed: 1.8325 tokens/s, remaining time: 0:19:35
pred is:
 ['Telenet was the first FCC-licensed public data network in the United States. It was']
 label is:
 ['the first FCC-licensed public data network in the United States']
The F1/Em of this example is:  {'F1': 80.85106382978724, 'Em': 0.0}
F1 score: 2.9384708479505077, Em score: 1.7045454545454546, current_count: 880
2024-06-05 16:31:40,731 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:40,731 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 228, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:40,732 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:40,732 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:40,732 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:41,673 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:41,704 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:41,734 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:41,763 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:41,793 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:41,822 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:41,852 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:41,881 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:41,910 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:41,940 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:42,231 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4981181621551514 s; generated tokens: 20 tokens; generate speed: 13.350081792766302 tokens/s
2024-06-05 16:31:42,235 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:42,236 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[881/2067], cost time 1.5095s, every example cost time is 1.5095, generate speed: 13.2498 tokens/s, avg speed: 1.8523 tokens/s, remaining time: 0:19:35
pred is:
 ['Tymnet was an international data communications network headquartered in San Jose, CA that utilized virtual call']
 label is:
 ['an international data communications network headquartered in San Jose, CA']
The F1/Em of this example is:  {'F1': 76.92307692307693, 'Em': 0.0}
2024-06-05 16:31:42,319 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:42,319 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 210, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:42,319 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:42,320 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:42,320 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:43,260 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:43,290 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:43,342 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:43,344 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.024146318435669 s; generated tokens: 3 tokens; generate speed: 2.929268939405403 tokens/s
2024-06-05 16:31:43,349 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:43,349 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[882/2067], cost time 1.0354s, every example cost time is 1.0354, generate speed: 2.8975 tokens/s, avg speed: 1.8535 tokens/s, remaining time: 0:19:34
pred is:
 ['Two']
 label is:
 ['There were two kinds of X.25 networks. Some such as DATAPAC and TRANSPAC']
The F1/Em of this example is:  {'F1': 7.4074074074074066, 'Em': 0.0}
2024-06-05 16:31:43,433 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:43,433 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 173, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:43,434 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:43,434 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:43,434 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:44,374 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:44,375 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410979747772217 s; generated tokens: 1 tokens; generate speed: 1.06258862180287 tokens/s
2024-06-05 16:31:44,380 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:44,380 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[883/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.8527 tokens/s, remaining time: 0:19:33
pred is:
 ['']
 label is:
 ['AUSTPAC was an Australian public X.25 network operated by Telstra']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:44,462 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:44,462 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:44,462 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:44,463 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:44,463 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:45,403 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:45,433 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:45,462 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:45,492 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:45,521 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:45,550 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:45,578 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:45,608 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:45,637 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:45,666 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:45,954 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4913058280944824 s; generated tokens: 20 tokens; generate speed: 13.411065405380345 tokens/s
2024-06-05 16:31:45,959 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:45,959 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[884/2067], cost time 1.5022s, every example cost time is 1.5022, generate speed: 13.3134 tokens/s, avg speed: 1.8723 tokens/s, remaining time: 0:19:32
pred is:
 ['The public switched data network operated by the Dutch PTT Telecom (now known as KPN).']
 label is:
 ['was the public switched data network operated by the Dutch PTT Telecom']
The F1/Em of this example is:  {'F1': 76.36363636363635, 'Em': 0.0}
2024-06-05 16:31:46,042 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:46,042 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 143, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:46,042 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:46,043 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:46,043 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:46,983 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:46,985 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941692590713501 s; generated tokens: 1 tokens; generate speed: 1.0619176681026243 tokens/s
2024-06-05 16:31:46,990 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:46,990 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[885/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.8714 tokens/s, remaining time: 0:19:31
pred is:
 ['']
 label is:
 ['The Computer Science Network']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:47,072 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:47,072 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 183, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:47,073 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:47,073 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:47,073 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:48,013 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:48,044 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:48,073 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:48,102 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:48,131 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:48,160 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:48,190 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:48,219 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:48,248 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:48,277 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:48,567 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4942853450775146 s; generated tokens: 20 tokens; generate speed: 13.384324530709039 tokens/s
2024-06-05 16:31:48,572 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:48,572 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[886/2067], cost time 1.5055s, every example cost time is 1.5055, generate speed: 13.2845 tokens/s, avg speed: 1.8910 tokens/s, remaining time: 0:19:31
pred is:
 ['Internet2 is a not-for-profit United States computer networking consortium led by members from the research and']
 label is:
 ['a not-for-profit United States computer networking consortium led by members from the research and education communities, industry, and government']
The F1/Em of this example is:  {'F1': 77.14285714285715, 'Em': 0.0}
2024-06-05 16:31:48,656 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:48,656 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:48,657 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:48,657 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:48,657 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:49,597 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:49,599 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415645599365234 s; generated tokens: 1 tokens; generate speed: 1.0620620640898124 tokens/s
2024-06-05 16:31:49,604 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:49,604 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[887/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.8900 tokens/s, remaining time: 0:19:30
pred is:
 ['']
 label is:
 ['The National Science Foundation Network']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:49,684 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:49,684 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 244, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:49,685 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:49,685 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:49,685 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:50,626 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:50,657 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:50,687 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:50,717 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:50,747 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:50,777 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:50,807 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:50,837 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:50,869 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:50,899 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:51,217 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5315873622894287 s; generated tokens: 20 tokens; generate speed: 13.058347497790686 tokens/s
2024-06-05 16:31:51,222 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:51,222 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[888/2067], cost time 1.5426s, every example cost time is 1.5426, generate speed: 12.9649 tokens/s, avg speed: 1.9094 tokens/s, remaining time: 0:19:30
pred is:
 ['Very high-speed Backbone Network Service']
 label is:
 ['The Very high-speed Backbone Network Service']
The F1/Em of this example is:  {'F1': 90.0, 'Em': 0.0}
2024-06-05 16:31:51,305 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:51,305 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 196, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:51,305 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:51,306 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:51,306 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:52,246 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:52,248 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420568943023682 s; generated tokens: 1 tokens; generate speed: 1.0615070130562985 tokens/s
2024-06-05 16:31:52,253 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:52,253 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[889/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.9085 tokens/s, remaining time: 0:19:29
pred is:
 ['']
 label is:
 ['the arid plains of Central Asia']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:52,335 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:52,335 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 285, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:52,335 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:52,336 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:52,336 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:53,278 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:53,280 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9441289901733398 s; generated tokens: 1 tokens; generate speed: 1.0591773056522735 tokens/s
2024-06-05 16:31:53,285 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:53,285 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[890/2067], cost time 0.9556s, every example cost time is 0.9556, generate speed: 1.0465 tokens/s, avg speed: 1.9076 tokens/s, remaining time: 0:19:28
pred is:
 ['']
 label is:
 ['commonly present']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.27381047644205, Em score: 1.6853932584269662, current_count: 890
2024-06-05 16:31:53,519 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:53,520 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 174, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:53,520 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:53,520 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:53,521 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:54,461 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:54,463 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418537616729736 s; generated tokens: 1 tokens; generate speed: 1.0617359516871747 tokens/s
2024-06-05 16:31:54,467 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:54,467 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[891/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9066 tokens/s, remaining time: 0:19:27
pred is:
 ['']
 label is:
 ['Genoese traders']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:54,548 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:54,548 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:54,549 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:54,549 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:54,549 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:55,489 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:55,491 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420275688171387 s; generated tokens: 1 tokens; generate speed: 1.0615400579578098 tokens/s
2024-06-05 16:31:55,496 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:55,496 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[892/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9057 tokens/s, remaining time: 0:19:26
pred is:
 ['']
 label is:
 ['northwest across Europe']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:55,577 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:55,577 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 222, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:55,578 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:55,578 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:55,578 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:56,519 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:56,521 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427084922790527 s; generated tokens: 1 tokens; generate speed: 1.0607733018108723 tokens/s
2024-06-05 16:31:56,525 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:56,526 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[893/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.9048 tokens/s, remaining time: 0:19:25
pred is:
 ['']
 label is:
 ['serious depopulation and permanent change in both economic and social structures']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:56,607 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:56,608 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:56,608 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:56,608 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:56,608 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:57,548 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:57,550 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417085647583008 s; generated tokens: 1 tokens; generate speed: 1.06189965497092 tokens/s
2024-06-05 16:31:57,555 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:57,555 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[894/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.9039 tokens/s, remaining time: 0:19:23
pred is:
 ['']
 label is:
 ['Gasquet']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:57,636 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:57,636 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 196, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:57,636 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:57,636 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:57,637 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:58,577 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:58,579 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422683715820312 s; generated tokens: 1 tokens; generate speed: 1.0612687745435407 tokens/s
2024-06-05 16:31:58,584 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:58,584 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[895/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.9030 tokens/s, remaining time: 0:19:22
pred is:
 ['']
 label is:
 ['the heavens']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:58,664 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:58,664 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 321, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:58,665 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:58,665 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:58,665 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:31:59,607 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:59,609 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438581466674805 s; generated tokens: 1 tokens; generate speed: 1.0594812404075145 tokens/s
2024-06-05 16:31:59,614 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:31:59,614 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[896/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0473 tokens/s, avg speed: 1.9020 tokens/s, remaining time: 0:19:21
pred is:
 ['']
 label is:
 ['Yersinia pestis']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:31:59,695 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:31:59,696 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 164, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:31:59,696 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:31:59,696 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:31:59,696 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:00,637 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:00,638 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418320655822754 s; generated tokens: 1 tokens; generate speed: 1.0617604098898066 tokens/s
2024-06-05 16:32:00,643 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:00,643 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[897/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.9011 tokens/s, remaining time: 0:19:20
pred is:
 ['']
 label is:
 ['Francis Aidan Gasquet']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:00,724 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:00,724 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 267, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:00,724 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:00,725 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:00,725 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:01,666 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:01,669 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438276290893555 s; generated tokens: 1 tokens; generate speed: 1.0595154975118095 tokens/s
2024-06-05 16:32:01,673 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:01,674 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[898/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0475 tokens/s, avg speed: 1.9002 tokens/s, remaining time: 0:19:19
pred is:
 ['']
 label is:
 ['30–75%']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:01,754 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:01,755 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 226, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:01,755 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:01,755 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:01,755 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:02,696 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:02,698 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422910213470459 s; generated tokens: 1 tokens; generate speed: 1.0612432649209123 tokens/s
2024-06-05 16:32:02,703 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:02,703 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[899/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.8993 tokens/s, remaining time: 0:19:18
pred is:
 ['']
 label is:
 ['In October 2010']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:02,784 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:02,784 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 293, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:02,784 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:02,784 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:02,785 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:03,727 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:03,729 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445126056671143 s; generated tokens: 1 tokens; generate speed: 1.0587471188843423 tokens/s
2024-06-05 16:32:03,734 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:03,734 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[900/2067], cost time 0.9553s, every example cost time is 0.9553, generate speed: 1.0468 tokens/s, avg speed: 1.8984 tokens/s, remaining time: 0:19:17
pred is:
 ['']
 label is:
 ['genetic branches']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.2374348044815826, Em score: 1.6666666666666667, current_count: 900
2024-06-05 16:32:03,976 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:03,977 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:03,977 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:03,977 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:03,977 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:04,917 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:04,919 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414443969726562 s; generated tokens: 1 tokens; generate speed: 1.062197622308484 tokens/s
2024-06-05 16:32:04,924 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:04,924 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[901/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.8975 tokens/s, remaining time: 0:19:16
pred is:
 ['']
 label is:
 ['confirmed and amended']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:05,005 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:05,006 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 188, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:05,006 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:05,006 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:05,006 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:05,946 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:05,948 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941697359085083 s; generated tokens: 1 tokens; generate speed: 1.0619122909844003 tokens/s
2024-06-05 16:32:05,953 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:05,953 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[902/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.8966 tokens/s, remaining time: 0:19:15
pred is:
 ['']
 label is:
 ['British bacteriologist J. F. D. Shrewsbury']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:06,035 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:06,035 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 149, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:06,035 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:06,036 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:06,036 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:06,976 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:06,978 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941943883895874 s; generated tokens: 1 tokens; generate speed: 1.0616343681366731 tokens/s
2024-06-05 16:32:06,983 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:06,983 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[903/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.8957 tokens/s, remaining time: 0:19:14
pred is:
 ['']
 label is:
 ['epidemiological account of the plague']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:07,065 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:07,065 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 289, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:07,066 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:07,066 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:07,066 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:08,008 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:08,010 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438872337341309 s; generated tokens: 1 tokens; generate speed: 1.0594485911668499 tokens/s
2024-06-05 16:32:08,015 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:08,015 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[904/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.8948 tokens/s, remaining time: 0:19:13
pred is:
 ['']
 label is:
 ['the rat population was insufficient']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:08,097 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:08,097 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 374, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:08,097 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:08,098 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:08,098 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:09,041 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:09,043 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9453237056732178 s; generated tokens: 1 tokens; generate speed: 1.0578387001179075 tokens/s
2024-06-05 16:32:09,048 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:09,048 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[905/2067], cost time 0.9562s, every example cost time is 0.9562, generate speed: 1.0458 tokens/s, avg speed: 1.8939 tokens/s, remaining time: 0:19:12
pred is:
 ['']
 label is:
 ['a form of anthrax']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:09,129 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:09,129 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 358, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:09,130 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:09,130 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:09,130 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:10,073 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:10,075 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9448931217193604 s; generated tokens: 1 tokens; generate speed: 1.0583207529126313 tokens/s
2024-06-05 16:32:10,080 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:10,080 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[906/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0463 tokens/s, avg speed: 1.8930 tokens/s, remaining time: 0:19:11
pred is:
 ['']
 label is:
 ['about a third.']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:10,161 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:10,161 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 256, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:10,162 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:10,162 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:10,162 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:11,103 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:11,105 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431624412536621 s; generated tokens: 1 tokens; generate speed: 1.0602627461190977 tokens/s
2024-06-05 16:32:11,110 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:11,110 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[907/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0483 tokens/s, avg speed: 1.8921 tokens/s, remaining time: 0:19:10
pred is:
 ['']
 label is:
 ['throughout the 14th to 17th centuries']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:11,191 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:11,191 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 272, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:11,191 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:11,192 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:11,192 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:12,134 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:12,136 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439451694488525 s; generated tokens: 1 tokens; generate speed: 1.0593835662974753 tokens/s
2024-06-05 16:32:12,141 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:12,141 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[908/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0473 tokens/s, avg speed: 1.8912 tokens/s, remaining time: 0:19:09
pred is:
 ['']
 label is:
 ['propose a range of preincident population figures from as high as 7 million to as low as 4 million']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:12,223 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:12,223 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 325, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:12,223 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:12,223 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:12,224 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:13,166 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:13,168 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438192844390869 s; generated tokens: 1 tokens; generate speed: 1.0595248650744633 tokens/s
2024-06-05 16:32:13,172 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:13,173 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[909/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.8903 tokens/s, remaining time: 0:19:08
pred is:
 ['']
 label is:
 ['40,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:13,265 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:13,265 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:13,266 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:13,266 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:13,266 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:14,207 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:14,209 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427425861358643 s; generated tokens: 1 tokens; generate speed: 1.0607349394269159 tokens/s
2024-06-05 16:32:14,214 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:14,214 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[910/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.8894 tokens/s, remaining time: 0:19:07
pred is:
 ['']
 label is:
 ['some 1.7 million victims']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.201858597838928, Em score: 1.6483516483516483, current_count: 910
2024-06-05 16:32:14,453 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:14,453 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 218, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:14,454 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:14,454 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:14,454 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:15,395 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:15,397 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427893161773682 s; generated tokens: 1 tokens; generate speed: 1.0606823633243938 tokens/s
2024-06-05 16:32:15,402 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:15,402 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[911/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.8885 tokens/s, remaining time: 0:19:06
pred is:
 ['']
 label is:
 ['between 1500 and 1850']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:15,483 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:15,483 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 268, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:15,483 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:15,483 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:15,484 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:16,425 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:16,427 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432730674743652 s; generated tokens: 1 tokens; generate speed: 1.060138399453641 tokens/s
2024-06-05 16:32:16,432 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:16,432 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[912/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.8876 tokens/s, remaining time: 0:19:05
pred is:
 ['']
 label is:
 ['melt (magma and/or lava)']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:16,518 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:16,518 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:16,518 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:16,519 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:16,519 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:17,460 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:17,462 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426674842834473 s; generated tokens: 1 tokens; generate speed: 1.0608194476551114 tokens/s
2024-06-05 16:32:17,466 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:17,466 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[913/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.8867 tokens/s, remaining time: 0:19:04
pred is:
 ['']
 label is:
 ['seafloor spreading']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:17,548 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:17,548 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 255, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:17,548 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:17,549 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:17,549 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:18,490 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:18,492 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429144859313965 s; generated tokens: 1 tokens; generate speed: 1.0605415601524197 tokens/s
2024-06-05 16:32:18,497 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:18,497 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[914/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.8858 tokens/s, remaining time: 0:19:03
pred is:
 ['']
 label is:
 ['divergent boundaries']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:18,578 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:18,578 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 225, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:18,578 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:18,578 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:18,579 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:19,520 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:19,522 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428822994232178 s; generated tokens: 1 tokens; generate speed: 1.060577763111814 tokens/s
2024-06-05 16:32:19,526 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:19,527 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[915/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.8850 tokens/s, remaining time: 0:19:02
pred is:
 ['']
 label is:
 ['seismic waves']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:19,607 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:19,607 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 217, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:19,607 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:19,608 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:19,608 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:20,548 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:20,578 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:20,608 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:20,637 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:20,666 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:20,695 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:20,724 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:20,753 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:20,782 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:20,811 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:21,077 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.468818187713623 s; generated tokens: 19 tokens; generate speed: 12.935569670181977 tokens/s
2024-06-05 16:32:21,082 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:21,082 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[916/2067], cost time 1.4798s, every example cost time is 1.4798, generate speed: 12.8392 tokens/s, avg speed: 1.9028 tokens/s, remaining time: 0:19:01
pred is:
 ['The second timeline is needed because the first timeline compresses the most recent eon.']
 label is:
 ['second scale shows the most recent eon with an expanded scale']
The F1/Em of this example is:  {'F1': 32.6530612244898, 'Em': 0.0}
2024-06-05 16:32:21,164 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:21,164 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:21,165 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:21,165 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:21,165 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:22,105 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:22,135 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:22,164 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:22,193 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:22,222 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:22,251 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:22,279 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:22,308 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:22,338 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:22,367 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:22,661 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4959614276885986 s; generated tokens: 20 tokens; generate speed: 13.369328667051185 tokens/s
2024-06-05 16:32:22,666 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:22,667 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[917/2067], cost time 1.5074s, every example cost time is 1.5074, generate speed: 13.2679 tokens/s, avg speed: 1.9216 tokens/s, remaining time: 0:19:01
pred is:
 ['The principle of cross-cutting relationships']
 label is:
 ['The principle of cross-cutting relationships']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:32:22,748 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:22,749 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 181, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:22,749 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:22,749 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:22,749 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:23,690 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:23,691 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416911602020264 s; generated tokens: 1 tokens; generate speed: 1.0619192812487104 tokens/s
2024-06-05 16:32:23,696 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:23,696 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[918/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.9207 tokens/s, remaining time: 0:19:00
pred is:
 ['']
 label is:
 ['xenoliths']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:23,777 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:23,777 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 191, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:23,778 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:23,778 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:23,778 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:24,718 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:24,720 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941591739654541 s; generated tokens: 1 tokens; generate speed: 1.0620314069098442 tokens/s
2024-06-05 16:32:24,725 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:24,725 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[919/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.9198 tokens/s, remaining time: 0:18:59
pred is:
 ['']
 label is:
 ['The principle of faunal succession']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:24,805 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:24,806 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 166, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:24,806 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:24,806 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:24,806 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:25,746 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:25,748 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416437149047852 s; generated tokens: 1 tokens; generate speed: 1.0619727867042745 tokens/s
2024-06-05 16:32:25,753 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:25,753 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[920/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.9189 tokens/s, remaining time: 0:18:58
pred is:
 ['']
 label is:
 ['At the beginning of the 20th century']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.311243897019472, Em score: 1.7391304347826086, current_count: 920
2024-06-05 16:32:25,995 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:25,995 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 236, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:25,996 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:25,996 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:25,996 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:26,937 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:26,939 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424488544464111 s; generated tokens: 1 tokens; generate speed: 1.0610655371716633 tokens/s
2024-06-05 16:32:26,944 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:26,944 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[921/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.9180 tokens/s, remaining time: 0:18:57
pred is:
 ['']
 label is:
 ['Thermochemical techniques']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:27,025 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:27,025 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 329, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:27,026 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:27,026 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:27,026 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:27,968 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:27,970 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94427490234375 s; generated tokens: 1 tokens; generate speed: 1.0590136384202702 tokens/s
2024-06-05 16:32:27,975 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:27,975 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[922/2067], cost time 0.9555s, every example cost time is 0.9555, generate speed: 1.0466 tokens/s, avg speed: 1.9171 tokens/s, remaining time: 0:18:56
pred is:
 ['']
 label is:
 ['horizontal compression']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:28,063 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:28,064 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 208, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:28,064 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:28,064 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:28,065 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:29,005 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:29,035 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:29,065 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:29,094 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:29,124 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:29,153 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:29,183 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:29,212 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:29,243 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:29,272 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:29,568 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5030207633972168 s; generated tokens: 20 tokens; generate speed: 13.306536068600153 tokens/s
2024-06-05 16:32:29,573 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:29,573 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[923/2067], cost time 1.5144s, every example cost time is 1.5144, generate speed: 13.2068 tokens/s, avg speed: 1.9357 tokens/s, remaining time: 0:18:55
pred is:
 ['True']
 label is:
 ['Extension']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:29,654 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:29,654 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 262, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:29,654 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:29,655 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:29,655 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:30,596 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:30,598 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430975914001465 s; generated tokens: 1 tokens; generate speed: 1.0603356525546574 tokens/s
2024-06-05 16:32:30,603 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:30,603 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[924/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0483 tokens/s, avg speed: 1.9348 tokens/s, remaining time: 0:18:54
pred is:
 ['']
 label is:
 ['Dikes']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:30,684 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:30,684 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 309, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:30,684 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:30,685 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:30,685 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:31,627 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:31,629 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9444587230682373 s; generated tokens: 1 tokens; generate speed: 1.0588075217848878 tokens/s
2024-06-05 16:32:31,634 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:31,634 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[925/2067], cost time 0.9552s, every example cost time is 0.9552, generate speed: 1.0468 tokens/s, avg speed: 1.9339 tokens/s, remaining time: 0:18:53
pred is:
 ['']
 label is:
 ['layered basaltic lava flows']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:31,715 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:31,715 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 163, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:31,716 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:31,716 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:31,716 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:32,656 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:32,658 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416961669921875 s; generated tokens: 1 tokens; generate speed: 1.0619136352588512 tokens/s
2024-06-05 16:32:32,662 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:32,663 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[926/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.9330 tokens/s, remaining time: 0:18:52
pred is:
 ['']
 label is:
 ['the study of rocks']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:32,743 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:32,744 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 206, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:32,744 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:32,744 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:32,744 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:33,685 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:33,687 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942408561706543 s; generated tokens: 1 tokens; generate speed: 1.0611109030983001 tokens/s
2024-06-05 16:32:33,692 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:33,692 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[927/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.9321 tokens/s, remaining time: 0:18:51
pred is:
 ['']
 label is:
 ['identifying rocks']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:33,772 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:33,772 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 147, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:33,773 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:33,773 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:33,773 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:34,713 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:34,715 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413471221923828 s; generated tokens: 1 tokens; generate speed: 1.0623073852618952 tokens/s
2024-06-05 16:32:34,719 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:34,719 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[928/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.9312 tokens/s, remaining time: 0:18:50
pred is:
 ['']
 label is:
 ['pressure physical experiments']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:34,801 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:34,801 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 144, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:34,801 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:34,802 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:34,802 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:35,741 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:35,743 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410607814788818 s; generated tokens: 1 tokens; generate speed: 1.062630618214155 tokens/s
2024-06-05 16:32:35,748 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:35,748 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[929/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.9302 tokens/s, remaining time: 0:18:49
pred is:
 ['']
 label is:
 ['Structural geologists']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:35,829 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:35,829 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:35,829 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:35,829 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:35,830 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:36,771 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:36,772 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425747394561768 s; generated tokens: 1 tokens; generate speed: 1.0609238271937513 tokens/s
2024-06-05 16:32:36,777 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:36,777 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[930/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.9293 tokens/s, remaining time: 0:18:48
pred is:
 ['']
 label is:
 ['orogenic wedges']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.2756391239332414, Em score: 1.7204301075268817, current_count: 930
2024-06-05 16:32:37,021 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:37,021 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 179, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:37,022 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:37,022 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:37,022 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:37,962 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:37,964 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417171478271484 s; generated tokens: 1 tokens; generate speed: 1.061889976525679 tokens/s
2024-06-05 16:32:37,969 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:37,969 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[931/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.9284 tokens/s, remaining time: 0:18:47
pred is:
 ['']
 label is:
 ['stratigraphers']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:38,049 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:38,049 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 168, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:38,050 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:38,050 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:38,050 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:38,990 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:39,021 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:39,050 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:39,079 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:39,108 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:39,137 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:39,166 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:39,195 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:39,225 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:39,254 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:39,398 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.3479821681976318 s; generated tokens: 15 tokens; generate speed: 11.12774364074585 tokens/s
2024-06-05 16:32:39,403 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:39,403 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[932/2067], cost time 1.3589s, every example cost time is 1.3589, generate speed: 11.0386 tokens/s, avg speed: 1.9418 tokens/s, remaining time: 0:18:46
pred is:
 ['To provide better absolute bounds on the timing and rates of deposition.']
 label is:
 ['provide better absolute bounds on the timing and rates of deposition']
The F1/Em of this example is:  {'F1': 93.33333333333333, 'Em': 0.0}
2024-06-05 16:32:39,487 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:39,487 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 287, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:39,487 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:39,488 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:39,488 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:40,429 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:40,431 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943286657333374 s; generated tokens: 1 tokens; generate speed: 1.0601231261204858 tokens/s
2024-06-05 16:32:40,436 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:40,436 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[933/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.9409 tokens/s, remaining time: 0:18:45
pred is:
 ['']
 label is:
 ['Persia']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:40,517 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:40,517 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 165, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:40,518 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:40,518 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:40,518 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:41,458 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:41,459 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410767555236816 s; generated tokens: 1 tokens; generate speed: 1.0626125808872298 tokens/s
2024-06-05 16:32:41,464 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:41,464 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[934/2067], cost time 0.9519s, every example cost time is 0.9519, generate speed: 1.0505 tokens/s, avg speed: 1.9400 tokens/s, remaining time: 0:18:44
pred is:
 ['']
 label is:
 ['James Hutton']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:41,546 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:41,546 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 206, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:41,546 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:41,547 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:41,547 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:42,487 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:42,489 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424173831939697 s; generated tokens: 1 tokens; generate speed: 1.0611009705815013 tokens/s
2024-06-05 16:32:42,494 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:42,494 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[935/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.9391 tokens/s, remaining time: 0:18:43
pred is:
 ['']
 label is:
 ['William Maclure']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:42,575 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:42,575 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:42,575 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:42,576 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:42,576 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:43,516 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:43,552 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:43,583 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:43,612 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:43,642 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:43,671 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:43,700 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:43,729 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:43,758 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:43,787 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:44,079 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5033767223358154 s; generated tokens: 20 tokens; generate speed: 13.303385440826666 tokens/s
2024-06-05 16:32:44,085 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:44,085 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[936/2067], cost time 1.5154s, every example cost time is 1.5154, generate speed: 13.1979 tokens/s, avg speed: 1.9574 tokens/s, remaining time: 0:18:43
pred is:
 ['Principles of Geology']
 label is:
 ['Principles of Geology']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:32:44,166 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:44,167 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 294, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:44,167 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:44,167 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:44,168 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:45,109 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:45,111 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430134296417236 s; generated tokens: 1 tokens; generate speed: 1.0604302850489915 tokens/s
2024-06-05 16:32:45,115 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:45,116 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[937/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.9565 tokens/s, remaining time: 0:18:42
pred is:
 ['']
 label is:
 ['103 miles']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:45,196 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:45,196 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 230, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:45,197 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:45,197 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:45,197 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:46,138 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:46,140 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421882629394531 s; generated tokens: 1 tokens; generate speed: 1.0613590078910398 tokens/s
2024-06-05 16:32:46,144 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:46,144 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[938/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9555 tokens/s, remaining time: 0:18:41
pred is:
 ['']
 label is:
 ['Robert Curthose']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:46,225 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:46,226 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 277, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:46,226 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:46,226 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:46,226 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:47,168 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:47,170 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943061113357544 s; generated tokens: 1 tokens; generate speed: 1.0603766668309955 tokens/s
2024-06-05 16:32:47,174 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:47,175 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[939/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.9546 tokens/s, remaining time: 0:18:40
pred is:
 ['']
 label is:
 ['Pons Aelius']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:47,263 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:47,263 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 189, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:47,264 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:47,264 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:47,264 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:48,204 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:48,206 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419996738433838 s; generated tokens: 1 tokens; generate speed: 1.0615714928222568 tokens/s
2024-06-05 16:32:48,211 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:48,211 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[940/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.9537 tokens/s, remaining time: 0:18:39
pred is:
 ['']
 label is:
 ["England's"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.4464656580757955, Em score: 1.8085106382978724, current_count: 940
2024-06-05 16:32:48,457 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:48,457 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 205, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:48,458 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:48,458 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:48,458 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:49,398 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:49,401 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423892498016357 s; generated tokens: 1 tokens; generate speed: 1.0611326479058316 tokens/s
2024-06-05 16:32:49,405 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:49,406 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[941/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.9528 tokens/s, remaining time: 0:18:38
pred is:
 ['']
 label is:
 ['coal']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:49,486 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:49,486 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 211, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:49,487 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:49,487 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:49,487 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:50,427 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:50,429 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419741630554199 s; generated tokens: 1 tokens; generate speed: 1.0616002425760442 tokens/s
2024-06-05 16:32:50,434 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:50,434 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[942/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.9518 tokens/s, remaining time: 0:18:37
pred is:
 ['']
 label is:
 ['their families']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:50,515 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:50,515 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 188, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:50,516 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:50,516 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:50,516 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:51,456 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:51,458 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941920280456543 s; generated tokens: 1 tokens; generate speed: 1.0616609714734098 tokens/s
2024-06-05 16:32:51,463 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:51,463 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[943/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.9509 tokens/s, remaining time: 0:18:36
pred is:
 ['']
 label is:
 ['the King']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:51,544 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:51,545 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 304, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:51,545 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:51,545 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:51,545 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:52,488 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:52,489 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437026977539062 s; generated tokens: 1 tokens; generate speed: 1.0596557606331805 tokens/s
2024-06-05 16:32:52,494 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:52,494 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[944/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0474 tokens/s, avg speed: 1.9500 tokens/s, remaining time: 0:18:35
pred is:
 ['']
 label is:
 ['urbanization']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:52,576 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:52,576 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 208, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:52,576 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:52,576 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:52,577 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:53,518 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:53,520 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428799152374268 s; generated tokens: 1 tokens; generate speed: 1.0605804449108345 tokens/s
2024-06-05 16:32:53,525 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:53,525 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[945/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.9491 tokens/s, remaining time: 0:18:34
pred is:
 ['']
 label is:
 ['medieval']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:53,606 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:53,606 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 241, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:53,607 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:53,607 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:53,607 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:54,548 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:54,550 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942866325378418 s; generated tokens: 1 tokens; generate speed: 1.060595731424231 tokens/s
2024-06-05 16:32:54,555 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:54,555 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[946/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.9482 tokens/s, remaining time: 0:18:33
pred is:
 ['']
 label is:
 ['Tyneside Classical']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:54,635 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:54,636 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 204, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:54,636 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:54,636 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:54,636 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:55,577 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:55,579 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418902397155762 s; generated tokens: 1 tokens; generate speed: 1.0616948321940052 tokens/s
2024-06-05 16:32:55,583 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:55,583 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[947/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.9473 tokens/s, remaining time: 0:18:32
pred is:
 ['']
 label is:
 ['Town Moor']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:55,664 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:55,664 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 220, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:55,665 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:55,665 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:55,665 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:56,606 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:56,607 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420650005340576 s; generated tokens: 1 tokens; generate speed: 1.061497879056221 tokens/s
2024-06-05 16:32:56,612 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:56,612 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[948/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.9464 tokens/s, remaining time: 0:18:31
pred is:
 ['']
 label is:
 ['Large-scale regeneration']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:56,693 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:56,693 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 190, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:56,693 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:56,693 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:56,694 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:57,633 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:57,635 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413409233093262 s; generated tokens: 1 tokens; generate speed: 1.062314380728775 tokens/s
2024-06-05 16:32:57,640 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:57,640 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[949/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.9454 tokens/s, remaining time: 0:18:29
pred is:
 ['']
 label is:
 ['the Grainger Town area']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:57,721 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:57,721 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:57,721 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:57,722 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:57,722 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:58,662 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:58,664 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422452449798584 s; generated tokens: 1 tokens; generate speed: 1.061294822476261 tokens/s
2024-06-05 16:32:58,669 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:58,669 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[950/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9445 tokens/s, remaining time: 0:18:28
pred is:
 ['']
 label is:
 ['the Butcher Market']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.4101870722013135, Em score: 1.7894736842105263, current_count: 950
2024-06-05 16:32:58,915 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:58,916 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 199, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:58,916 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:58,916 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:58,916 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:32:59,858 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:59,863 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9465017318725586 s; generated tokens: 1 tokens; generate speed: 1.0565221027346674 tokens/s
2024-06-05 16:32:59,868 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:32:59,868 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[951/2067], cost time 0.9581s, every example cost time is 0.9581, generate speed: 1.0438 tokens/s, avg speed: 1.9436 tokens/s, remaining time: 0:18:27
pred is:
 ['']
 label is:
 ['oceanic']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:32:59,949 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:32:59,949 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 311, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:32:59,950 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:32:59,950 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:32:59,950 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:00,892 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:00,894 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436695575714111 s; generated tokens: 1 tokens; generate speed: 1.0596929740677008 tokens/s
2024-06-05 16:33:00,899 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:00,899 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[952/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0474 tokens/s, avg speed: 1.9427 tokens/s, remaining time: 0:18:26
pred is:
 ['']
 label is:
 ['2010']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:00,979 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:00,980 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 152, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:00,980 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:00,980 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:00,980 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:01,920 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:01,922 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412131309509277 s; generated tokens: 1 tokens; generate speed: 1.062458615499423 tokens/s
2024-06-05 16:33:01,926 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:01,927 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[953/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0504 tokens/s, avg speed: 1.9418 tokens/s, remaining time: 0:18:25
pred is:
 ['']
 label is:
 ['shopping']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:02,008 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:02,008 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 185, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:02,009 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:02,009 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:02,009 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:02,952 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:02,954 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9451389312744141 s; generated tokens: 1 tokens; generate speed: 1.0580455072902477 tokens/s
2024-06-05 16:33:02,959 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:02,959 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[954/2067], cost time 0.9564s, every example cost time is 0.9564, generate speed: 1.0456 tokens/s, avg speed: 1.9409 tokens/s, remaining time: 0:18:24
pred is:
 ['']
 label is:
 ['The Tyneside flat']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:03,040 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:03,040 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 192, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:03,040 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:03,041 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:03,041 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:03,981 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:03,983 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421584606170654 s; generated tokens: 1 tokens; generate speed: 1.0613925807608322 tokens/s
2024-06-05 16:33:03,988 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:03,988 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[955/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.9400 tokens/s, remaining time: 0:18:23
pred is:
 ['']
 label is:
 ['7.8%']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:04,068 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:04,068 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 287, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:04,069 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:04,069 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:04,069 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:05,011 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:05,013 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437301158905029 s; generated tokens: 1 tokens; generate speed: 1.0596249745155168 tokens/s
2024-06-05 16:33:05,018 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:05,018 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[956/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0476 tokens/s, avg speed: 1.9391 tokens/s, remaining time: 0:18:22
pred is:
 ['']
 label is:
 ['2001']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:05,098 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:05,099 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 186, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:05,099 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:05,099 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:05,099 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:06,039 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:06,041 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414546489715576 s; generated tokens: 1 tokens; generate speed: 1.062186055475319 tokens/s
2024-06-05 16:33:06,046 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:06,046 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[957/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.9382 tokens/s, remaining time: 0:18:21
pred is:
 ['']
 label is:
 ['37.8']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:06,127 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:06,127 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 269, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:06,127 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:06,128 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:06,128 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:07,069 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:07,071 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94258713722229 s; generated tokens: 1 tokens; generate speed: 1.0609098729555126 tokens/s
2024-06-05 16:33:07,075 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:07,075 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[958/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0488 tokens/s, avg speed: 1.9373 tokens/s, remaining time: 0:18:20
pred is:
 ['']
 label is:
 ['Geordie']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:07,156 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:07,156 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 279, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:07,157 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:07,157 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:07,157 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:08,099 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:08,101 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433498382568359 s; generated tokens: 1 tokens; generate speed: 1.0600521242976464 tokens/s
2024-06-05 16:33:08,105 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:08,106 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[959/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.9364 tokens/s, remaining time: 0:18:19
pred is:
 ['']
 label is:
 ['Scandinavia']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:08,188 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:08,188 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 166, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:08,188 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:08,189 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:08,189 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:09,129 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:09,131 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416632652282715 s; generated tokens: 1 tokens; generate speed: 1.0619507385770082 tokens/s
2024-06-05 16:33:09,135 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:09,135 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[960/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.9356 tokens/s, remaining time: 0:18:18
pred is:
 ['']
 label is:
 ['a report']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.3746642901992163, Em score: 1.7708333333333333, current_count: 960
2024-06-05 16:33:09,383 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:09,383 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 207, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:09,384 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:09,384 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:09,384 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:10,324 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:10,326 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420855045318604 s; generated tokens: 1 tokens; generate speed: 1.061474776110602 tokens/s
2024-06-05 16:33:10,331 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:10,331 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[961/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.9347 tokens/s, remaining time: 0:18:17
pred is:
 ['']
 label is:
 ['Collingwood Street']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:10,412 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:10,412 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 157, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:10,413 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:10,413 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:10,413 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:11,353 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:11,354 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941295862197876 s; generated tokens: 1 tokens; generate speed: 1.062365235161082 tokens/s
2024-06-05 16:33:11,359 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:11,359 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[962/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.9338 tokens/s, remaining time: 0:18:16
pred is:
 ['']
 label is:
 ['theatre']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:11,440 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:11,440 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 212, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:11,440 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:11,441 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:11,441 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:12,381 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:12,383 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418232440948486 s; generated tokens: 1 tokens; generate speed: 1.0617703547559636 tokens/s
2024-06-05 16:33:12,387 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:12,388 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[963/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.9329 tokens/s, remaining time: 0:18:15
pred is:
 ['']
 label is:
 ['theatres']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:12,468 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:12,468 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 169, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:12,469 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:12,469 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:12,469 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:13,409 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:13,411 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415624141693115 s; generated tokens: 1 tokens; generate speed: 1.0620644844688758 tokens/s
2024-06-05 16:33:13,415 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:13,416 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[964/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.9320 tokens/s, remaining time: 0:18:14
pred is:
 ['']
 label is:
 ['The Literary and Philosophical Society of Newcastle']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:13,497 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:13,497 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:13,498 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:13,498 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:13,498 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:14,438 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:14,440 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415757656097412 s; generated tokens: 1 tokens; generate speed: 1.0620494245117118 tokens/s
2024-06-05 16:33:14,444 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:14,445 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[965/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.9312 tokens/s, remaining time: 0:18:13
pred is:
 ['']
 label is:
 ['The Newcastle Beer Festival']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:14,525 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:14,525 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 212, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:14,526 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:14,526 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:14,526 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:15,466 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:15,469 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422464370727539 s; generated tokens: 1 tokens; generate speed: 1.0612934797680607 tokens/s
2024-06-05 16:33:15,473 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:15,473 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[966/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.9303 tokens/s, remaining time: 0:18:12
pred is:
 ['']
 label is:
 ['The Hoppings']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:15,554 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:15,554 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 174, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:15,554 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:15,555 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:15,555 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:16,495 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:16,496 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414565563201904 s; generated tokens: 1 tokens; generate speed: 1.0621839035341518 tokens/s
2024-06-05 16:33:16,501 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:16,501 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[967/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.9294 tokens/s, remaining time: 0:18:11
pred is:
 ['']
 label is:
 ['Newcastle Mela']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:16,582 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:16,582 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 216, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:16,583 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:16,583 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:16,583 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:17,523 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:17,525 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422054290771484 s; generated tokens: 1 tokens; generate speed: 1.0613396708820273 tokens/s
2024-06-05 16:33:17,530 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:17,530 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[968/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.9285 tokens/s, remaining time: 0:18:10
pred is:
 ['']
 label is:
 ['folk-rock']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:17,611 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:17,611 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 156, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:17,612 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:17,612 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:17,612 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:18,552 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:18,582 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:18,612 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:18,641 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:18,670 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:18,699 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:18,728 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:18,757 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:18,786 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:18,815 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:19,106 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4930260181427002 s; generated tokens: 20 tokens; generate speed: 13.39561384528293 tokens/s
2024-06-05 16:33:19,110 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:19,111 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[969/2067], cost time 1.5042s, every example cost time is 1.5042, generate speed: 13.2957 tokens/s, avg speed: 1.9463 tokens/s, remaining time: 0:18:09
pred is:
 ['November 2006 and May 2008']
 label is:
 ['November 2006 and May 2008']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:33:19,192 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:19,193 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 155, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:19,193 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:19,193 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:19,193 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:20,134 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:20,136 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420170783996582 s; generated tokens: 1 tokens; generate speed: 1.0615518793978191 tokens/s
2024-06-05 16:33:20,140 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:20,140 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[970/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9454 tokens/s, remaining time: 0:18:08
pred is:
 ['']
 label is:
 ['Centre for Life']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.4429667201971625, Em score: 1.8556701030927836, current_count: 970
2024-06-05 16:33:20,391 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:20,391 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:20,391 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:20,392 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:20,392 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:21,332 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:21,334 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941723108291626 s; generated tokens: 1 tokens; generate speed: 1.0618832554869486 tokens/s
2024-06-05 16:33:21,338 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:21,339 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[971/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.9445 tokens/s, remaining time: 0:18:07
pred is:
 ['']
 label is:
 ['On the Night of the Fire']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:21,419 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:21,419 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 249, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:21,419 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:21,420 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:21,420 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:22,361 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:22,363 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429154396057129 s; generated tokens: 1 tokens; generate speed: 1.0605404875098423 tokens/s
2024-06-05 16:33:22,367 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:22,368 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[972/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.9436 tokens/s, remaining time: 0:18:06
pred is:
 ['']
 label is:
 ['Gosforth Park']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:22,450 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:22,450 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 183, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:22,451 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:22,451 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:22,451 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:23,391 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:23,393 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420011043548584 s; generated tokens: 1 tokens; generate speed: 1.0615698807326377 tokens/s
2024-06-05 16:33:23,398 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:23,398 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[973/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9428 tokens/s, remaining time: 0:18:05
pred is:
 ['']
 label is:
 ['6 miles']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:23,479 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:23,479 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:23,480 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:23,480 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:23,480 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:24,421 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:24,423 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427638053894043 s; generated tokens: 1 tokens; generate speed: 1.0607110649384281 tokens/s
2024-06-05 16:33:24,428 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:24,428 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[974/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.9419 tokens/s, remaining time: 0:18:04
pred is:
 ['']
 label is:
 ['Victorian architecture']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:24,509 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:24,509 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:24,509 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:24,509 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:24,510 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:25,450 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:25,452 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418234825134277 s; generated tokens: 1 tokens; generate speed: 1.0617700859733479 tokens/s
2024-06-05 16:33:25,456 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:25,457 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[975/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.9410 tokens/s, remaining time: 0:18:03
pred is:
 ['']
 label is:
 ['half-hourly']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:25,537 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:25,537 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 252, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:25,538 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:25,538 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:25,538 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:26,479 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:26,482 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433157444000244 s; generated tokens: 1 tokens; generate speed: 1.0600904373074238 tokens/s
2024-06-05 16:33:26,486 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:26,486 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[976/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.9401 tokens/s, remaining time: 0:18:02
pred is:
 ['']
 label is:
 ['Tyne and Wear Metro']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:26,567 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:26,568 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 223, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:26,568 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:26,568 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:26,568 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:27,509 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:27,511 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428408145904541 s; generated tokens: 1 tokens; generate speed: 1.0606244283499484 tokens/s
2024-06-05 16:33:27,516 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:27,516 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[977/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.9392 tokens/s, remaining time: 0:18:01
pred is:
 ['']
 label is:
 ["Metro: All Change.'"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:27,601 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:27,601 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 284, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:27,602 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:27,602 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:27,602 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:28,544 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:28,546 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436006546020508 s; generated tokens: 1 tokens; generate speed: 1.0597703542519634 tokens/s
2024-06-05 16:33:28,550 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:28,551 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[978/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0474 tokens/s, avg speed: 1.9384 tokens/s, remaining time: 0:18:00
pred is:
 ['']
 label is:
 ['the A1']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:28,632 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:28,632 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 242, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:28,633 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:28,633 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:28,633 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:29,574 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:29,576 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428596496582031 s; generated tokens: 1 tokens; generate speed: 1.0606032407501063 tokens/s
2024-06-05 16:33:29,581 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:29,581 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[979/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.9375 tokens/s, remaining time: 0:17:59
pred is:
 ['']
 label is:
 ['3']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:29,669 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:29,669 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 191, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:29,670 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:29,670 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:29,670 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:30,611 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:30,613 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426224231719971 s; generated tokens: 1 tokens; generate speed: 1.0608701590557574 tokens/s
2024-06-05 16:33:30,618 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:30,618 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[980/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.9366 tokens/s, remaining time: 0:17:58
pred is:
 ['']
 label is:
 ['1998']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.407834406725763, Em score: 1.836734693877551, current_count: 980
2024-06-05 16:33:30,873 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:30,874 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:30,874 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:30,874 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:30,875 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:31,816 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:31,818 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432411193847656 s; generated tokens: 1 tokens; generate speed: 1.0601743069176794 tokens/s
2024-06-05 16:33:31,823 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:31,823 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[981/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0475 tokens/s, avg speed: 1.9358 tokens/s, remaining time: 0:17:57
pred is:
 ['']
 label is:
 ['Danish DFDS Seaways']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:31,904 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:31,904 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 258, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:31,905 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:31,905 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:31,905 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:32,847 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:32,849 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434618949890137 s; generated tokens: 1 tokens; generate speed: 1.0599262199260784 tokens/s
2024-06-05 16:33:32,854 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:32,854 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[982/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0476 tokens/s, avg speed: 1.9349 tokens/s, remaining time: 0:17:56
pred is:
 ['']
 label is:
 ['eleven']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:32,936 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:32,936 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 227, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:32,937 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:32,937 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:32,937 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:33,879 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:33,880 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433374404907227 s; generated tokens: 1 tokens; generate speed: 1.0600660559807755 tokens/s
2024-06-05 16:33:33,885 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:33,885 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[983/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0474 tokens/s, avg speed: 1.9340 tokens/s, remaining time: 0:17:55
pred is:
 ['']
 label is:
 ['two']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:33,966 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:33,967 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 169, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:33,967 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:33,967 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:33,967 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:34,907 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:34,909 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416656494140625 s; generated tokens: 1 tokens; generate speed: 1.061948049843631 tokens/s
2024-06-05 16:33:34,914 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:34,914 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[984/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.9331 tokens/s, remaining time: 0:17:54
pred is:
 ['']
 label is:
 ['three']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:34,996 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:34,996 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 238, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:34,997 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:34,997 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:34,997 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:35,939 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:35,976 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:36,006 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:36,035 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:36,064 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:36,093 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:36,122 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:36,151 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:36,180 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:36,210 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:36,518 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.521164894104004 s; generated tokens: 20 tokens; generate speed: 13.147818541907906 tokens/s
2024-06-05 16:33:36,523 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:36,524 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[985/2067], cost time 1.5328s, every example cost time is 1.5328, generate speed: 13.0481 tokens/s, avg speed: 1.9506 tokens/s, remaining time: 0:17:53
pred is:
 ['The Parish Church of St Andrew']
 label is:
 ['The Parish Church of St Andrew']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:33:36,605 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:36,605 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 196, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:36,606 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:36,606 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:36,606 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:37,546 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:37,548 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414458274841309 s; generated tokens: 1 tokens; generate speed: 1.0621960083166402 tokens/s
2024-06-05 16:33:37,552 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:37,553 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[986/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.9497 tokens/s, remaining time: 0:17:52
pred is:
 ['']
 label is:
 ['City Road']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:37,634 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:37,634 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:37,635 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:37,635 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:37,635 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:38,575 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:38,577 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417097568511963 s; generated tokens: 1 tokens; generate speed: 1.0618983107318642 tokens/s
2024-06-05 16:33:38,582 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:38,582 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[987/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.9488 tokens/s, remaining time: 0:17:51
pred is:
 ['']
 label is:
 ['NE1fm']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:38,664 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:38,664 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 282, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:38,664 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:38,665 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:38,665 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:39,607 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:39,609 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436845779418945 s; generated tokens: 1 tokens; generate speed: 1.0596761072231626 tokens/s
2024-06-05 16:33:39,613 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:39,614 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[988/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0472 tokens/s, avg speed: 1.9479 tokens/s, remaining time: 0:17:50
pred is:
 ['']
 label is:
 ['1770']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:39,695 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:39,695 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:39,696 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:39,696 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:39,696 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:40,636 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:40,638 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414238929748535 s; generated tokens: 1 tokens; generate speed: 1.0622207567305828 tokens/s
2024-06-05 16:33:40,642 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:40,643 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[989/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.9471 tokens/s, remaining time: 0:17:49
pred is:
 ['']
 label is:
 ['Rutherford Grammar School']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:40,724 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:40,724 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 214, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:40,724 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:40,725 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:40,725 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:41,666 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:41,667 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423234462738037 s; generated tokens: 1 tokens; generate speed: 1.0612067480165803 tokens/s
2024-06-05 16:33:41,672 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:41,672 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[990/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.9462 tokens/s, remaining time: 0:17:48
pred is:
 ['']
 label is:
 ['The V&A is located in the Brompton district of the Royal Borough of Kensington and Chelsea']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.4744219379709573, Em score: 1.9191919191919191, current_count: 990
2024-06-05 16:33:41,961 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:41,962 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 239, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:41,962 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:41,962 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:41,962 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:42,903 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:42,905 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428517818450928 s; generated tokens: 1 tokens; generate speed: 1.0606120911635468 tokens/s
2024-06-05 16:33:42,910 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:42,910 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[991/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.9453 tokens/s, remaining time: 0:17:47
pred is:
 ['']
 label is:
 ['12.5']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:42,991 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:42,991 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 246, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:42,992 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:42,992 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:42,992 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:43,934 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:43,964 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:43,993 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:44,023 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:44,052 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:44,081 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:44,110 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:44,139 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:44,169 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:44,198 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:44,490 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4974291324615479 s; generated tokens: 20 tokens; generate speed: 13.356224723051175 tokens/s
2024-06-05 16:33:44,495 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:44,495 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[992/2067], cost time 1.5086s, every example cost time is 1.5086, generate speed: 13.2576 tokens/s, avg speed: 1.9627 tokens/s, remaining time: 0:17:47
pred is:
 ['The Great Exhibition of 1851']
 label is:
 ['Great Exhibition of 1851']
The F1/Em of this example is:  {'F1': 87.50000000000001, 'Em': 0.0}
2024-06-05 16:33:44,576 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:44,576 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 308, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:44,576 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:44,577 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:44,577 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:45,519 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:45,521 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439682960510254 s; generated tokens: 1 tokens; generate speed: 1.0593576120971184 tokens/s
2024-06-05 16:33:45,526 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:45,526 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[993/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.9618 tokens/s, remaining time: 0:17:46
pred is:
 ['']
 label is:
 ['Queen Victoria']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:45,607 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:45,607 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 154, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:45,607 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:45,607 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:45,608 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:46,547 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:46,549 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413070678710938 s; generated tokens: 1 tokens; generate speed: 1.0623525883659293 tokens/s
2024-06-05 16:33:46,554 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:46,554 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[994/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.9609 tokens/s, remaining time: 0:17:45
pred is:
 ['']
 label is:
 ['between September and November 1946']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:46,635 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:46,635 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:46,636 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:46,636 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:46,636 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:47,577 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:47,579 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422035217285156 s; generated tokens: 1 tokens; generate speed: 1.0613418194037887 tokens/s
2024-06-05 16:33:47,583 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:47,584 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[995/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9600 tokens/s, remaining time: 0:17:44
pred is:
 ['']
 label is:
 ['a rock concert']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:47,665 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:47,665 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 214, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:47,666 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:47,666 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:47,666 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:48,607 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:48,609 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425060749053955 s; generated tokens: 1 tokens; generate speed: 1.0610011188526032 tokens/s
2024-06-05 16:33:48,614 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:48,614 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[996/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.9591 tokens/s, remaining time: 0:17:43
pred is:
 ['']
 label is:
 ['Dundee']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:48,694 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:48,695 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 346, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:48,695 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:48,695 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:48,695 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:49,638 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:49,640 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9441893100738525 s; generated tokens: 1 tokens; generate speed: 1.0591096396990367 tokens/s
2024-06-05 16:33:49,644 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:49,645 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[997/2067], cost time 0.9551s, every example cost time is 0.9551, generate speed: 1.0471 tokens/s, avg speed: 1.9583 tokens/s, remaining time: 0:17:42
pred is:
 ['']
 label is:
 ['Brompton Park House']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:49,725 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:49,725 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 502, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:49,726 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:49,726 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:49,726 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:50,671 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:50,672 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9459426403045654 s; generated tokens: 1 tokens; generate speed: 1.0571465513786646 tokens/s
2024-06-05 16:33:50,677 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:50,677 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[998/2067], cost time 0.9570s, every example cost time is 0.9570, generate speed: 1.0449 tokens/s, avg speed: 1.9574 tokens/s, remaining time: 0:17:41
pred is:
 ['']
 label is:
 ['Oriental Courts']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:50,788 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:50,788 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 324, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:50,789 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:50,789 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:50,789 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:51,732 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:51,734 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9447400569915771 s; generated tokens: 1 tokens; generate speed: 1.0584922197375564 tokens/s
2024-06-05 16:33:51,739 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:51,739 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[999/2067], cost time 0.9563s, every example cost time is 0.9563, generate speed: 1.0457 tokens/s, avg speed: 1.9565 tokens/s, remaining time: 0:17:40
pred is:
 ['']
 label is:
 ['Philip Webb and William Morris']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:51,820 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:51,821 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 245, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:51,821 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:51,821 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:51,821 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:52,763 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:52,765 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431924819946289 s; generated tokens: 1 tokens; generate speed: 1.0602289766827198 tokens/s
2024-06-05 16:33:52,769 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:52,770 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1000/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0477 tokens/s, avg speed: 1.9556 tokens/s, remaining time: 0:17:39
pred is:
 ['']
 label is:
 ['Henry Young Darracott Scott']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.527177718591248, Em score: 1.9, current_count: 1000
2024-06-05 16:33:53,024 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:53,024 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 359, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:53,025 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:53,025 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:53,025 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:53,968 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:53,971 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9453315734863281 s; generated tokens: 1 tokens; generate speed: 1.057829895929592 tokens/s
2024-06-05 16:33:53,975 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:53,976 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1001/2067], cost time 0.9565s, every example cost time is 0.9565, generate speed: 1.0454 tokens/s, avg speed: 1.9547 tokens/s, remaining time: 0:17:37
pred is:
 ['']
 label is:
 ['sgraffito']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:54,056 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:54,056 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 252, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:54,056 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:54,057 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:54,057 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:54,998 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:55,000 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434103965759277 s; generated tokens: 1 tokens; generate speed: 1.0599840786464323 tokens/s
2024-06-05 16:33:55,005 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:55,005 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1002/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0478 tokens/s, avg speed: 1.9539 tokens/s, remaining time: 0:17:36
pred is:
 ['']
 label is:
 ['Aston Webb']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:55,115 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:55,115 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:55,116 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:55,116 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:55,116 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:56,057 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:56,058 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420297145843506 s; generated tokens: 1 tokens; generate speed: 1.0615376399684244 tokens/s
2024-06-05 16:33:56,063 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:56,063 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1003/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.9530 tokens/s, remaining time: 0:17:35
pred is:
 ['']
 label is:
 ['Alfred Drury']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:56,144 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:56,145 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 339, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:56,145 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:56,145 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:56,145 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:57,088 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:57,090 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9446454048156738 s; generated tokens: 1 tokens; generate speed: 1.0585982792084057 tokens/s
2024-06-05 16:33:57,095 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:57,095 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1004/2067], cost time 0.9556s, every example cost time is 0.9556, generate speed: 1.0464 tokens/s, avg speed: 1.9521 tokens/s, remaining time: 0:17:34
pred is:
 ['']
 label is:
 ['Art Library']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:57,176 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:57,176 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 471, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:57,177 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:57,177 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:57,177 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:58,122 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:58,152 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:58,182 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:58,212 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:58,241 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:58,270 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:58,299 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:58,328 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:58,358 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:58,387 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:58,697 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5197865962982178 s; generated tokens: 20 tokens; generate speed: 13.159742327452092 tokens/s
2024-06-05 16:33:58,702 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:58,702 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1005/2067], cost time 1.5308s, every example cost time is 1.5308, generate speed: 13.0653 tokens/s, avg speed: 1.9692 tokens/s, remaining time: 0:17:34
pred is:
 ['The main silverware gallery']
 label is:
 ['main silverware gallery']
The F1/Em of this example is:  {'F1': 83.33333333333333, 'Em': 0.0}
2024-06-05 16:33:58,783 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:58,784 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 228, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:58,784 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:58,784 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:58,784 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:33:59,725 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:59,727 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422271251678467 s; generated tokens: 1 tokens; generate speed: 1.0613152320592147 tokens/s
2024-06-05 16:33:59,731 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:33:59,732 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1006/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9683 tokens/s, remaining time: 0:17:33
pred is:
 ['']
 label is:
 ['Kim Wilkie']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:33:59,843 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:33:59,843 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 175, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:33:59,843 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:33:59,844 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:33:59,844 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:00,783 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:00,785 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413232803344727 s; generated tokens: 1 tokens; generate speed: 1.0623342914080254 tokens/s
2024-06-05 16:34:00,790 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:00,790 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1007/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.9674 tokens/s, remaining time: 0:17:32
pred is:
 ['']
 label is:
 ['2004']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:00,871 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:00,871 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 282, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:00,872 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:00,872 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:00,872 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:01,814 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:01,815 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430999755859375 s; generated tokens: 1 tokens; generate speed: 1.0603329719934635 tokens/s
2024-06-05 16:34:01,820 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:01,820 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1008/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.9665 tokens/s, remaining time: 0:17:31
pred is:
 ['']
 label is:
 ['Andrea Palladio']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:01,902 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:01,902 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 251, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:01,903 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:01,903 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:01,903 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:02,844 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:02,846 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427955150604248 s; generated tokens: 1 tokens; generate speed: 1.0606753893349916 tokens/s
2024-06-05 16:34:02,851 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:02,851 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1009/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.9657 tokens/s, remaining time: 0:17:30
pred is:
 ['']
 label is:
 ['Bishopsgate']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:02,932 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:02,932 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 320, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:02,933 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:02,933 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:02,933 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:03,876 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:03,878 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445319175720215 s; generated tokens: 1 tokens; generate speed: 1.0587254717347856 tokens/s
2024-06-05 16:34:03,882 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:03,883 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1010/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0463 tokens/s, avg speed: 1.9648 tokens/s, remaining time: 0:17:29
pred is:
 ['']
 label is:
 ['over 19,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.57476341774711, Em score: 1.881188118811881, current_count: 1010
2024-06-05 16:34:04,167 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:04,167 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 278, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:04,168 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:04,168 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:04,168 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:05,110 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:05,112 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435763359069824 s; generated tokens: 1 tokens; generate speed: 1.0597976676034189 tokens/s
2024-06-05 16:34:05,117 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:05,117 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1011/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.9639 tokens/s, remaining time: 0:17:28
pred is:
 ['']
 label is:
 ['nearly 60,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:05,198 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:05,199 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 314, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:05,199 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:05,199 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:05,199 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:06,142 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:06,144 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439067840576172 s; generated tokens: 1 tokens; generate speed: 1.0594266477260097 tokens/s
2024-06-05 16:34:06,148 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:06,149 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1012/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.9631 tokens/s, remaining time: 0:17:27
pred is:
 ['']
 label is:
 ['more than 70,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:06,229 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:06,230 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 272, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:06,230 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:06,230 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:06,230 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:07,172 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:07,174 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430191516876221 s; generated tokens: 1 tokens; generate speed: 1.0604238505765289 tokens/s
2024-06-05 16:34:07,178 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:07,178 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1013/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.9622 tokens/s, remaining time: 0:17:26
pred is:
 ['']
 label is:
 ['Toshiba']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:07,259 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:07,260 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 246, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:07,260 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:07,260 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:07,260 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:08,201 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:08,203 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425976276397705 s; generated tokens: 1 tokens; generate speed: 1.0608980658098652 tokens/s
2024-06-05 16:34:08,208 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:08,208 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1014/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.9613 tokens/s, remaining time: 0:17:25
pred is:
 ['']
 label is:
 ['from the 14th to the 19th century']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:08,289 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:08,289 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 277, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:08,290 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:08,290 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:08,290 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:09,232 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:09,234 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431939125061035 s; generated tokens: 1 tokens; generate speed: 1.0602273686679766 tokens/s
2024-06-05 16:34:09,238 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:09,239 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1015/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.9605 tokens/s, remaining time: 0:17:24
pred is:
 ['']
 label is:
 ['Leonardo da Vinci']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:09,320 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:09,320 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:09,320 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:09,321 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:09,321 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:10,260 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:10,262 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415972232818604 s; generated tokens: 1 tokens; generate speed: 1.0620252219038853 tokens/s
2024-06-05 16:34:10,267 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:10,267 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1016/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.9596 tokens/s, remaining time: 0:17:23
pred is:
 ['']
 label is:
 ['Charles Dickens']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:10,349 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:10,349 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 210, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:10,349 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:10,350 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:10,350 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:11,291 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:11,292 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424746036529541 s; generated tokens: 1 tokens; generate speed: 1.0610365479601065 tokens/s
2024-06-05 16:34:11,297 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:11,297 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1017/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.9587 tokens/s, remaining time: 0:17:22
pred is:
 ['']
 label is:
 ['Word and Image Department']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:11,378 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:11,379 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 353, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:11,379 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:11,379 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:11,379 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:12,322 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:12,324 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9443850517272949 s; generated tokens: 1 tokens; generate speed: 1.0588901192061273 tokens/s
2024-06-05 16:34:12,329 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:12,329 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1018/2067], cost time 0.9552s, every example cost time is 0.9552, generate speed: 1.0469 tokens/s, avg speed: 1.9579 tokens/s, remaining time: 0:17:21
pred is:
 ['']
 label is:
 ['2007']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:12,410 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:12,410 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 216, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:12,410 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:12,411 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:12,411 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:13,351 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:13,353 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425132274627686 s; generated tokens: 1 tokens; generate speed: 1.0609930671126866 tokens/s
2024-06-05 16:34:13,358 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:13,358 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1019/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.9570 tokens/s, remaining time: 0:17:20
pred is:
 ['']
 label is:
 ['British patrons']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:13,439 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:13,440 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 314, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:13,440 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:13,440 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:13,440 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:14,383 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:14,384 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439361095428467 s; generated tokens: 1 tokens; generate speed: 1.059393734269055 tokens/s
2024-06-05 16:34:14,389 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:14,389 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1020/2067], cost time 0.9552s, every example cost time is 0.9552, generate speed: 1.0469 tokens/s, avg speed: 1.9562 tokens/s, remaining time: 0:17:18
pred is:
 ['']
 label is:
 ['increase in tea drinking']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.539716717573119, Em score: 1.8627450980392157, current_count: 1020
2024-06-05 16:34:14,655 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:14,655 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 191, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:14,656 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:14,656 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:14,656 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:15,597 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:15,598 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420936107635498 s; generated tokens: 1 tokens; generate speed: 1.0614656426652953 tokens/s
2024-06-05 16:34:15,603 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:15,603 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1021/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.9553 tokens/s, remaining time: 0:17:17
pred is:
 ['']
 label is:
 ["Trajan's Column"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:15,685 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:15,685 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 248, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:15,685 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:15,686 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:15,686 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:16,627 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:16,629 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426438808441162 s; generated tokens: 1 tokens; generate speed: 1.0608460101650719 tokens/s
2024-06-05 16:34:16,633 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:16,634 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1022/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.9544 tokens/s, remaining time: 0:17:16
pred is:
 ['']
 label is:
 ['1731']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:16,714 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:16,715 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:16,715 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:16,715 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:16,715 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:17,663 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:17,665 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9496119022369385 s; generated tokens: 1 tokens; generate speed: 1.0530617799170015 tokens/s
2024-06-05 16:34:17,670 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:17,670 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1023/2067], cost time 0.9605s, every example cost time is 0.9605, generate speed: 1.0412 tokens/s, avg speed: 1.9536 tokens/s, remaining time: 0:17:15
pred is:
 ['']
 label is:
 ['Josiah Wedgwood, William De Morgan and Bernard Leach']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:17,751 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:17,751 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 312, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:17,752 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:17,752 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:17,752 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:18,694 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:18,696 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435322284698486 s; generated tokens: 1 tokens; generate speed: 1.0598472101178003 tokens/s
2024-06-05 16:34:18,701 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:18,701 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1024/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0476 tokens/s, avg speed: 1.9527 tokens/s, remaining time: 0:17:14
pred is:
 ['']
 label is:
 ['4000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:18,781 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:18,781 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 235, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:18,782 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:18,782 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:18,782 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:19,723 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:19,725 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428741931915283 s; generated tokens: 1 tokens; generate speed: 1.0605868812838188 tokens/s
2024-06-05 16:34:19,730 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:19,730 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1025/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0485 tokens/s, avg speed: 1.9519 tokens/s, remaining time: 0:17:13
pred is:
 ['']
 label is:
 ['1994']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:19,811 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:19,811 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 223, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:19,812 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:19,812 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:19,812 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:20,753 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:20,755 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429142475128174 s; generated tokens: 1 tokens; generate speed: 1.0605418283134032 tokens/s
2024-06-05 16:34:20,760 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:20,760 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1026/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.9510 tokens/s, remaining time: 0:17:12
pred is:
 ['']
 label is:
 ['over 10,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:20,841 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:20,841 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 176, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:20,842 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:20,842 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:20,842 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:21,782 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:21,784 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414267539978027 s; generated tokens: 1 tokens; generate speed: 1.0622175286111892 tokens/s
2024-06-05 16:34:21,789 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:21,789 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1027/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.9502 tokens/s, remaining time: 0:17:11
pred is:
 ['']
 label is:
 ['over 14,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:21,870 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:21,870 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 174, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:21,870 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:21,871 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:21,871 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:22,810 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:22,812 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412977695465088 s; generated tokens: 1 tokens; generate speed: 1.0623630824938344 tokens/s
2024-06-05 16:34:22,817 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:22,817 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1028/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.9494 tokens/s, remaining time: 0:17:10
pred is:
 ['']
 label is:
 ['2002']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:22,898 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:22,898 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 331, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:22,899 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:22,899 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:22,899 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:23,841 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:23,843 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439413547515869 s; generated tokens: 1 tokens; generate speed: 1.059387847524877 tokens/s
2024-06-05 16:34:23,848 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:23,848 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1029/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.9485 tokens/s, remaining time: 0:17:09
pred is:
 ['']
 label is:
 ['Italian and French Renaissance']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:23,930 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:23,930 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 262, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:23,931 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:23,931 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:23,931 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:24,872 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:24,874 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431443214416504 s; generated tokens: 1 tokens; generate speed: 1.0602831160255966 tokens/s
2024-06-05 16:34:24,879 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:24,879 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1030/2067], cost time 0.9544s, every example cost time is 0.9544, generate speed: 1.0477 tokens/s, avg speed: 1.9477 tokens/s, remaining time: 0:17:08
pred is:
 ['']
 label is:
 ['1580']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.505350535849108, Em score: 1.8446601941747574, current_count: 1030
2024-06-05 16:34:25,145 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:25,145 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 339, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:25,145 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:25,146 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:25,146 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:26,088 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:26,090 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9443094730377197 s; generated tokens: 1 tokens; generate speed: 1.0589748684646052 tokens/s
2024-06-05 16:34:26,095 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:26,095 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1031/2067], cost time 0.9560s, every example cost time is 0.9560, generate speed: 1.0460 tokens/s, avg speed: 1.9468 tokens/s, remaining time: 0:17:07
pred is:
 ['']
 label is:
 ['over 6000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:26,177 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:26,178 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 379, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:26,178 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:26,178 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:26,178 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:27,122 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:27,124 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9449739456176758 s; generated tokens: 1 tokens; generate speed: 1.058230234428693 tokens/s
2024-06-05 16:34:27,128 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:27,128 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1032/2067], cost time 0.9563s, every example cost time is 0.9563, generate speed: 1.0457 tokens/s, avg speed: 1.9460 tokens/s, remaining time: 0:17:06
pred is:
 ['']
 label is:
 ['secular and sacred']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:27,209 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:27,209 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 254, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:27,210 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:27,210 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:27,210 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:28,151 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:28,153 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426207542419434 s; generated tokens: 1 tokens; generate speed: 1.0608720373488922 tokens/s
2024-06-05 16:34:28,158 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:28,158 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1033/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.9452 tokens/s, remaining time: 0:17:05
pred is:
 ['']
 label is:
 ['c1110']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:28,245 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:28,245 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 226, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:28,245 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:28,246 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:28,246 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:29,186 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:29,188 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423120021820068 s; generated tokens: 1 tokens; generate speed: 1.0612196360487944 tokens/s
2024-06-05 16:34:29,193 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:29,193 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1034/2067], cost time 0.9594s, every example cost time is 0.9594, generate speed: 1.0423 tokens/s, avg speed: 1.9443 tokens/s, remaining time: 0:17:04
pred is:
 ['']
 label is:
 ['over 5,100']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:29,274 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:29,274 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 247, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:29,275 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:29,275 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:29,275 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:30,216 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:30,218 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942986011505127 s; generated tokens: 1 tokens; generate speed: 1.060461117979758 tokens/s
2024-06-05 16:34:30,223 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:30,223 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1035/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.9435 tokens/s, remaining time: 0:17:03
pred is:
 ['']
 label is:
 ['1130']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:30,305 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:30,305 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 343, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:30,305 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:30,306 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:30,306 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:31,248 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:31,250 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9442732334136963 s; generated tokens: 1 tokens; generate speed: 1.0590155101451333 tokens/s
2024-06-05 16:34:31,255 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:31,255 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1036/2067], cost time 0.9554s, every example cost time is 0.9554, generate speed: 1.0466 tokens/s, avg speed: 1.9426 tokens/s, remaining time: 0:17:02
pred is:
 ['']
 label is:
 ['1857']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:31,341 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:31,341 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 176, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:31,342 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:31,342 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:31,342 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:32,282 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:32,284 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941624641418457 s; generated tokens: 1 tokens; generate speed: 1.061994297954657 tokens/s
2024-06-05 16:34:32,289 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:32,289 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1037/2067], cost time 0.9577s, every example cost time is 0.9577, generate speed: 1.0441 tokens/s, avg speed: 1.9418 tokens/s, remaining time: 0:17:01
pred is:
 ['']
 label is:
 ['continental art 1600–1800']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:32,370 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:32,370 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 234, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:32,371 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:32,371 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:32,371 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:33,312 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:33,314 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426138401031494 s; generated tokens: 1 tokens; generate speed: 1.060879818919878 tokens/s
2024-06-05 16:34:33,318 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:33,319 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1038/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.9410 tokens/s, remaining time: 0:17:00
pred is:
 ['']
 label is:
 ['Eadweard Muybridge']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:33,400 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:33,400 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 216, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:33,400 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:33,401 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:33,401 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:34,341 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:34,343 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422729015350342 s; generated tokens: 1 tokens; generate speed: 1.0612636725209055 tokens/s
2024-06-05 16:34:34,348 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:34,348 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1039/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9402 tokens/s, remaining time: 0:16:59
pred is:
 ['']
 label is:
 ['post-classical European']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:34,429 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:34,429 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 513, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:34,429 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:34,430 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:34,430 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:35,374 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:35,376 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9457767009735107 s; generated tokens: 1 tokens; generate speed: 1.057332030880731 tokens/s
2024-06-05 16:34:35,380 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:35,381 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1040/2067], cost time 0.9566s, every example cost time is 0.9566, generate speed: 1.0454 tokens/s, avg speed: 1.9393 tokens/s, remaining time: 0:16:58
pred is:
 ['']
 label is:
 ['National Galleries of Scotland']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.4716452422351742, Em score: 1.8269230769230769, current_count: 1040
2024-06-05 16:34:35,642 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:35,642 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 178, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:35,643 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:35,643 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:35,643 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:36,583 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:36,585 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420828819274902 s; generated tokens: 1 tokens; generate speed: 1.0614777310824415 tokens/s
2024-06-05 16:34:36,590 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:36,590 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1041/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.9385 tokens/s, remaining time: 0:16:57
pred is:
 ['']
 label is:
 ['more than 20']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:36,675 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:36,676 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 206, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:36,676 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:36,676 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:36,677 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:37,617 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:37,619 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419951438903809 s; generated tokens: 1 tokens; generate speed: 1.0615765978050191 tokens/s
2024-06-05 16:34:37,623 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:37,624 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1042/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.9377 tokens/s, remaining time: 0:16:56
pred is:
 ['']
 label is:
 ['George Frampton']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:37,716 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:37,716 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 241, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:37,717 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:37,717 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:37,717 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:38,658 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:38,660 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425077438354492 s; generated tokens: 1 tokens; generate speed: 1.0609992401023585 tokens/s
2024-06-05 16:34:38,664 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:38,664 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1043/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0485 tokens/s, avg speed: 1.9369 tokens/s, remaining time: 0:16:55
pred is:
 ['']
 label is:
 ['Dorothy and Michael Hintze']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:38,746 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:38,746 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:38,746 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:38,747 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:38,747 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:39,686 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:39,688 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411990642547607 s; generated tokens: 1 tokens; generate speed: 1.0624744944809286 tokens/s
2024-06-05 16:34:39,693 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:39,693 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1044/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.9360 tokens/s, remaining time: 0:16:54
pred is:
 ['']
 label is:
 ['more than 53,000']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:39,775 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:39,775 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 259, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:39,776 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:39,776 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:39,776 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:40,718 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:40,719 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.943260669708252 s; generated tokens: 1 tokens; generate speed: 1.0601523334046117 tokens/s
2024-06-05 16:34:40,724 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:40,724 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1045/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.9352 tokens/s, remaining time: 0:16:53
pred is:
 ['']
 label is:
 ['Cloth of St Gereon']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:40,806 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:40,806 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:40,806 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:40,806 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:40,807 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:41,746 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:41,749 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941835880279541 s; generated tokens: 1 tokens; generate speed: 1.0617561094648418 tokens/s
2024-06-05 16:34:41,753 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:41,754 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1046/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.9344 tokens/s, remaining time: 0:16:52
pred is:
 ['']
 label is:
 ['late 14th-century']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:41,841 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:41,842 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 158, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:41,842 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:41,843 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:41,843 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:42,783 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:42,785 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416530132293701 s; generated tokens: 1 tokens; generate speed: 1.061962300285676 tokens/s
2024-06-05 16:34:42,789 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:42,789 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1047/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.9336 tokens/s, remaining time: 0:16:51
pred is:
 ['']
 label is:
 ['Theatre Museum']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:42,870 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:42,870 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 240, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:42,870 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:42,870 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:42,871 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:43,811 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:43,813 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423508644104004 s; generated tokens: 1 tokens; generate speed: 1.0611758717127817 tokens/s
2024-06-05 16:34:43,818 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:43,818 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1048/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9328 tokens/s, remaining time: 0:16:50
pred is:
 ['']
 label is:
 ['Conservation']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:43,898 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:43,899 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 145, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:43,899 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:43,899 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:43,899 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:44,839 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:44,841 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941664457321167 s; generated tokens: 1 tokens; generate speed: 1.0619493942086178 tokens/s
2024-06-05 16:34:44,846 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:44,846 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1049/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.9320 tokens/s, remaining time: 0:16:49
pred is:
 ['']
 label is:
 ['The Walt Disney Company']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:44,928 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:44,928 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 231, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:44,928 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:44,929 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:44,929 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:45,870 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:45,872 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942885160446167 s; generated tokens: 1 tokens; generate speed: 1.0605745449708919 tokens/s
2024-06-05 16:34:45,876 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:45,877 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1050/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.9312 tokens/s, remaining time: 0:16:48
pred is:
 ['']
 label is:
 ['October 12, 1943']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.438581954213887, Em score: 1.8095238095238095, current_count: 1050
2024-06-05 16:34:46,138 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:46,139 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 192, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:46,139 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:46,139 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:46,140 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:47,080 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:47,082 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417717456817627 s; generated tokens: 1 tokens; generate speed: 1.0618284149903914 tokens/s
2024-06-05 16:34:47,086 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:47,086 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1051/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.9304 tokens/s, remaining time: 0:16:47
pred is:
 ['']
 label is:
 ['232']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:47,167 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:47,167 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 163, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:47,168 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:47,168 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:47,168 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:48,108 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:48,110 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941317081451416 s; generated tokens: 1 tokens; generate speed: 1.0623412872292732 tokens/s
2024-06-05 16:34:48,114 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:48,115 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1052/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.9296 tokens/s, remaining time: 0:16:46
pred is:
 ['']
 label is:
 ['Radio Corporation of America']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:48,196 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:48,196 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:48,196 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:48,197 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:48,197 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:49,137 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:49,139 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422698020935059 s; generated tokens: 1 tokens; generate speed: 1.0612671633731985 tokens/s
2024-06-05 16:34:49,144 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:49,144 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1053/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9288 tokens/s, remaining time: 0:16:45
pred is:
 ['']
 label is:
 ['Mutual']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:49,225 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:49,226 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 291, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:49,226 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:49,226 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:49,226 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:50,168 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:50,170 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9433212280273438 s; generated tokens: 1 tokens; generate speed: 1.0600842748881862 tokens/s
2024-06-05 16:34:50,174 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:50,175 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1054/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.9279 tokens/s, remaining time: 0:16:43
pred is:
 ['']
 label is:
 ['Mark Woods']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:50,256 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:50,256 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 229, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:50,257 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:50,257 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:50,257 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:51,198 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:51,200 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423890113830566 s; generated tokens: 1 tokens; generate speed: 1.061132916365815 tokens/s
2024-06-05 16:34:51,204 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:51,204 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1055/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.9271 tokens/s, remaining time: 0:16:42
pred is:
 ['']
 label is:
 ['Life Savers candy']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:51,285 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:51,285 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 255, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:51,285 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:51,286 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:51,286 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:52,226 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:52,229 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429547786712646 s; generated tokens: 1 tokens; generate speed: 1.0604962428941915 tokens/s
2024-06-05 16:34:52,233 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:52,234 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1056/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.9263 tokens/s, remaining time: 0:16:41
pred is:
 ['']
 label is:
 ['Magnetophon tape recorder']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:52,315 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:52,315 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 274, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:52,315 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:52,315 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:52,316 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:53,258 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:53,259 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436337947845459 s; generated tokens: 1 tokens; generate speed: 1.0597331353825918 tokens/s
2024-06-05 16:34:53,264 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:53,264 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1057/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0476 tokens/s, avg speed: 1.9255 tokens/s, remaining time: 0:16:40
pred is:
 ['']
 label is:
 ['$155 million']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:53,345 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:53,345 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 169, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:53,345 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:53,346 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:53,346 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:54,286 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:54,287 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412736892700195 s; generated tokens: 1 tokens; generate speed: 1.0623902605580362 tokens/s
2024-06-05 16:34:54,292 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:54,292 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1058/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.9248 tokens/s, remaining time: 0:16:39
pred is:
 ['']
 label is:
 ['1959']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:54,373 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:54,373 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 265, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:54,374 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:54,374 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:54,374 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:55,316 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:55,320 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9454758167266846 s; generated tokens: 1 tokens; generate speed: 1.0576685117786329 tokens/s
2024-06-05 16:34:55,325 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:55,326 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1059/2067], cost time 0.9573s, every example cost time is 0.9573, generate speed: 1.0446 tokens/s, avg speed: 1.9239 tokens/s, remaining time: 0:16:38
pred is:
 ['']
 label is:
 ['coronation of Queen Elizabeth II']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:55,407 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:55,408 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:55,408 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:55,408 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:55,408 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:56,348 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:56,350 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415202140808105 s; generated tokens: 1 tokens; generate speed: 1.0621120874991328 tokens/s
2024-06-05 16:34:56,355 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:56,355 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1060/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0496 tokens/s, avg speed: 1.9232 tokens/s, remaining time: 0:16:37
pred is:
 ['']
 label is:
 ['Peanuts']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.406142501815643, Em score: 1.7924528301886793, current_count: 1060
2024-06-05 16:34:56,623 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:56,623 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 238, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:56,623 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:56,624 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:56,624 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:57,565 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:57,567 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435513019561768 s; generated tokens: 1 tokens; generate speed: 1.0598257857593896 tokens/s
2024-06-05 16:34:57,572 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:57,572 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1061/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0474 tokens/s, avg speed: 1.9224 tokens/s, remaining time: 0:16:36
pred is:
 ['']
 label is:
 ['1974']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:57,653 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:57,653 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 281, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:57,654 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:57,654 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:57,654 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:58,596 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:58,598 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9440598487854004 s; generated tokens: 1 tokens; generate speed: 1.0592548780530922 tokens/s
2024-06-05 16:34:58,603 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:58,603 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1062/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0473 tokens/s, avg speed: 1.9216 tokens/s, remaining time: 0:16:35
pred is:
 ['']
 label is:
 ['General Hospital']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:58,684 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:58,684 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 377, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:58,685 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:58,685 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:58,685 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:34:59,629 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:59,631 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9454021453857422 s; generated tokens: 1 tokens; generate speed: 1.0577509315805296 tokens/s
2024-06-05 16:34:59,635 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:34:59,636 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1063/2067], cost time 0.9563s, every example cost time is 0.9563, generate speed: 1.0457 tokens/s, avg speed: 1.9208 tokens/s, remaining time: 0:16:34
pred is:
 ['']
 label is:
 ['X Games']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:34:59,716 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:34:59,716 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 183, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:34:59,716 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:34:59,717 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:34:59,717 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:00,657 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:00,658 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414525032043457 s; generated tokens: 1 tokens; generate speed: 1.0621884764195548 tokens/s
2024-06-05 16:35:00,663 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:00,663 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1064/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.9200 tokens/s, remaining time: 0:16:33
pred is:
 ['']
 label is:
 ['Frank Marx']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:00,768 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:00,769 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 218, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:00,769 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:00,769 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:00,770 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:01,711 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:01,713 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427757263183594 s; generated tokens: 1 tokens; generate speed: 1.0606976527759233 tokens/s
2024-06-05 16:35:01,717 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:01,717 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1065/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0483 tokens/s, avg speed: 1.9192 tokens/s, remaining time: 0:16:32
pred is:
 ['']
 label is:
 ['108']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:01,798 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:01,798 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 227, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:01,799 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:01,799 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:01,799 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:02,740 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:02,742 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428234100341797 s; generated tokens: 1 tokens; generate speed: 1.0606440075175345 tokens/s
2024-06-05 16:35:02,747 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:02,747 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1066/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.9184 tokens/s, remaining time: 0:16:31
pred is:
 ['']
 label is:
 ['U.S. Supreme Court']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:02,828 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:02,829 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 266, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:02,829 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:02,829 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:02,829 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:03,770 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:03,772 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426367282867432 s; generated tokens: 1 tokens; generate speed: 1.060854059673142 tokens/s
2024-06-05 16:35:03,777 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:03,777 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1067/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0486 tokens/s, avg speed: 1.9176 tokens/s, remaining time: 0:16:30
pred is:
 ['']
 label is:
 ['Leonard Goldenson']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:03,858 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:03,858 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 314, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:03,858 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:03,859 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:03,859 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:04,801 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:04,802 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434776306152344 s; generated tokens: 1 tokens; generate speed: 1.0599085421324805 tokens/s
2024-06-05 16:35:04,807 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:04,807 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1068/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.9168 tokens/s, remaining time: 0:16:29
pred is:
 ['']
 label is:
 ['1952']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:04,888 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:04,888 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 333, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:04,888 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:04,889 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:04,889 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:05,831 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:05,833 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9442191123962402 s; generated tokens: 1 tokens; generate speed: 1.0590762110949004 tokens/s
2024-06-05 16:35:05,838 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:05,838 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1069/2067], cost time 0.9551s, every example cost time is 0.9551, generate speed: 1.0470 tokens/s, avg speed: 1.9161 tokens/s, remaining time: 0:16:28
pred is:
 ['']
 label is:
 ['August 10, 1948']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:05,921 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:05,921 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 202, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:05,922 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:05,922 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:05,922 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:06,863 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:06,865 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422171115875244 s; generated tokens: 1 tokens; generate speed: 1.061326511376044 tokens/s
2024-06-05 16:35:06,869 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:06,869 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1070/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0484 tokens/s, avg speed: 1.9153 tokens/s, remaining time: 0:16:27
pred is:
 ['']
 label is:
 ['September 30, 1960']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.374309394322039, Em score: 1.7757009345794392, current_count: 1070
2024-06-05 16:35:07,137 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:07,137 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 259, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:07,138 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:07,138 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:07,138 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:08,079 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:08,082 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431173801422119 s; generated tokens: 1 tokens; generate speed: 1.060313404307331 tokens/s
2024-06-05 16:35:08,086 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:08,087 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1071/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.9145 tokens/s, remaining time: 0:16:26
pred is:
 ['']
 label is:
 ['1959']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:08,167 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:08,167 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 157, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:08,168 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:08,168 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:08,168 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:09,108 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:09,109 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412562847137451 s; generated tokens: 1 tokens; generate speed: 1.0624099049751579 tokens/s
2024-06-05 16:35:09,114 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:09,114 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1072/2067], cost time 0.9521s, every example cost time is 0.9521, generate speed: 1.0503 tokens/s, avg speed: 1.9137 tokens/s, remaining time: 0:16:25
pred is:
 ['']
 label is:
 ['circle logo']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:09,195 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:09,195 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 320, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:09,195 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:09,196 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:09,196 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:10,138 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:10,140 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9437315464019775 s; generated tokens: 1 tokens; generate speed: 1.0596233683323915 tokens/s
2024-06-05 16:35:10,144 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:10,145 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1073/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0476 tokens/s, avg speed: 1.9129 tokens/s, remaining time: 0:16:24
pred is:
 ['']
 label is:
 ['Pittard Sullivan']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:10,225 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:10,226 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:10,226 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:10,226 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:10,227 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:11,167 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:11,169 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422221183776855 s; generated tokens: 1 tokens; generate speed: 1.0613208716876612 tokens/s
2024-06-05 16:35:11,174 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:11,174 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1074/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.9122 tokens/s, remaining time: 0:16:23
pred is:
 ['']
 label is:
 ['1993–94 season']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:11,255 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:11,255 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 156, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:11,255 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:11,255 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:11,256 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:12,196 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:12,197 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416136741638184 s; generated tokens: 1 tokens; generate speed: 1.0620066673182402 tokens/s
2024-06-05 16:35:12,202 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:12,202 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1075/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.9114 tokens/s, remaining time: 0:16:22
pred is:
 ['']
 label is:
 ['1977']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:12,283 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:12,283 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 190, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:12,283 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:12,284 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:12,284 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:13,223 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:13,226 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418008327484131 s; generated tokens: 1 tokens; generate speed: 1.0617956209294772 tokens/s
2024-06-05 16:35:13,230 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:13,231 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1076/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.9106 tokens/s, remaining time: 0:16:21
pred is:
 ['']
 label is:
 ['Paul Rand']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:13,311 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:13,311 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 162, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:13,312 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:13,312 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:13,312 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:14,252 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:14,254 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9413981437683105 s; generated tokens: 1 tokens; generate speed: 1.0622498106880824 tokens/s
2024-06-05 16:35:14,258 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:14,259 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1077/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.9099 tokens/s, remaining time: 0:16:20
pred is:
 ['']
 label is:
 ['ABC Radio']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:14,339 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:14,340 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 299, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:14,340 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:14,340 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:14,340 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:15,282 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:15,284 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435875415802002 s; generated tokens: 1 tokens; generate speed: 1.0597850818646115 tokens/s
2024-06-05 16:35:15,313 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:15,313 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1078/2067], cost time 0.9788s, every example cost time is 0.9788, generate speed: 1.0217 tokens/s, avg speed: 1.9090 tokens/s, remaining time: 0:16:19
pred is:
 ['']
 label is:
 ['2004']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:15,394 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:15,394 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 181, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:15,395 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:15,395 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:15,395 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:16,335 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:16,337 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414558410644531 s; generated tokens: 1 tokens; generate speed: 1.0621847105110678 tokens/s
2024-06-05 16:35:16,341 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:16,342 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1079/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.9083 tokens/s, remaining time: 0:16:18
pred is:
 ['']
 label is:
 ['2002']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:16,422 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:16,422 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:16,423 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:16,423 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:16,423 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:17,364 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:17,366 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423391819000244 s; generated tokens: 1 tokens; generate speed: 1.061189027483411 tokens/s
2024-06-05 16:35:17,370 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:17,371 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1080/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9075 tokens/s, remaining time: 0:16:17
pred is:
 ['']
 label is:
 ['Time Warner Cable']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.343065788819057, Em score: 1.7592592592592593, current_count: 1080
2024-06-05 16:35:17,636 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:17,636 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 246, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:17,636 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:17,637 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:17,637 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:18,578 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:18,619 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:18,649 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:18,678 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:18,707 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:18,709 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.0717978477478027 s; generated tokens: 5 tokens; generate speed: 4.665058817300887 tokens/s
2024-06-05 16:35:18,713 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:18,714 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1081/2067], cost time 1.0830s, every example cost time is 1.0830, generate speed: 4.6169 tokens/s, avg speed: 1.9103 tokens/s, remaining time: 0:16:16
pred is:
 ['2000']
 label is:
 ['2000']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:35:18,818 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:18,819 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 238, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:18,819 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:18,819 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:18,820 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:19,761 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:19,762 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424903392791748 s; generated tokens: 1 tokens; generate speed: 1.0610188331105963 tokens/s
2024-06-05 16:35:19,767 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:19,767 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1082/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0484 tokens/s, avg speed: 1.9095 tokens/s, remaining time: 0:16:15
pred is:
 ['']
 label is:
 ['August 1999']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:19,848 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:19,848 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 378, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:19,849 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:19,849 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:19,849 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:20,792 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:20,794 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9444661140441895 s; generated tokens: 1 tokens; generate speed: 1.0587992360234242 tokens/s
2024-06-05 16:35:20,798 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:20,799 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1083/2067], cost time 0.9554s, every example cost time is 0.9554, generate speed: 1.0466 tokens/s, avg speed: 1.9087 tokens/s, remaining time: 0:16:14
pred is:
 ['']
 label is:
 ['July 31, 1995']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:20,879 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:20,879 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 192, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:20,880 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:20,880 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:20,880 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:21,822 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:21,853 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:21,883 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:21,912 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:21,941 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:21,970 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:21,999 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:22,028 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:22,058 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:22,098 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:22,411 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5303287506103516 s; generated tokens: 20 tokens; generate speed: 13.069087274236507 tokens/s
2024-06-05 16:35:22,416 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:22,416 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1084/2067], cost time 1.5415s, every example cost time is 1.5415, generate speed: 12.9742 tokens/s, avg speed: 1.9246 tokens/s, remaining time: 0:16:13
pred is:
 ['1965–66']
 label is:
 ['1965–66 season']
The F1/Em of this example is:  {'F1': 74.99999999999999, 'Em': 0.0}
2024-06-05 16:35:22,496 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:22,497 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 203, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:22,497 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:22,497 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:22,497 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:23,438 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:23,440 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426357746124268 s; generated tokens: 1 tokens; generate speed: 1.0608551329501144 tokens/s
2024-06-05 16:35:23,445 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:23,445 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1085/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.9238 tokens/s, remaining time: 0:16:12
pred is:
 ['']
 label is:
 ['May 1, 1953']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:23,526 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:23,527 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 297, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:23,527 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:23,527 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:23,527 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:24,470 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:24,471 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9438221454620361 s; generated tokens: 1 tokens; generate speed: 1.059521653320036 tokens/s
2024-06-05 16:35:24,476 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:24,476 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1086/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.9230 tokens/s, remaining time: 0:16:11
pred is:
 ['']
 label is:
 ['Robert Kintner']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:24,557 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:24,557 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 236, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:24,557 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:24,558 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:24,558 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:25,499 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:25,501 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429659843444824 s; generated tokens: 1 tokens; generate speed: 1.0604836405580056 tokens/s
2024-06-05 16:35:25,506 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:25,506 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1087/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0483 tokens/s, avg speed: 1.9223 tokens/s, remaining time: 0:16:10
pred is:
 ['']
 label is:
 ['Paramount Pictures']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:25,586 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:25,586 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 226, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:25,587 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:25,587 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:25,587 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:26,528 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:26,530 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421947002410889 s; generated tokens: 1 tokens; generate speed: 1.061351756430088 tokens/s
2024-06-05 16:35:26,534 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:26,534 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1088/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.9215 tokens/s, remaining time: 0:16:09
pred is:
 ['']
 label is:
 ['Cheyenne']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:26,615 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:26,615 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:26,616 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:26,616 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:26,616 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:27,556 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:27,558 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416496753692627 s; generated tokens: 1 tokens; generate speed: 1.0619660646172426 tokens/s
2024-06-05 16:35:27,562 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:27,563 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1089/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.9207 tokens/s, remaining time: 0:16:08
pred is:
 ['']
 label is:
 ['Roy']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:27,643 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:27,644 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:27,644 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:27,644 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:27,645 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:28,586 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:28,588 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.94327712059021 s; generated tokens: 1 tokens; generate speed: 1.0601338442029618 tokens/s
2024-06-05 16:35:28,593 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:28,593 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1090/2067], cost time 0.9543s, every example cost time is 0.9543, generate speed: 1.0479 tokens/s, avg speed: 1.9200 tokens/s, remaining time: 0:16:07
pred is:
 ['']
 label is:
 ['Allen Shaw']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.4729459191968637, Em score: 1.834862385321101, current_count: 1090
2024-06-05 16:35:28,859 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:28,859 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:28,860 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:28,860 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:28,860 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:29,801 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:29,803 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426703453063965 s; generated tokens: 1 tokens; generate speed: 1.0608162280473241 tokens/s
2024-06-05 16:35:29,808 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:29,808 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1091/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0484 tokens/s, avg speed: 1.9192 tokens/s, remaining time: 0:16:06
pred is:
 ['']
 label is:
 ['1969']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:29,914 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:29,914 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 157, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:29,915 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:29,915 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:29,915 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:30,855 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:30,857 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414372444152832 s; generated tokens: 1 tokens; generate speed: 1.062205692341277 tokens/s
2024-06-05 16:35:30,861 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:30,861 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1092/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.9184 tokens/s, remaining time: 0:16:05
pred is:
 ['']
 label is:
 ['early 1970s']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:30,942 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:30,943 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 226, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:30,943 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:30,943 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:30,943 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:31,884 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:31,886 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425666332244873 s; generated tokens: 1 tokens; generate speed: 1.0609329513172296 tokens/s
2024-06-05 16:35:31,891 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:31,891 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1093/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.9177 tokens/s, remaining time: 0:16:04
pred is:
 ['']
 label is:
 ['Monday Night Football']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:31,972 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:31,972 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 171, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:31,973 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:31,973 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:31,973 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:32,913 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:32,944 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:32,973 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:33,003 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:33,032 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:33,061 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:33,090 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:33,119 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:33,148 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:33,177 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:33,469 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.496044397354126 s; generated tokens: 20 tokens; generate speed: 13.36858721263326 tokens/s
2024-06-05 16:35:33,474 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:33,474 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1094/2067], cost time 1.5070s, every example cost time is 1.5070, generate speed: 13.2711 tokens/s, avg speed: 1.9334 tokens/s, remaining time: 0:16:04
pred is:
 ['1970']
 label is:
 ['1970']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:35:33,555 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:33,555 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 166, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:33,556 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:33,556 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:33,556 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:34,496 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:34,497 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941152811050415 s; generated tokens: 1 tokens; generate speed: 1.062526710071562 tokens/s
2024-06-05 16:35:34,502 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:34,502 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1095/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.9327 tokens/s, remaining time: 0:16:03
pred is:
 ['']
 label is:
 ['cigarette advertising from all television and radio networks']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:34,583 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:34,583 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 228, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:34,584 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:34,584 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:34,584 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:35,525 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:35,556 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:35,591 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:35,621 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:35,651 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:35,681 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:35,710 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:35,739 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:35,768 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:35,797 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:36,064 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4794731140136719 s; generated tokens: 19 tokens; generate speed: 12.842409787667435 tokens/s
2024-06-05 16:35:36,069 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:36,069 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1096/2067], cost time 1.4905s, every example cost time is 1.4905, generate speed: 12.7471 tokens/s, avg speed: 1.9475 tokens/s, remaining time: 0:16:02
pred is:
 ['1966']
 label is:
 ['1966']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:35:36,150 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:36,150 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 334, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:36,150 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:36,151 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:36,151 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:37,093 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:37,095 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.944068431854248 s; generated tokens: 1 tokens; generate speed: 1.059245247758043 tokens/s
2024-06-05 16:35:37,100 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:37,100 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1097/2067], cost time 0.9549s, every example cost time is 0.9549, generate speed: 1.0472 tokens/s, avg speed: 1.9467 tokens/s, remaining time: 0:16:01
pred is:
 ['']
 label is:
 ['Fred Pierce']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:37,181 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:37,181 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:37,181 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:37,181 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:37,182 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:38,122 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:38,124 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419257640838623 s; generated tokens: 1 tokens; generate speed: 1.061654790781333 tokens/s
2024-06-05 16:35:38,128 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:38,129 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1098/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.9459 tokens/s, remaining time: 0:16:00
pred is:
 ['']
 label is:
 ["president of NBC's entertainment division"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:38,210 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:38,210 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 271, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:38,210 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:38,211 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:38,211 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:39,153 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:39,155 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435405731201172 s; generated tokens: 1 tokens; generate speed: 1.059837836854415 tokens/s
2024-06-05 16:35:39,159 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:39,159 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1099/2067], cost time 0.9546s, every example cost time is 0.9546, generate speed: 1.0476 tokens/s, avg speed: 1.9451 tokens/s, remaining time: 0:15:59
pred is:
 ['']
 label is:
 ['Alex Haley']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:39,240 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:39,241 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 250, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:39,241 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:39,241 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:39,241 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:40,183 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:40,185 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429924488067627 s; generated tokens: 1 tokens; generate speed: 1.0604538787827762 tokens/s
2024-06-05 16:35:40,189 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:40,189 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1100/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.9444 tokens/s, remaining time: 0:15:58
pred is:
 ['']
 label is:
 ['Roone Arledge']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.623191865385983, Em score: 2.0, current_count: 1100
2024-06-05 16:35:40,457 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:40,458 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 204, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:40,458 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:40,458 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:40,458 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:41,399 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:41,400 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417660236358643 s; generated tokens: 1 tokens; generate speed: 1.0618348665195125 tokens/s
2024-06-05 16:35:41,405 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:41,405 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1101/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.9436 tokens/s, remaining time: 0:15:57
pred is:
 ['']
 label is:
 ['June 1978']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:41,486 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:41,487 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 321, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:41,487 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:41,487 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:41,487 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:42,430 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:42,432 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439191818237305 s; generated tokens: 1 tokens; generate speed: 1.059412732844264 tokens/s
2024-06-05 16:35:42,436 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:42,436 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1102/2067], cost time 0.9548s, every example cost time is 0.9548, generate speed: 1.0473 tokens/s, avg speed: 1.9428 tokens/s, remaining time: 0:15:56
pred is:
 ['']
 label is:
 ['ABC Cable News']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:42,529 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:42,529 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 306, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:42,530 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:42,530 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:42,530 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:43,472 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:43,474 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9435765743255615 s; generated tokens: 1 tokens; generate speed: 1.0597973998186296 tokens/s
2024-06-05 16:35:43,478 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:43,479 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1103/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0475 tokens/s, avg speed: 1.9420 tokens/s, remaining time: 0:15:55
pred is:
 ['']
 label is:
 ['Writers Guild of America']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:43,560 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:43,560 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 183, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:43,560 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:43,561 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:43,561 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:44,501 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:44,503 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9418966770172119 s; generated tokens: 1 tokens; generate speed: 1.0616875761434779 tokens/s
2024-06-05 16:35:44,507 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:44,508 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1104/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.9412 tokens/s, remaining time: 0:15:54
pred is:
 ['']
 label is:
 ['ABC Entertainment']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:44,594 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:44,594 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 216, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:44,595 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:44,595 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:44,595 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:45,536 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:45,538 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422409534454346 s; generated tokens: 1 tokens; generate speed: 1.061299656253914 tokens/s
2024-06-05 16:35:45,542 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:45,543 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1105/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.9404 tokens/s, remaining time: 0:15:53
pred is:
 ['']
 label is:
 ['2010']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:45,623 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:45,623 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 238, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:45,624 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:45,624 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:45,624 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:46,569 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:46,571 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9465396404266357 s; generated tokens: 1 tokens; generate speed: 1.056479789424633 tokens/s
2024-06-05 16:35:46,575 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:46,576 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1106/2067], cost time 0.9574s, every example cost time is 0.9574, generate speed: 1.0445 tokens/s, avg speed: 1.9397 tokens/s, remaining time: 0:15:52
pred is:
 ['']
 label is:
 ['1970']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:46,657 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:46,657 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 153, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:46,658 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:46,658 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:46,658 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:47,598 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:47,600 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414544105529785 s; generated tokens: 1 tokens; generate speed: 1.062186324468578 tokens/s
2024-06-05 16:35:47,604 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:47,605 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1107/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0498 tokens/s, avg speed: 1.9389 tokens/s, remaining time: 0:15:51
pred is:
 ['']
 label is:
 ['Disney–ABC Domestic Television']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:47,692 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:47,692 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 188, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:47,692 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:47,693 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:47,693 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:48,633 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:48,635 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415950775146484 s; generated tokens: 1 tokens; generate speed: 1.062027642115029 tokens/s
2024-06-05 16:35:48,639 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:48,639 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1108/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.9381 tokens/s, remaining time: 0:15:50
pred is:
 ['']
 label is:
 ['WABC-TV and WPVI-TV']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:48,720 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:48,720 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 202, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:48,721 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:48,721 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:48,721 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:49,661 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:49,663 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416406154632568 s; generated tokens: 1 tokens; generate speed: 1.0619762822231624 tokens/s
2024-06-05 16:35:49,667 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:49,668 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1109/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.9374 tokens/s, remaining time: 0:15:49
pred is:
 ['']
 label is:
 ['1946']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:49,748 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:49,748 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 237, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:49,749 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:49,749 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:49,749 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:50,690 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:50,692 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942511796951294 s; generated tokens: 1 tokens; generate speed: 1.0609946774508934 tokens/s
2024-06-05 16:35:50,696 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:50,697 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1110/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.9366 tokens/s, remaining time: 0:15:48
pred is:
 ['']
 label is:
 ['2011']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.5905504972293527, Em score: 1.981981981981982, current_count: 1110
2024-06-05 16:35:50,971 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:50,971 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 166, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:50,972 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:50,972 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:50,972 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:51,912 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:51,914 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417781829833984 s; generated tokens: 1 tokens; generate speed: 1.061821157113838 tokens/s
2024-06-05 16:35:51,919 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:51,919 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1111/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0494 tokens/s, avg speed: 1.9358 tokens/s, remaining time: 0:15:47
pred is:
 ['']
 label is:
 ['720p high definition']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:52,000 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:52,001 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 211, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:52,001 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:52,001 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:52,001 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:52,942 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:52,944 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421601295471191 s; generated tokens: 1 tokens; generate speed: 1.0613907006239838 tokens/s
2024-06-05 16:35:52,948 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:52,948 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1112/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.9350 tokens/s, remaining time: 0:15:46
pred is:
 ['']
 label is:
 ['Body of Proof']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:53,029 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:53,029 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 243, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:53,029 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:53,030 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:53,030 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:53,971 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:53,972 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942469596862793 s; generated tokens: 1 tokens; generate speed: 1.0610421846271847 tokens/s
2024-06-05 16:35:53,977 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:53,977 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1113/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.9343 tokens/s, remaining time: 0:15:45
pred is:
 ['']
 label is:
 ['All My Children and One Life to Live']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:54,059 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:54,060 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 215, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:54,060 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:54,060 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:54,061 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:55,002 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:55,003 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425687789916992 s; generated tokens: 1 tokens; generate speed: 1.0609305360928007 tokens/s
2024-06-05 16:35:55,008 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:55,008 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1114/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0483 tokens/s, avg speed: 1.9335 tokens/s, remaining time: 0:15:44
pred is:
 ['']
 label is:
 ['2004']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:55,089 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:55,089 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 220, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:55,090 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:55,090 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:55,090 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:56,031 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:56,033 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428513050079346 s; generated tokens: 1 tokens; generate speed: 1.0606126275569874 tokens/s
2024-06-05 16:35:56,038 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:56,038 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1115/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0483 tokens/s, avg speed: 1.9328 tokens/s, remaining time: 0:15:43
pred is:
 ['']
 label is:
 ['The Middle and Modern Family']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:56,119 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:56,120 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 173, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:56,120 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:56,120 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:56,120 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:57,060 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:57,062 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417116641998291 s; generated tokens: 1 tokens; generate speed: 1.0618961599564538 tokens/s
2024-06-05 16:35:57,067 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:57,067 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1116/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.9320 tokens/s, remaining time: 0:15:42
pred is:
 ['']
 label is:
 ['Daniel Burke']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:57,148 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:57,149 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 158, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:57,149 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:57,149 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:57,149 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:58,089 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:58,091 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9411091804504395 s; generated tokens: 1 tokens; generate speed: 1.0625759696886325 tokens/s
2024-06-05 16:35:58,095 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:58,096 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1117/2067], cost time 0.9520s, every example cost time is 0.9520, generate speed: 1.0504 tokens/s, avg speed: 1.9312 tokens/s, remaining time: 0:15:41
pred is:
 ['']
 label is:
 ['1993']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:35:58,176 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:58,177 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 252, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:58,177 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:58,177 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:58,177 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:35:59,118 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:59,149 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:59,179 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:59,208 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:59,237 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:59,267 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:59,296 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:59,325 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:59,354 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:59,383 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:59,684 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5059006214141846 s; generated tokens: 20 tokens; generate speed: 13.281088881693991 tokens/s
2024-06-05 16:35:59,689 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:35:59,689 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1118/2067], cost time 1.5177s, every example cost time is 1.5177, generate speed: 13.1780 tokens/s, avg speed: 1.9466 tokens/s, remaining time: 0:15:40
pred is:
 ['WLS']
 label is:
 ['WLS']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
2024-06-05 16:35:59,771 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:35:59,771 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 203, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:35:59,771 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:35:59,772 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:35:59,772 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:00,712 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:00,714 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419851303100586 s; generated tokens: 1 tokens; generate speed: 1.061587882677984 tokens/s
2024-06-05 16:36:00,719 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:00,719 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1119/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.9459 tokens/s, remaining time: 0:15:39
pred is:
 ['']
 label is:
 ['Wide World of Sports']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:00,800 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:00,800 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 288, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:00,800 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:00,801 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:00,801 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:01,743 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:01,773 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:01,803 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:01,833 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:01,862 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:01,891 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:01,921 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:01,950 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:01,980 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:02,010 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:02,303 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5021240711212158 s; generated tokens: 20 tokens; generate speed: 13.31447939920941 tokens/s
2024-06-05 16:36:02,308 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:02,308 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1120/2067], cost time 1.5132s, every example cost time is 1.5132, generate speed: 13.2173 tokens/s, avg speed: 1.9612 tokens/s, remaining time: 0:15:38
pred is:
 ['American Broadcasting Companies']
 label is:
 ['American Broadcasting Companies']
The F1/Em of this example is:  {'F1': 100.0, 'Em': 100.0}
F1 score: 3.737063439218376, Em score: 2.142857142857143, current_count: 1120
2024-06-05 16:36:02,580 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:02,580 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 274, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:02,581 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:02,581 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:02,581 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:03,524 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:03,527 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9455745220184326 s; generated tokens: 1 tokens; generate speed: 1.057558105378506 tokens/s
2024-06-05 16:36:03,531 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:03,532 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1121/2067], cost time 0.9567s, every example cost time is 0.9567, generate speed: 1.0453 tokens/s, avg speed: 1.9604 tokens/s, remaining time: 0:15:37
pred is:
 ['']
 label is:
 ['90%']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:03,613 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:03,613 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 268, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:03,613 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:03,613 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:03,614 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:04,555 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:04,556 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942683219909668 s; generated tokens: 1 tokens; generate speed: 1.0608017400541239 tokens/s
2024-06-05 16:36:04,561 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:04,561 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1122/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.9597 tokens/s, remaining time: 0:15:36
pred is:
 ['']
 label is:
 ['Infinity Broadcasting Corporation']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:04,643 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:04,643 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 307, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:04,643 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:04,644 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:04,644 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:05,585 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:05,587 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430253505706787 s; generated tokens: 1 tokens; generate speed: 1.0604168799861453 tokens/s
2024-06-05 16:36:05,592 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:05,592 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1123/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0485 tokens/s, avg speed: 1.9589 tokens/s, remaining time: 0:15:35
pred is:
 ['']
 label is:
 ['Daniel B. Burke']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:05,673 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:05,673 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 236, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:05,673 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:05,674 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:05,674 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:06,615 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:06,616 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426283836364746 s; generated tokens: 1 tokens; generate speed: 1.0608634509202841 tokens/s
2024-06-05 16:36:06,621 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:06,621 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1124/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.9581 tokens/s, remaining time: 0:15:34
pred is:
 ['']
 label is:
 ['General Hospital']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:06,702 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:06,702 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 218, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:06,703 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:06,703 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:06,703 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:07,644 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:07,646 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942702054977417 s; generated tokens: 1 tokens; generate speed: 1.0607805453696137 tokens/s
2024-06-05 16:36:07,651 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:07,651 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1125/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.9573 tokens/s, remaining time: 0:15:33
pred is:
 ['']
 label is:
 ['New Jersey, Rhode Island and Delaware']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:07,732 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:07,732 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 191, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:07,732 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:07,733 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:07,733 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:08,673 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:08,674 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9415428638458252 s; generated tokens: 1 tokens; generate speed: 1.0620865373196084 tokens/s
2024-06-05 16:36:08,679 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:08,679 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1126/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.9565 tokens/s, remaining time: 0:15:32
pred is:
 ['']
 label is:
 ['ABC Circle Films']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:08,760 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:08,760 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 185, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:08,761 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:08,761 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:08,761 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:09,701 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:09,703 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416248798370361 s; generated tokens: 1 tokens; generate speed: 1.0619940290586487 tokens/s
2024-06-05 16:36:09,708 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:09,708 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1127/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.9558 tokens/s, remaining time: 0:15:31
pred is:
 ['']
 label is:
 ['Times Square Studios']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:09,789 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:09,789 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 194, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:09,789 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:09,789 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:09,789 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:10,729 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:10,731 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416334629058838 s; generated tokens: 1 tokens; generate speed: 1.0619843488930363 tokens/s
2024-06-05 16:36:10,736 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:10,736 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1128/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.9550 tokens/s, remaining time: 0:15:30
pred is:
 ['']
 label is:
 ['ABC on Demand']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:10,817 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:10,817 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:10,818 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:10,818 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:10,818 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:11,759 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:11,761 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423413276672363 s; generated tokens: 1 tokens; generate speed: 1.0611866110929227 tokens/s
2024-06-05 16:36:11,765 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:11,765 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1129/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0488 tokens/s, avg speed: 1.9542 tokens/s, remaining time: 0:15:29
pred is:
 ['']
 label is:
 ['the day after their original broadcast']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:11,846 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:11,846 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 283, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:11,847 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:11,847 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:11,847 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:12,789 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:12,792 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9442644119262695 s; generated tokens: 1 tokens; generate speed: 1.0590254036578923 tokens/s
2024-06-05 16:36:12,796 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:12,797 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1130/2067], cost time 0.9552s, every example cost time is 0.9552, generate speed: 1.0469 tokens/s, avg speed: 1.9535 tokens/s, remaining time: 0:15:28
pred is:
 ['']
 label is:
 ['LoyalKaspar']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.7039920813491864, Em score: 2.1238938053097347, current_count: 1130
2024-06-05 16:36:13,069 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:13,069 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 299, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:13,069 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:13,070 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:13,070 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:14,012 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:14,014 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439876079559326 s; generated tokens: 1 tokens; generate speed: 1.0593359399763245 tokens/s
2024-06-05 16:36:14,019 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:14,019 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1131/2067], cost time 0.9551s, every example cost time is 0.9551, generate speed: 1.0470 tokens/s, avg speed: 1.9527 tokens/s, remaining time: 0:15:27
pred is:
 ['']
 label is:
 ['14']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:14,100 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:14,100 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 283, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:14,100 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:14,100 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:14,101 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:15,043 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:15,045 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439058303833008 s; generated tokens: 1 tokens; generate speed: 1.0594277181166691 tokens/s
2024-06-05 16:36:15,049 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:15,050 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1132/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0475 tokens/s, avg speed: 1.9519 tokens/s, remaining time: 0:15:26
pred is:
 ['']
 label is:
 ['Youngstown']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:15,130 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:15,130 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 212, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:15,131 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:15,131 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:15,131 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:16,072 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:16,073 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421474933624268 s; generated tokens: 1 tokens; generate speed: 1.0614049361115463 tokens/s
2024-06-05 16:36:16,078 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:16,078 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1133/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.9511 tokens/s, remaining time: 0:15:25
pred is:
 ['']
 label is:
 ['Walt Disney Presents']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:16,159 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:16,159 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 308, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:16,160 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:16,160 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:16,160 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:17,105 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:17,107 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9463334083557129 s; generated tokens: 1 tokens; generate speed: 1.0567100254206756 tokens/s
2024-06-05 16:36:17,112 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:17,112 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1134/2067], cost time 0.9580s, every example cost time is 0.9580, generate speed: 1.0438 tokens/s, avg speed: 1.9504 tokens/s, remaining time: 0:15:24
pred is:
 ['']
 label is:
 ['ABC Sunday Night Movie']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:17,193 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:17,193 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 240, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:17,193 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:17,193 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:17,194 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:18,135 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:18,137 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9431564807891846 s; generated tokens: 1 tokens; generate speed: 1.06026944665985 tokens/s
2024-06-05 16:36:18,141 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:18,142 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1135/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.9496 tokens/s, remaining time: 0:15:23
pred is:
 ['']
 label is:
 ['ITT']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:18,223 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:18,223 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 381, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:18,223 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:18,223 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:18,223 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:19,167 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:19,169 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9449276924133301 s; generated tokens: 1 tokens; generate speed: 1.058282033671821 tokens/s
2024-06-05 16:36:19,173 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:19,174 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1136/2067], cost time 0.9557s, every example cost time is 0.9557, generate speed: 1.0463 tokens/s, avg speed: 1.9488 tokens/s, remaining time: 0:15:22
pred is:
 ['']
 label is:
 ['Capital Cities Communications']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:19,254 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:19,254 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 334, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:19,254 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:19,255 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:19,255 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:20,197 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:20,199 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439287185668945 s; generated tokens: 1 tokens; generate speed: 1.059402029337803 tokens/s
2024-06-05 16:36:20,203 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:20,204 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1137/2067], cost time 0.9547s, every example cost time is 0.9547, generate speed: 1.0475 tokens/s, avg speed: 1.9481 tokens/s, remaining time: 0:15:21
pred is:
 ['']
 label is:
 ['September 5, 1985']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:20,284 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:20,285 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 229, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:20,285 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:20,285 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:20,285 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:21,226 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:21,228 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424746036529541 s; generated tokens: 1 tokens; generate speed: 1.0610365479601065 tokens/s
2024-06-05 16:36:21,233 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:21,233 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1138/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.9473 tokens/s, remaining time: 0:15:20
pred is:
 ['']
 label is:
 ['Laverne & Shirley']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:21,314 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:21,314 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 218, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:21,315 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:21,315 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:21,315 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:22,255 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:22,257 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942157506942749 s; generated tokens: 1 tokens; generate speed: 1.0613936551277363 tokens/s
2024-06-05 16:36:22,262 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:22,262 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1139/2067], cost time 0.9531s, every example cost time is 0.9531, generate speed: 1.0492 tokens/s, avg speed: 1.9466 tokens/s, remaining time: 0:15:19
pred is:
 ['']
 label is:
 ['the "TGIF" block']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:22,343 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:22,343 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 255, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:22,344 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:22,344 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:22,344 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:23,286 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:23,288 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9436368942260742 s; generated tokens: 1 tokens; generate speed: 1.059729654614821 tokens/s
2024-06-05 16:36:23,293 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:23,293 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1140/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0477 tokens/s, avg speed: 1.9458 tokens/s, remaining time: 0:15:18
pred is:
 ['']
 label is:
 ['seven radio stations']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.6715009227408606, Em score: 2.1052631578947367, current_count: 1140
2024-06-05 16:36:23,570 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:23,571 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 252, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:23,571 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:23,571 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:23,572 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:24,513 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:24,514 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427545070648193 s; generated tokens: 1 tokens; generate speed: 1.060721526660646 tokens/s
2024-06-05 16:36:24,519 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:24,519 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1141/2067], cost time 0.9539s, every example cost time is 0.9539, generate speed: 1.0483 tokens/s, avg speed: 1.9450 tokens/s, remaining time: 0:15:17
pred is:
 ['']
 label is:
 ['westerns and detective series']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:24,626 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:24,627 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 221, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:24,627 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:24,628 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:24,628 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:25,568 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:25,570 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9422459602355957 s; generated tokens: 1 tokens; generate speed: 1.061294016850933 tokens/s
2024-06-05 16:36:25,575 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:25,575 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1142/2067], cost time 0.9794s, every example cost time is 0.9794, generate speed: 1.0211 tokens/s, avg speed: 1.9442 tokens/s, remaining time: 0:15:16
pred is:
 ['']
 label is:
 ['counterprogramming']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:25,656 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:25,656 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 278, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:25,657 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:25,657 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:25,657 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:26,599 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:26,600 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432761669158936 s; generated tokens: 1 tokens; generate speed: 1.0601349160231293 tokens/s
2024-06-05 16:36:26,605 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:26,605 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1143/2067], cost time 0.9542s, every example cost time is 0.9542, generate speed: 1.0480 tokens/s, avg speed: 1.9435 tokens/s, remaining time: 0:15:15
pred is:
 ['']
 label is:
 ['WATCH ABC']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:26,686 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:26,687 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 259, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:26,687 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:26,687 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:26,688 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:27,629 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:27,631 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428665637969971 s; generated tokens: 1 tokens; generate speed: 1.0605954632359877 tokens/s
2024-06-05 16:36:27,635 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:27,636 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1144/2067], cost time 0.9541s, every example cost time is 0.9541, generate speed: 1.0481 tokens/s, avg speed: 1.9427 tokens/s, remaining time: 0:15:14
pred is:
 ['']
 label is:
 ['Sinclair Broadcast Group']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:27,717 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:27,717 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 211, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:27,717 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:27,718 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:27,718 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:28,658 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:28,661 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425914287567139 s; generated tokens: 1 tokens; generate speed: 1.0609050427278004 tokens/s
2024-06-05 16:36:28,665 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:28,665 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1145/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.9420 tokens/s, remaining time: 0:15:13
pred is:
 ['']
 label is:
 ['Start Here']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:28,746 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:28,746 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 269, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:28,747 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:28,747 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:28,747 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:29,688 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:29,690 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.942997932434082 s; generated tokens: 1 tokens; generate speed: 1.0604477121373779 tokens/s
2024-06-05 16:36:29,695 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:29,695 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1146/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0483 tokens/s, avg speed: 1.9412 tokens/s, remaining time: 0:15:12
pred is:
 ['']
 label is:
 ['WFTS-TV and WWSB']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:29,776 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:29,776 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 180, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:29,776 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:29,777 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:29,777 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:30,717 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:30,719 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417576789855957 s; generated tokens: 1 tokens; generate speed: 1.0618442751400121 tokens/s
2024-06-05 16:36:30,723 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:30,723 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1147/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.9405 tokens/s, remaining time: 0:15:11
pred is:
 ['']
 label is:
 ['the Mongol Empire']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:30,804 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:30,804 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 197, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:30,805 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:30,805 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:30,805 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:31,745 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:31,747 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420695304870605 s; generated tokens: 1 tokens; generate speed: 1.0614927748305252 tokens/s
2024-06-05 16:36:31,752 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:31,752 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1148/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.9397 tokens/s, remaining time: 0:15:10
pred is:
 ['']
 label is:
 ['Ögedei Khan']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:31,834 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:31,834 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 227, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:31,834 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:31,834 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:31,835 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:32,775 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:32,777 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425539970397949 s; generated tokens: 1 tokens; generate speed: 1.0609471745285906 tokens/s
2024-06-05 16:36:32,782 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:32,782 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1149/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0489 tokens/s, avg speed: 1.9390 tokens/s, remaining time: 0:15:09
pred is:
 ['']
 label is:
 ['Delüün Boldog']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:32,863 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:32,863 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:32,863 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:32,864 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:32,864 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:33,804 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:33,807 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427211284637451 s; generated tokens: 1 tokens; generate speed: 1.0607590832610236 tokens/s
2024-06-05 16:36:33,811 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:33,812 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1150/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.9382 tokens/s, remaining time: 0:15:08
pred is:
 ['']
 label is:
 ['Temülen']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.639574827760505, Em score: 2.0869565217391304, current_count: 1150
2024-06-05 16:36:34,118 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:34,118 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 187, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:34,119 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:34,119 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:34,119 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:35,059 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:35,061 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941767692565918 s; generated tokens: 1 tokens; generate speed: 1.0618329848154204 tokens/s
2024-06-05 16:36:35,065 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:35,066 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1151/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.9375 tokens/s, remaining time: 0:15:07
pred is:
 ['']
 label is:
 ['Begter']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:35,147 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:35,147 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 211, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:35,148 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:35,148 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:35,148 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:36,088 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:36,090 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420406818389893 s; generated tokens: 1 tokens; generate speed: 1.0615252815280403 tokens/s
2024-06-05 16:36:36,095 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:36,095 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1152/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.9368 tokens/s, remaining time: 0:15:06
pred is:
 ['']
 label is:
 ["the Tayichi'ud"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:36,176 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:36,176 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 168, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:36,177 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:36,177 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:36,177 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:37,117 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:37,119 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9414510726928711 s; generated tokens: 1 tokens; generate speed: 1.0621900903885095 tokens/s
2024-06-05 16:36:37,123 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:37,124 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1153/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0500 tokens/s, avg speed: 1.9360 tokens/s, remaining time: 0:15:05
pred is:
 ['']
 label is:
 ['arranged marriages']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:37,205 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:37,205 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 222, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:37,205 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:37,205 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:37,206 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:38,148 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:38,150 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9446535110473633 s; generated tokens: 1 tokens; generate speed: 1.058589195197372 tokens/s
2024-06-05 16:36:38,156 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:38,156 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1154/2067], cost time 0.9568s, every example cost time is 0.9568, generate speed: 1.0452 tokens/s, avg speed: 1.9353 tokens/s, remaining time: 0:15:04
pred is:
 ['']
 label is:
 ['the Onggirat']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:38,298 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:38,298 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 177, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:38,298 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:38,299 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:38,299 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:39,240 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:39,243 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9439313411712646 s; generated tokens: 1 tokens; generate speed: 1.0593990859114428 tokens/s
2024-06-05 16:36:39,249 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:39,249 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1155/2067], cost time 0.9574s, every example cost time is 0.9574, generate speed: 1.0445 tokens/s, avg speed: 1.9345 tokens/s, remaining time: 0:15:03
pred is:
 ['']
 label is:
 ['three']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:39,331 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:39,331 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 207, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:39,331 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:39,332 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:39,332 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:40,274 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:40,276 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9445469379425049 s; generated tokens: 1 tokens; generate speed: 1.0587086356748854 tokens/s
2024-06-05 16:36:40,282 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:40,282 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1156/2067], cost time 0.9570s, every example cost time is 0.9570, generate speed: 1.0449 tokens/s, avg speed: 1.9338 tokens/s, remaining time: 0:15:02
pred is:
 ['']
 label is:
 ['sworn brother or blood brother']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:40,365 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:40,365 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 339, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:40,365 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:40,366 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:40,366 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:41,309 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:41,311 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9446899890899658 s; generated tokens: 1 tokens; generate speed: 1.058548319076944 tokens/s
2024-06-05 16:36:41,315 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:41,316 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1157/2067], cost time 0.9559s, every example cost time is 0.9559, generate speed: 1.0462 tokens/s, avg speed: 1.9330 tokens/s, remaining time: 0:15:01
pred is:
 ['']
 label is:
 ['the traditional Mongolian aristocracy']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:41,396 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:41,397 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:41,397 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:41,397 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:41,398 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:42,337 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:42,339 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412844181060791 s; generated tokens: 1 tokens; generate speed: 1.0623781513477724 tokens/s
2024-06-05 16:36:42,344 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:42,344 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1158/2067], cost time 0.9523s, every example cost time is 0.9523, generate speed: 1.0501 tokens/s, avg speed: 1.9323 tokens/s, remaining time: 0:15:00
pred is:
 ['']
 label is:
 ['the Yassa code']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:42,425 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:42,425 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 213, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:42,425 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:42,425 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:42,426 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:43,366 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:43,368 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419312477111816 s; generated tokens: 1 tokens; generate speed: 1.0616486101612201 tokens/s
2024-06-05 16:36:43,372 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:43,373 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1159/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.9316 tokens/s, remaining time: 0:14:59
pred is:
 ['']
 label is:
 ['Jochi']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:43,454 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:43,454 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 221, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:43,454 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:43,454 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:43,455 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:44,395 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:44,398 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429049491882324 s; generated tokens: 1 tokens; generate speed: 1.0605522866975319 tokens/s
2024-06-05 16:36:44,402 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:44,403 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1160/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.9308 tokens/s, remaining time: 0:14:58
pred is:
 ['']
 label is:
 ['the Naimans']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.608199182693604, Em score: 2.0689655172413794, current_count: 1160
2024-06-05 16:36:44,679 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:44,680 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 187, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:44,680 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:44,680 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:44,680 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:45,621 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:45,622 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419295787811279 s; generated tokens: 1 tokens; generate speed: 1.0616504912118974 tokens/s
2024-06-05 16:36:45,627 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:45,627 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1161/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.9301 tokens/s, remaining time: 0:14:57
pred is:
 ['']
 label is:
 ['his friendship']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:45,708 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:45,708 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 226, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:45,709 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:45,709 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:45,709 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:46,650 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:46,651 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420275688171387 s; generated tokens: 1 tokens; generate speed: 1.0615400579578098 tokens/s
2024-06-05 16:36:46,656 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:46,656 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1162/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.9294 tokens/s, remaining time: 0:14:56
pred is:
 ['']
 label is:
 ['the Chinese']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:46,737 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:46,737 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 255, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:46,737 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:46,737 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:46,738 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:47,679 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:47,680 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9427201747894287 s; generated tokens: 1 tokens; generate speed: 1.0607601563458273 tokens/s
2024-06-05 16:36:47,685 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:47,685 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1163/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.9287 tokens/s, remaining time: 0:14:55
pred is:
 ['']
 label is:
 ['1206']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:47,766 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:47,766 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 268, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:47,767 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:47,767 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:47,767 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:48,709 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:48,710 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9430022239685059 s; generated tokens: 1 tokens; generate speed: 1.0604428861170934 tokens/s
2024-06-05 16:36:48,715 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:48,715 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1164/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.9279 tokens/s, remaining time: 0:14:54
pred is:
 ['']
 label is:
 ['the Jin dynasty']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:48,796 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:48,797 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 210, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:48,797 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:48,797 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:48,797 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:49,738 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:49,741 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9429569244384766 s; generated tokens: 1 tokens; generate speed: 1.0604938296576931 tokens/s
2024-06-05 16:36:49,745 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:49,746 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1165/2067], cost time 0.9540s, every example cost time is 0.9540, generate speed: 1.0482 tokens/s, avg speed: 1.9272 tokens/s, remaining time: 0:14:53
pred is:
 ['']
 label is:
 ['Kuchlug']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:49,827 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:49,827 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 204, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:49,827 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:49,827 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:49,828 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:50,768 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:50,770 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420173168182373 s; generated tokens: 1 tokens; generate speed: 1.0615516107258043 tokens/s
2024-06-05 16:36:50,774 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:50,775 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1166/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0493 tokens/s, avg speed: 1.9265 tokens/s, remaining time: 0:14:52
pred is:
 ['']
 label is:
 ['inciting internal revolt']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:50,856 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:50,856 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 351, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:50,857 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:50,857 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:50,857 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:51,800 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:51,802 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9444870948791504 s; generated tokens: 1 tokens; generate speed: 1.058775715858725 tokens/s
2024-06-05 16:36:51,806 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:51,807 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1167/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0462 tokens/s, avg speed: 1.9257 tokens/s, remaining time: 0:14:51
pred is:
 ['']
 label is:
 ['Shah Ala ad-Din Muhammad']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:51,890 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:51,890 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 187, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:51,891 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:51,891 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:51,891 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:52,831 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:52,833 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416403770446777 s; generated tokens: 1 tokens; generate speed: 1.061976551110184 tokens/s
2024-06-05 16:36:52,838 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:52,838 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1168/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0494 tokens/s, avg speed: 1.9250 tokens/s, remaining time: 0:14:50
pred is:
 ['']
 label is:
 ['Tien Shan']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:52,919 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:52,919 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 254, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:52,920 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:52,920 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:52,920 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:53,861 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:53,863 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428422451019287 s; generated tokens: 1 tokens; generate speed: 1.0606228191354452 tokens/s
2024-06-05 16:36:53,868 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:53,868 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1169/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0485 tokens/s, avg speed: 1.9243 tokens/s, remaining time: 0:14:49
pred is:
 ['']
 label is:
 ['fragmentation']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:53,949 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:53,949 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 175, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:53,950 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:53,950 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:53,950 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:54,890 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:54,893 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9423525333404541 s; generated tokens: 1 tokens; generate speed: 1.0611739923436052 tokens/s
2024-06-05 16:36:54,897 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:54,898 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1170/2067], cost time 0.9535s, every example cost time is 0.9535, generate speed: 1.0487 tokens/s, avg speed: 1.9236 tokens/s, remaining time: 0:14:47
pred is:
 ['']
 label is:
 ['Samarkand']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.577359873439813, Em score: 2.051282051282051, current_count: 1170
2024-06-05 16:36:55,194 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:55,195 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 221, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:55,195 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:55,195 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:55,195 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:56,135 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:56,137 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417660236358643 s; generated tokens: 1 tokens; generate speed: 1.0618348665195125 tokens/s
2024-06-05 16:36:56,142 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:56,142 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1171/2067], cost time 0.9530s, every example cost time is 0.9530, generate speed: 1.0494 tokens/s, avg speed: 1.9229 tokens/s, remaining time: 0:14:46
pred is:
 ['']
 label is:
 ['captured enemies']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:56,223 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:56,223 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:56,223 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:56,224 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:56,224 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:57,165 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:57,167 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9424970149993896 s; generated tokens: 1 tokens; generate speed: 1.0610113178986011 tokens/s
2024-06-05 16:36:57,171 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:57,171 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1172/2067], cost time 0.9533s, every example cost time is 0.9533, generate speed: 1.0490 tokens/s, avg speed: 1.9221 tokens/s, remaining time: 0:14:45
pred is:
 ['']
 label is:
 ['opened the gates']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:57,252 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:57,252 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 509, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:57,252 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:57,253 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:57,253 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:58,197 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:58,199 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9463083744049072 s; generated tokens: 1 tokens; generate speed: 1.056737979972815 tokens/s
2024-06-05 16:36:58,204 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:58,204 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1173/2067], cost time 0.9571s, every example cost time is 0.9571, generate speed: 1.0448 tokens/s, avg speed: 1.9214 tokens/s, remaining time: 0:14:44
pred is:
 ['']
 label is:
 ['1220']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:58,285 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:58,285 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 267, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:58,285 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:58,285 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:58,286 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:36:59,227 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:59,228 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426162242889404 s; generated tokens: 1 tokens; generate speed: 1.0608771356066429 tokens/s
2024-06-05 16:36:59,233 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:36:59,233 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1174/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.9207 tokens/s, remaining time: 0:14:43
pred is:
 ['']
 label is:
 ['Batu']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:36:59,314 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:36:59,314 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 205, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:36:59,314 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:36:59,314 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:36:59,315 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:00,255 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:00,257 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419906139373779 s; generated tokens: 1 tokens; generate speed: 1.0615817028368804 tokens/s
2024-06-05 16:37:00,261 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:00,262 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1175/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.9200 tokens/s, remaining time: 0:14:42
pred is:
 ['']
 label is:
 ['1226']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:00,343 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:00,343 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 238, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:00,343 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:00,343 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:00,344 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:01,285 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:01,287 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428706169128418 s; generated tokens: 1 tokens; generate speed: 1.0605909040566053 tokens/s
2024-06-05 16:37:01,291 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:01,292 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1176/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0486 tokens/s, avg speed: 1.9193 tokens/s, remaining time: 0:14:41
pred is:
 ['']
 label is:
 ['Ning Hia']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:01,373 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:01,373 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 209, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:01,374 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:01,374 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:01,374 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:02,314 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:02,316 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419777393341064 s; generated tokens: 1 tokens; generate speed: 1.0615962121428795 tokens/s
2024-06-05 16:37:02,321 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:02,321 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1177/2067], cost time 0.9532s, every example cost time is 0.9532, generate speed: 1.0491 tokens/s, avg speed: 1.9186 tokens/s, remaining time: 0:14:40
pred is:
 ['']
 label is:
 ['Jochi']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:02,406 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:02,407 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 280, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:02,407 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:02,407 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:02,407 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:03,350 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:03,352 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.944589376449585 s; generated tokens: 1 tokens; generate speed: 1.0586610700182615 tokens/s
2024-06-05 16:37:03,357 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:03,357 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1178/2067], cost time 0.9558s, every example cost time is 0.9558, generate speed: 1.0463 tokens/s, avg speed: 1.9178 tokens/s, remaining time: 0:14:39
pred is:
 ['']
 label is:
 ['Chagatai and Jochi']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:03,438 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:03,438 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 309, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:03,439 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:03,439 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:03,439 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:04,382 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:04,384 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9450695514678955 s; generated tokens: 1 tokens; generate speed: 1.0581231809307428 tokens/s
2024-06-05 16:37:04,389 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:04,389 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1179/2067], cost time 0.9564s, every example cost time is 0.9564, generate speed: 1.0455 tokens/s, avg speed: 1.9171 tokens/s, remaining time: 0:14:38
pred is:
 ['']
 label is:
 ['1226']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:04,470 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:04,470 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 268, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:04,471 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:04,471 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:04,471 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:05,413 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:05,416 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9446103572845459 s; generated tokens: 1 tokens; generate speed: 1.0586375559915324 tokens/s
2024-06-05 16:37:05,420 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:05,421 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1180/2067], cost time 0.9554s, every example cost time is 0.9554, generate speed: 1.0467 tokens/s, avg speed: 1.9164 tokens/s, remaining time: 0:14:37
pred is:
 ['']
 label is:
 ['Yinchuan']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.5470432643428653, Em score: 2.0338983050847457, current_count: 1180
2024-06-05 16:37:05,706 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:05,706 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 176, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:05,707 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:05,707 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:05,707 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:06,647 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:06,649 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417111873626709 s; generated tokens: 1 tokens; generate speed: 1.0618966976494897 tokens/s
2024-06-05 16:37:06,653 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:06,654 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1181/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.9157 tokens/s, remaining time: 0:14:36
pred is:
 ['']
 label is:
 ['without markings']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:06,740 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:06,740 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 279, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:06,740 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:06,741 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:06,741 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:07,682 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:07,684 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9432950019836426 s; generated tokens: 1 tokens; generate speed: 1.0601137479760978 tokens/s
2024-06-05 16:37:07,689 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:07,689 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1182/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0477 tokens/s, avg speed: 1.9150 tokens/s, remaining time: 0:14:35
pred is:
 ['']
 label is:
 ['Edsen Khoroo']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:07,770 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:07,770 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 186, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:07,770 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:07,770 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:07,771 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:08,710 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:08,712 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416751861572266 s; generated tokens: 1 tokens; generate speed: 1.0619372950462722 tokens/s
2024-06-05 16:37:08,717 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:08,717 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1183/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.9143 tokens/s, remaining time: 0:14:34
pred is:
 ['']
 label is:
 ['October 6, 2004']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:08,797 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:08,798 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 193, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:08,798 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:08,798 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:08,798 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:09,738 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:09,740 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417049884796143 s; generated tokens: 1 tokens; generate speed: 1.0619036877085075 tokens/s
2024-06-05 16:37:09,745 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:09,745 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1184/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0499 tokens/s, avg speed: 1.9136 tokens/s, remaining time: 0:14:33
pred is:
 ['']
 label is:
 ['Genghis Khan']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:09,826 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:09,827 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 159, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:09,827 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:09,827 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:09,827 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:10,767 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:10,769 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416618347167969 s; generated tokens: 1 tokens; generate speed: 1.0619523518235696 tokens/s
2024-06-05 16:37:10,774 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:10,774 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1185/2067], cost time 0.9526s, every example cost time is 0.9526, generate speed: 1.0497 tokens/s, avg speed: 1.9129 tokens/s, remaining time: 0:14:32
pred is:
 ['']
 label is:
 ['tax exemptions']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:10,859 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:10,860 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 189, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:10,860 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:10,860 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:10,860 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:11,800 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:11,802 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9412970542907715 s; generated tokens: 1 tokens; generate speed: 1.0623638897430299 tokens/s
2024-06-05 16:37:11,807 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:11,807 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1186/2067], cost time 0.9524s, every example cost time is 0.9524, generate speed: 1.0499 tokens/s, avg speed: 1.9122 tokens/s, remaining time: 0:14:31
pred is:
 ['']
 label is:
 ['Töregene Khatun']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:11,888 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:11,889 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 255, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:11,889 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:11,889 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:11,890 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:12,831 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:12,833 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434731006622314 s; generated tokens: 1 tokens; generate speed: 1.0599136311338309 tokens/s
2024-06-05 16:37:12,838 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:12,838 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1187/2067], cost time 0.9550s, every example cost time is 0.9550, generate speed: 1.0471 tokens/s, avg speed: 1.9115 tokens/s, remaining time: 0:14:30
pred is:
 ['']
 label is:
 ["Chu'Tsai"]
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:12,918 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:12,919 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 224, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:12,919 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:12,919 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:12,919 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:13,860 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:13,861 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9419534206390381 s; generated tokens: 1 tokens; generate speed: 1.0616236196919187 tokens/s
2024-06-05 16:37:13,866 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:13,866 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1188/2067], cost time 0.9528s, every example cost time is 0.9528, generate speed: 1.0495 tokens/s, avg speed: 1.9108 tokens/s, remaining time: 0:14:29
pred is:
 ['']
 label is:
 ['his generals']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:13,947 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:13,947 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 167, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:13,947 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:13,947 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:13,948 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:14,888 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:14,891 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9434559345245361 s; generated tokens: 1 tokens; generate speed: 1.059932916214004 tokens/s
2024-06-05 16:37:14,896 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:14,896 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1189/2067], cost time 0.9545s, every example cost time is 0.9545, generate speed: 1.0477 tokens/s, avg speed: 1.9101 tokens/s, remaining time: 0:14:28
pred is:
 ['']
 label is:
 ['rivers']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:14,977 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:14,977 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 210, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:14,978 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:14,978 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:14,978 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:15,919 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:15,921 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9428715705871582 s; generated tokens: 1 tokens; generate speed: 1.0605898313142117 tokens/s
2024-06-05 16:37:15,926 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:15,926 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1190/2067], cost time 0.9538s, every example cost time is 0.9538, generate speed: 1.0485 tokens/s, avg speed: 1.9094 tokens/s, remaining time: 0:14:27
pred is:
 ['']
 label is:
 ['Sea of Japan']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
F1 score: 3.517236178087883, Em score: 2.0168067226890756, current_count: 1190
2024-06-05 16:37:16,214 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:16,214 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 160, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:16,214 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:16,215 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:16,215 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:17,154 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:17,156 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9410834312438965 s; generated tokens: 1 tokens; generate speed: 1.0626050430812806 tokens/s
2024-06-05 16:37:17,161 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:17,161 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1191/2067], cost time 0.9522s, every example cost time is 0.9522, generate speed: 1.0502 tokens/s, avg speed: 1.9087 tokens/s, remaining time: 0:14:26
pred is:
 ['']
 label is:
 ['the Silk Road']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:17,241 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:17,241 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 239, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:17,241 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:17,241 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:17,242 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:18,182 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:18,184 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425985813140869 s; generated tokens: 1 tokens; generate speed: 1.0608969924460199 tokens/s
2024-06-05 16:37:18,189 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:18,189 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1192/2067], cost time 0.9534s, every example cost time is 0.9534, generate speed: 1.0489 tokens/s, avg speed: 1.9080 tokens/s, remaining time: 0:14:25
pred is:
 ['']
 label is:
 ['1990s']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:18,270 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:18,270 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 190, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:18,270 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:18,271 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:18,271 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:19,211 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:19,213 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9417586326599121 s; generated tokens: 1 tokens; generate speed: 1.061843199860659 tokens/s
2024-06-05 16:37:19,217 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:19,218 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1193/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0496 tokens/s, avg speed: 1.9073 tokens/s, remaining time: 0:14:24
pred is:
 ['']
 label is:
 ['tögrög']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:19,298 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:19,298 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 359, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:19,299 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:19,299 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:19,299 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:20,242 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:20,244 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9442558288574219 s; generated tokens: 1 tokens; generate speed: 1.059035029955844 tokens/s
2024-06-05 16:37:20,248 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:20,249 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1194/2067], cost time 0.9551s, every example cost time is 0.9551, generate speed: 1.0470 tokens/s, avg speed: 1.9066 tokens/s, remaining time: 0:14:23
pred is:
 ['']
 label is:
 ['Ikh Zasag']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:20,340 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:20,341 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 239, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:20,341 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:20,341 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:20,341 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:21,282 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:21,284 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9425790309906006 s; generated tokens: 1 tokens; generate speed: 1.0609189968389738 tokens/s
2024-06-05 16:37:21,289 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:21,289 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1195/2067], cost time 0.9537s, every example cost time is 0.9537, generate speed: 1.0485 tokens/s, avg speed: 1.9059 tokens/s, remaining time: 0:14:22
pred is:
 ['']
 label is:
 ['Inner Mongolia region']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:21,370 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:21,370 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 165, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:21,370 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:21,371 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:21,371 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:22,311 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:22,313 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9416766166687012 s; generated tokens: 1 tokens; generate speed: 1.0619356818454568 tokens/s
2024-06-05 16:37:22,317 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:22,317 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1196/2067], cost time 0.9525s, every example cost time is 0.9525, generate speed: 1.0498 tokens/s, avg speed: 1.9052 tokens/s, remaining time: 0:14:21
pred is:
 ['']
 label is:
 ['Iran']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:22,398 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:22,399 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 248, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:22,399 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:22,399 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:22,399 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:23,340 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:23,342 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9426023960113525 s; generated tokens: 1 tokens; generate speed: 1.0608926990123588 tokens/s
2024-06-05 16:37:23,347 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:23,347 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1197/2067], cost time 0.9536s, every example cost time is 0.9536, generate speed: 1.0487 tokens/s, avg speed: 1.9045 tokens/s, remaining time: 0:14:20
pred is:
 ['']
 label is:
 ['Hulagu Khan']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:23,428 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:23,428 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 184, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:23,429 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:23,429 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:23,429 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:24,369 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:24,371 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.941648006439209 s; generated tokens: 1 tokens; generate speed: 1.0619679467930336 tokens/s
2024-06-05 16:37:24,376 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:24,376 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1198/2067], cost time 0.9527s, every example cost time is 0.9527, generate speed: 1.0497 tokens/s, avg speed: 1.9039 tokens/s, remaining time: 0:14:19
pred is:
 ['']
 label is:
 ['Mughal emperors']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:24,457 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:24,458 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 219, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:24,458 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:24,458 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:24,459 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-06-05 16:37:25,399 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:25,401 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9420208930969238 s; generated tokens: 1 tokens; generate speed: 1.0615475806618981 tokens/s
2024-06-05 16:37:25,405 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-06-05 16:37:25,406 - mindformers[mindformers/trainer/causal_language_modeling/causal_language_modeling.py:283] - INFO - Step[1199/2067], cost time 0.9529s, every example cost time is 0.9529, generate speed: 1.0495 tokens/s, avg speed: 1.9032 tokens/s, remaining time: 0:14:18
pred is:
 ['']
 label is:
 ['tenggis']
The F1/Em of this example is:  {'F1': 0.0, 'Em': 0.0}
2024-06-05 16:37:25,487 - mindformers[mindformers/generation/text_generator.py:695] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-06-05 16:37:25,487 - mindformers[mindformers/generation/text_generator.py:697] - INFO - Generation Config is: {'max_length': 245, 'max_new_tokens': 20, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 0, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'pad_token_id': 128002, 'bos_token_id': 128000, 'eos_token_id': 128001, '_from_model_config': True}
2024-06-05 16:37:25,487 - mindformers[mindformers/generation/text_generator.py:252] - INFO - The generation mode will be **GREEDY_SEARCH**.
2024-06-05 16:37:25,488 - mindformers[mindformers/generation/text_generator.py:93] - INFO - Set kbk infer :True
2024-06-05 16:37:25,488 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
